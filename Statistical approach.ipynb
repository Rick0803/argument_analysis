{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Statistical Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import json\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from project import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Issue</th>\n",
       "      <th>Stance</th>\n",
       "      <th>Argument</th>\n",
       "      <th>Annotator</th>\n",
       "      <th>Argumentative</th>\n",
       "      <th>CO</th>\n",
       "      <th>LA</th>\n",
       "      <th>LR</th>\n",
       "      <th>LS</th>\n",
       "      <th>...</th>\n",
       "      <th>CR</th>\n",
       "      <th>EM</th>\n",
       "      <th>CL</th>\n",
       "      <th>AP</th>\n",
       "      <th>AR</th>\n",
       "      <th>RE</th>\n",
       "      <th>GA</th>\n",
       "      <th>GR</th>\n",
       "      <th>GS</th>\n",
       "      <th>OV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>arg219250</td>\n",
       "      <td>ban-plastic-water-bottles</td>\n",
       "      <td>no-bad-for-the-economy</td>\n",
       "      <td>it is true that bottled water is a waste, but ...</td>\n",
       "      <td>1</td>\n",
       "      <td>y</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>arg219250</td>\n",
       "      <td>ban-plastic-water-bottles</td>\n",
       "      <td>no-bad-for-the-economy</td>\n",
       "      <td>it is true that bottled water is a waste, but ...</td>\n",
       "      <td>2</td>\n",
       "      <td>y</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>arg219250</td>\n",
       "      <td>ban-plastic-water-bottles</td>\n",
       "      <td>no-bad-for-the-economy</td>\n",
       "      <td>it is true that bottled water is a waste, but ...</td>\n",
       "      <td>3</td>\n",
       "      <td>y</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>arg219293</td>\n",
       "      <td>ban-plastic-water-bottles</td>\n",
       "      <td>no-bad-for-the-economy</td>\n",
       "      <td>Most Americans on average recycle 86-88% of th...</td>\n",
       "      <td>1</td>\n",
       "      <td>y</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>arg219293</td>\n",
       "      <td>ban-plastic-water-bottles</td>\n",
       "      <td>no-bad-for-the-economy</td>\n",
       "      <td>Most Americans on average recycle 86-88% of th...</td>\n",
       "      <td>2</td>\n",
       "      <td>y</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>929</th>\n",
       "      <td>arg168822</td>\n",
       "      <td>william-farquhar-ought-to-be-honoured-as-the-r...</td>\n",
       "      <td>yes-of-course</td>\n",
       "      <td>Raffles neglected Singapore when he went aroun...</td>\n",
       "      <td>2</td>\n",
       "      <td>y</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>930</th>\n",
       "      <td>arg168822</td>\n",
       "      <td>william-farquhar-ought-to-be-honoured-as-the-r...</td>\n",
       "      <td>yes-of-course</td>\n",
       "      <td>Raffles neglected Singapore when he went aroun...</td>\n",
       "      <td>3</td>\n",
       "      <td>y</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>931</th>\n",
       "      <td>arg168834</td>\n",
       "      <td>william-farquhar-ought-to-be-honoured-as-the-r...</td>\n",
       "      <td>yes-of-course</td>\n",
       "      <td>Raffles doesn't care about the citizens, doesn...</td>\n",
       "      <td>1</td>\n",
       "      <td>y</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>932</th>\n",
       "      <td>arg168834</td>\n",
       "      <td>william-farquhar-ought-to-be-honoured-as-the-r...</td>\n",
       "      <td>yes-of-course</td>\n",
       "      <td>Raffles doesn't care about the citizens, doesn...</td>\n",
       "      <td>2</td>\n",
       "      <td>y</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>933</th>\n",
       "      <td>arg168834</td>\n",
       "      <td>william-farquhar-ought-to-be-honoured-as-the-r...</td>\n",
       "      <td>yes-of-course</td>\n",
       "      <td>Raffles doesn't care about the citizens, doesn...</td>\n",
       "      <td>3</td>\n",
       "      <td>y</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>934 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            ID                                              Issue  \\\n",
       "0    arg219250                          ban-plastic-water-bottles   \n",
       "1    arg219250                          ban-plastic-water-bottles   \n",
       "2    arg219250                          ban-plastic-water-bottles   \n",
       "3    arg219293                          ban-plastic-water-bottles   \n",
       "4    arg219293                          ban-plastic-water-bottles   \n",
       "..         ...                                                ...   \n",
       "929  arg168822  william-farquhar-ought-to-be-honoured-as-the-r...   \n",
       "930  arg168822  william-farquhar-ought-to-be-honoured-as-the-r...   \n",
       "931  arg168834  william-farquhar-ought-to-be-honoured-as-the-r...   \n",
       "932  arg168834  william-farquhar-ought-to-be-honoured-as-the-r...   \n",
       "933  arg168834  william-farquhar-ought-to-be-honoured-as-the-r...   \n",
       "\n",
       "                     Stance  \\\n",
       "0    no-bad-for-the-economy   \n",
       "1    no-bad-for-the-economy   \n",
       "2    no-bad-for-the-economy   \n",
       "3    no-bad-for-the-economy   \n",
       "4    no-bad-for-the-economy   \n",
       "..                      ...   \n",
       "929           yes-of-course   \n",
       "930           yes-of-course   \n",
       "931           yes-of-course   \n",
       "932           yes-of-course   \n",
       "933           yes-of-course   \n",
       "\n",
       "                                              Argument  Annotator  \\\n",
       "0    it is true that bottled water is a waste, but ...          1   \n",
       "1    it is true that bottled water is a waste, but ...          2   \n",
       "2    it is true that bottled water is a waste, but ...          3   \n",
       "3    Most Americans on average recycle 86-88% of th...          1   \n",
       "4    Most Americans on average recycle 86-88% of th...          2   \n",
       "..                                                 ...        ...   \n",
       "929  Raffles neglected Singapore when he went aroun...          2   \n",
       "930  Raffles neglected Singapore when he went aroun...          3   \n",
       "931  Raffles doesn't care about the citizens, doesn...          1   \n",
       "932  Raffles doesn't care about the citizens, doesn...          2   \n",
       "933  Raffles doesn't care about the citizens, doesn...          3   \n",
       "\n",
       "    Argumentative  CO  LA  LR  LS  ...  CR  EM  CL  AP  AR  RE  GA  GR  GS  OV  \n",
       "0               y   1   1   1   1  ...   1   1   2   1   1   1   1   1   1   1  \n",
       "1               y   1   3   2   1  ...   2   2   3   2   2   2   3   1   1   1  \n",
       "2               y   2   2   3   2  ...   2   1   2   2   2   2   2   2   2   2  \n",
       "3               y   2   3   3   2  ...   3   2   2   2   2   2   2   3   2   2  \n",
       "4               y   1   2   2   1  ...   2   2   2   1   2   1   2   1   1   1  \n",
       "..            ...  ..  ..  ..  ..  ...  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  \n",
       "929             y   1   2   2   1  ...   2   2   2   3   2   2   3   2   1   2  \n",
       "930             y   2   2   3   2  ...   2   2   2   2   2   2   2   3   2   2  \n",
       "931             y   2   2   3   2  ...   2   2   1   2   2   2   2   3   2   2  \n",
       "932             y   1   2   2   1  ...   2   3   3   3   2   2   2   2   1   2  \n",
       "933             y   2   2   3   2  ...   2   2   2   2   2   2   2   3   2   2  \n",
       "\n",
       "[934 rows x 21 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATASET = load_dataset(\"dataset.csv\")\n",
    "DATASET\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Preprocessing\n",
    "\n",
    "### Data Aggregation\n",
    "\n",
    "As we are treating the problem as a classification problem, we will adopt the majority vote as the aggregation method. As suggested by the original paper, when all three annotators disagree with each other (i.e., no majority exists), we will use 2 as the aggregated result. In some cases, annotators disagree on wether the argument is argumentative. We discard instances where such disagreement occurs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def majority_vote(instance: pd.Series) -> int | None:\n",
    "    if len(instance) != 3:\n",
    "        return None\n",
    "\n",
    "    counts = instance.value_counts()\n",
    "\n",
    "    if counts.iloc[0] == 1:\n",
    "        return 2\n",
    "\n",
    "    return counts.index[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Issue</th>\n",
       "      <th>Stance</th>\n",
       "      <th>Argument</th>\n",
       "      <th>CO</th>\n",
       "      <th>LA</th>\n",
       "      <th>LR</th>\n",
       "      <th>LS</th>\n",
       "      <th>EF</th>\n",
       "      <th>CR</th>\n",
       "      <th>EM</th>\n",
       "      <th>CL</th>\n",
       "      <th>AP</th>\n",
       "      <th>AR</th>\n",
       "      <th>RE</th>\n",
       "      <th>GA</th>\n",
       "      <th>GR</th>\n",
       "      <th>GS</th>\n",
       "      <th>OV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1191878965</td>\n",
       "      <td>is-porn-wrong</td>\n",
       "      <td>yes-porn-is-wrong</td>\n",
       "      <td>hells yeah porn is wrong. i mean wtf. film nak...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12365</td>\n",
       "      <td>firefox-vs-internet-explorer</td>\n",
       "      <td>there-s-more-browsers-than-the-ie-firefox-is-a...</td>\n",
       "      <td>(I am writing this through Firefox) Emotions a...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12367</td>\n",
       "      <td>firefox-vs-internet-explorer</td>\n",
       "      <td>there-s-more-browsers-than-the-ie-firefox-is-a...</td>\n",
       "      <td>Firefox (and the extensions) leaks memory like...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12371</td>\n",
       "      <td>firefox-vs-internet-explorer</td>\n",
       "      <td>there-s-more-browsers-than-the-ie-firefox-is-a...</td>\n",
       "      <td>I was a IE user from the beginning, but recent...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12380</td>\n",
       "      <td>firefox-vs-internet-explorer</td>\n",
       "      <td>there-s-more-browsers-than-the-ie-firefox-is-a...</td>\n",
       "      <td>I'm not an IE user but FFX has a lot of issues...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>arg636360</td>\n",
       "      <td>christianity-or-atheism</td>\n",
       "      <td>christianity</td>\n",
       "      <td>One of the key component to Christianity is FA...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>arg644073</td>\n",
       "      <td>christianity-or-atheism</td>\n",
       "      <td>christianity</td>\n",
       "      <td>Christianity does offer hope in the world. Chr...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>arg649666</td>\n",
       "      <td>india-has-the-potential-to-lead-the-world</td>\n",
       "      <td>no-against</td>\n",
       "      <td>India has Strong Military Neighbors (China &amp; P...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>arg660921</td>\n",
       "      <td>is-the-school-uniform-a-good-or-bad-idea</td>\n",
       "      <td>good</td>\n",
       "      <td>yas,of course . School uniform is important &lt;b...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>arg7751</td>\n",
       "      <td>should-physical-education-be-mandatory-in-schools</td>\n",
       "      <td>yes</td>\n",
       "      <td>It should be mandatory because being active an...</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>303 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             ID                                              Issue  \\\n",
       "0    1191878965                                      is-porn-wrong   \n",
       "1         12365                       firefox-vs-internet-explorer   \n",
       "2         12367                       firefox-vs-internet-explorer   \n",
       "3         12371                       firefox-vs-internet-explorer   \n",
       "4         12380                       firefox-vs-internet-explorer   \n",
       "..          ...                                                ...   \n",
       "298   arg636360                            christianity-or-atheism   \n",
       "299   arg644073                            christianity-or-atheism   \n",
       "300   arg649666          india-has-the-potential-to-lead-the-world   \n",
       "301   arg660921           is-the-school-uniform-a-good-or-bad-idea   \n",
       "302     arg7751  should-physical-education-be-mandatory-in-schools   \n",
       "\n",
       "                                                Stance  \\\n",
       "0                                    yes-porn-is-wrong   \n",
       "1    there-s-more-browsers-than-the-ie-firefox-is-a...   \n",
       "2    there-s-more-browsers-than-the-ie-firefox-is-a...   \n",
       "3    there-s-more-browsers-than-the-ie-firefox-is-a...   \n",
       "4    there-s-more-browsers-than-the-ie-firefox-is-a...   \n",
       "..                                                 ...   \n",
       "298                                       christianity   \n",
       "299                                       christianity   \n",
       "300                                         no-against   \n",
       "301                                               good   \n",
       "302                                                yes   \n",
       "\n",
       "                                              Argument  CO  LA  LR  LS  EF  \\\n",
       "0    hells yeah porn is wrong. i mean wtf. film nak...   2   1   3   2   2   \n",
       "1    (I am writing this through Firefox) Emotions a...   1   2   3   1   1   \n",
       "2    Firefox (and the extensions) leaks memory like...   1   2   3   1   1   \n",
       "3    I was a IE user from the beginning, but recent...   1   2   3   1   1   \n",
       "4    I'm not an IE user but FFX has a lot of issues...   2   2   3   2   1   \n",
       "..                                                 ...  ..  ..  ..  ..  ..   \n",
       "298  One of the key component to Christianity is FA...   1   2   3   1   1   \n",
       "299  Christianity does offer hope in the world. Chr...   1   2   2   1   1   \n",
       "300  India has Strong Military Neighbors (China & P...   1   2   2   2   1   \n",
       "301  yas,of course . School uniform is important <b...   1   1   2   1   1   \n",
       "302  It should be mandatory because being active an...   2   3   3   2   2   \n",
       "\n",
       "     CR  EM  CL  AP  AR  RE  GA  GR  GS  OV  \n",
       "0     1   2   1   1   2   1   1   2   1   1  \n",
       "1     2   2   3   2   2   2   2   1   1   2  \n",
       "2     2   2   2   2   2   2   2   2   1   1  \n",
       "3     1   1   2   2   2   1   2   2   1   1  \n",
       "4     2   2   1   2   1   2   2   2   1   1  \n",
       "..   ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  \n",
       "298   1   1   2   3   2   1   1   3   1   1  \n",
       "299   1   3   2   2   1   1   2   2   1   1  \n",
       "300   2   2   2   2   1   1   2   2   1   1  \n",
       "301   1   2   1   1   1   1   1   2   1   1  \n",
       "302   2   2   3   3   2   2   3   2   1   2  \n",
       "\n",
       "[303 rows x 19 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AGGREGATED = (DATASET\n",
    "              .drop(columns=[\"Annotator\", \"Argumentative\"])\n",
    "              .groupby([\"ID\", \"Issue\", \"Stance\", \"Argument\"])\n",
    "              .aggregate(majority_vote)\n",
    "              .dropna()\n",
    "              .astype(int)\n",
    "              .reset_index())\n",
    "\n",
    "AGGREGATED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AGGREGATED.to_csv(\"data_preprocess.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Augmentation\n",
    "\n",
    "#### Remove HTML tags mixed into the argument\n",
    "\n",
    "Through inspection, it seems that some arguments contain HTML tags such as `<br/>`. To prevent causing trouble for the NLP components, we will preemptively remove those HTML tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<br/>    162\n",
       "Name: Argument, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# determine the kinds of HTML tags present in the arguments.\n",
    "AGGREGATED[\"Argument\"].str.findall(f\"<[^>]+>\").explode().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Issue</th>\n",
       "      <th>Stance</th>\n",
       "      <th>Argument</th>\n",
       "      <th>CO</th>\n",
       "      <th>LA</th>\n",
       "      <th>LR</th>\n",
       "      <th>LS</th>\n",
       "      <th>EF</th>\n",
       "      <th>CR</th>\n",
       "      <th>EM</th>\n",
       "      <th>CL</th>\n",
       "      <th>AP</th>\n",
       "      <th>AR</th>\n",
       "      <th>RE</th>\n",
       "      <th>GA</th>\n",
       "      <th>GR</th>\n",
       "      <th>GS</th>\n",
       "      <th>OV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1191878965</td>\n",
       "      <td>is-porn-wrong</td>\n",
       "      <td>yes-porn-is-wrong</td>\n",
       "      <td>hells yeah porn is wrong. i mean wtf. film nak...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12365</td>\n",
       "      <td>firefox-vs-internet-explorer</td>\n",
       "      <td>there-s-more-browsers-than-the-ie-firefox-is-a...</td>\n",
       "      <td>(I am writing this through Firefox) Emotions a...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12367</td>\n",
       "      <td>firefox-vs-internet-explorer</td>\n",
       "      <td>there-s-more-browsers-than-the-ie-firefox-is-a...</td>\n",
       "      <td>Firefox (and the extensions) leaks memory like...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12371</td>\n",
       "      <td>firefox-vs-internet-explorer</td>\n",
       "      <td>there-s-more-browsers-than-the-ie-firefox-is-a...</td>\n",
       "      <td>I was a IE user from the beginning, but recent...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12380</td>\n",
       "      <td>firefox-vs-internet-explorer</td>\n",
       "      <td>there-s-more-browsers-than-the-ie-firefox-is-a...</td>\n",
       "      <td>I'm not an IE user but FFX has a lot of issues...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>arg636360</td>\n",
       "      <td>christianity-or-atheism</td>\n",
       "      <td>christianity</td>\n",
       "      <td>One of the key component to Christianity is FA...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>arg644073</td>\n",
       "      <td>christianity-or-atheism</td>\n",
       "      <td>christianity</td>\n",
       "      <td>Christianity does offer hope in the world. Chr...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>arg649666</td>\n",
       "      <td>india-has-the-potential-to-lead-the-world</td>\n",
       "      <td>no-against</td>\n",
       "      <td>India has Strong Military Neighbors (China &amp; P...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>arg660921</td>\n",
       "      <td>is-the-school-uniform-a-good-or-bad-idea</td>\n",
       "      <td>good</td>\n",
       "      <td>yas,of course . School uniform is important 1....</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>arg7751</td>\n",
       "      <td>should-physical-education-be-mandatory-in-schools</td>\n",
       "      <td>yes</td>\n",
       "      <td>It should be mandatory because being active an...</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>303 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             ID                                              Issue  \\\n",
       "0    1191878965                                      is-porn-wrong   \n",
       "1         12365                       firefox-vs-internet-explorer   \n",
       "2         12367                       firefox-vs-internet-explorer   \n",
       "3         12371                       firefox-vs-internet-explorer   \n",
       "4         12380                       firefox-vs-internet-explorer   \n",
       "..          ...                                                ...   \n",
       "298   arg636360                            christianity-or-atheism   \n",
       "299   arg644073                            christianity-or-atheism   \n",
       "300   arg649666          india-has-the-potential-to-lead-the-world   \n",
       "301   arg660921           is-the-school-uniform-a-good-or-bad-idea   \n",
       "302     arg7751  should-physical-education-be-mandatory-in-schools   \n",
       "\n",
       "                                                Stance  \\\n",
       "0                                    yes-porn-is-wrong   \n",
       "1    there-s-more-browsers-than-the-ie-firefox-is-a...   \n",
       "2    there-s-more-browsers-than-the-ie-firefox-is-a...   \n",
       "3    there-s-more-browsers-than-the-ie-firefox-is-a...   \n",
       "4    there-s-more-browsers-than-the-ie-firefox-is-a...   \n",
       "..                                                 ...   \n",
       "298                                       christianity   \n",
       "299                                       christianity   \n",
       "300                                         no-against   \n",
       "301                                               good   \n",
       "302                                                yes   \n",
       "\n",
       "                                              Argument  CO  LA  LR  LS  EF  \\\n",
       "0    hells yeah porn is wrong. i mean wtf. film nak...   2   1   3   2   2   \n",
       "1    (I am writing this through Firefox) Emotions a...   1   2   3   1   1   \n",
       "2    Firefox (and the extensions) leaks memory like...   1   2   3   1   1   \n",
       "3    I was a IE user from the beginning, but recent...   1   2   3   1   1   \n",
       "4    I'm not an IE user but FFX has a lot of issues...   2   2   3   2   1   \n",
       "..                                                 ...  ..  ..  ..  ..  ..   \n",
       "298  One of the key component to Christianity is FA...   1   2   3   1   1   \n",
       "299  Christianity does offer hope in the world. Chr...   1   2   2   1   1   \n",
       "300  India has Strong Military Neighbors (China & P...   1   2   2   2   1   \n",
       "301  yas,of course . School uniform is important 1....   1   1   2   1   1   \n",
       "302  It should be mandatory because being active an...   2   3   3   2   2   \n",
       "\n",
       "     CR  EM  CL  AP  AR  RE  GA  GR  GS  OV  \n",
       "0     1   2   1   1   2   1   1   2   1   1  \n",
       "1     2   2   3   2   2   2   2   1   1   2  \n",
       "2     2   2   2   2   2   2   2   2   1   1  \n",
       "3     1   1   2   2   2   1   2   2   1   1  \n",
       "4     2   2   1   2   1   2   2   2   1   1  \n",
       "..   ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  \n",
       "298   1   1   2   3   2   1   1   3   1   1  \n",
       "299   1   3   2   2   1   1   2   2   1   1  \n",
       "300   2   2   2   2   1   1   2   2   1   1  \n",
       "301   1   2   1   1   1   1   1   2   1   1  \n",
       "302   2   2   3   3   2   2   3   2   1   2  \n",
       "\n",
       "[303 rows x 19 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AGGREGATED[\"Argument\"] = (AGGREGATED[\"Argument\"]\n",
    "                          .str.replace(\"<br/>\", \" \", regex=False)\n",
    "                          .str.replace(r\"\\s+\", \" \", regex=True))\n",
    "\n",
    "AGGREGATED"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove `-` from issue and stance\n",
    "\n",
    "The use of `-` may complicate future NLP processing for issue and stance field. We will replace `-` with a space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Issue</th>\n",
       "      <th>Stance</th>\n",
       "      <th>Argument</th>\n",
       "      <th>CO</th>\n",
       "      <th>LA</th>\n",
       "      <th>LR</th>\n",
       "      <th>LS</th>\n",
       "      <th>EF</th>\n",
       "      <th>CR</th>\n",
       "      <th>EM</th>\n",
       "      <th>CL</th>\n",
       "      <th>AP</th>\n",
       "      <th>AR</th>\n",
       "      <th>RE</th>\n",
       "      <th>GA</th>\n",
       "      <th>GR</th>\n",
       "      <th>GS</th>\n",
       "      <th>OV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1191878965</td>\n",
       "      <td>is porn wrong</td>\n",
       "      <td>yes porn is wrong</td>\n",
       "      <td>hells yeah porn is wrong. i mean wtf. film nak...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12365</td>\n",
       "      <td>firefox vs internet explorer</td>\n",
       "      <td>there s more browsers than the ie firefox is a...</td>\n",
       "      <td>(I am writing this through Firefox) Emotions a...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12367</td>\n",
       "      <td>firefox vs internet explorer</td>\n",
       "      <td>there s more browsers than the ie firefox is a...</td>\n",
       "      <td>Firefox (and the extensions) leaks memory like...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12371</td>\n",
       "      <td>firefox vs internet explorer</td>\n",
       "      <td>there s more browsers than the ie firefox is a...</td>\n",
       "      <td>I was a IE user from the beginning, but recent...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12380</td>\n",
       "      <td>firefox vs internet explorer</td>\n",
       "      <td>there s more browsers than the ie firefox is a...</td>\n",
       "      <td>I'm not an IE user but FFX has a lot of issues...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>arg636360</td>\n",
       "      <td>christianity or atheism</td>\n",
       "      <td>christianity</td>\n",
       "      <td>One of the key component to Christianity is FA...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>arg644073</td>\n",
       "      <td>christianity or atheism</td>\n",
       "      <td>christianity</td>\n",
       "      <td>Christianity does offer hope in the world. Chr...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>arg649666</td>\n",
       "      <td>india has the potential to lead the world</td>\n",
       "      <td>no against</td>\n",
       "      <td>India has Strong Military Neighbors (China &amp; P...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>arg660921</td>\n",
       "      <td>is the school uniform a good or bad idea</td>\n",
       "      <td>good</td>\n",
       "      <td>yas,of course . School uniform is important 1....</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>arg7751</td>\n",
       "      <td>should physical education be mandatory in schools</td>\n",
       "      <td>yes</td>\n",
       "      <td>It should be mandatory because being active an...</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>303 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             ID                                              Issue  \\\n",
       "0    1191878965                                      is porn wrong   \n",
       "1         12365                       firefox vs internet explorer   \n",
       "2         12367                       firefox vs internet explorer   \n",
       "3         12371                       firefox vs internet explorer   \n",
       "4         12380                       firefox vs internet explorer   \n",
       "..          ...                                                ...   \n",
       "298   arg636360                            christianity or atheism   \n",
       "299   arg644073                            christianity or atheism   \n",
       "300   arg649666          india has the potential to lead the world   \n",
       "301   arg660921           is the school uniform a good or bad idea   \n",
       "302     arg7751  should physical education be mandatory in schools   \n",
       "\n",
       "                                                Stance  \\\n",
       "0                                    yes porn is wrong   \n",
       "1    there s more browsers than the ie firefox is a...   \n",
       "2    there s more browsers than the ie firefox is a...   \n",
       "3    there s more browsers than the ie firefox is a...   \n",
       "4    there s more browsers than the ie firefox is a...   \n",
       "..                                                 ...   \n",
       "298                                       christianity   \n",
       "299                                       christianity   \n",
       "300                                         no against   \n",
       "301                                               good   \n",
       "302                                                yes   \n",
       "\n",
       "                                              Argument  CO  LA  LR  LS  EF  \\\n",
       "0    hells yeah porn is wrong. i mean wtf. film nak...   2   1   3   2   2   \n",
       "1    (I am writing this through Firefox) Emotions a...   1   2   3   1   1   \n",
       "2    Firefox (and the extensions) leaks memory like...   1   2   3   1   1   \n",
       "3    I was a IE user from the beginning, but recent...   1   2   3   1   1   \n",
       "4    I'm not an IE user but FFX has a lot of issues...   2   2   3   2   1   \n",
       "..                                                 ...  ..  ..  ..  ..  ..   \n",
       "298  One of the key component to Christianity is FA...   1   2   3   1   1   \n",
       "299  Christianity does offer hope in the world. Chr...   1   2   2   1   1   \n",
       "300  India has Strong Military Neighbors (China & P...   1   2   2   2   1   \n",
       "301  yas,of course . School uniform is important 1....   1   1   2   1   1   \n",
       "302  It should be mandatory because being active an...   2   3   3   2   2   \n",
       "\n",
       "     CR  EM  CL  AP  AR  RE  GA  GR  GS  OV  \n",
       "0     1   2   1   1   2   1   1   2   1   1  \n",
       "1     2   2   3   2   2   2   2   1   1   2  \n",
       "2     2   2   2   2   2   2   2   2   1   1  \n",
       "3     1   1   2   2   2   1   2   2   1   1  \n",
       "4     2   2   1   2   1   2   2   2   1   1  \n",
       "..   ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  \n",
       "298   1   1   2   3   2   1   1   3   1   1  \n",
       "299   1   3   2   2   1   1   2   2   1   1  \n",
       "300   2   2   2   2   1   1   2   2   1   1  \n",
       "301   1   2   1   1   1   1   1   2   1   1  \n",
       "302   2   2   3   3   2   2   3   2   1   2  \n",
       "\n",
       "[303 rows x 19 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AGGREGATED[\"Issue\"] = AGGREGATED[\"Issue\"].str.replace(\"-\", \" \", regex=False)\n",
    "AGGREGATED[\"Stance\"] = AGGREGATED[\"Stance\"].str.replace(\"-\", \" \", regex=False)\n",
    "\n",
    "AGGREGATED"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Natural Language Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import stanza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m nlp \u001b[39m=\u001b[39m stanza\u001b[39m.\u001b[39mPipeline(\u001b[39m\"\u001b[39m\u001b[39men\u001b[39m\u001b[39m\"\u001b[39m, verbose\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, device\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mcuda\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m AGGREGATED[\u001b[39m\"\u001b[39m\u001b[39mArgument\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m AGGREGATED[\u001b[39m\"\u001b[39m\u001b[39mArgument\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mastype(\u001b[39m\"\u001b[39m\u001b[39mcategory\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m AGGREGATED[\u001b[39m\"\u001b[39m\u001b[39mDocument\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m AGGREGATED[\u001b[39m\"\u001b[39;49m\u001b[39mArgument\u001b[39;49m\u001b[39m\"\u001b[39;49m]\u001b[39m.\u001b[39;49mapply(nlp)\n\u001b[1;32m      6\u001b[0m AGGREGATED\n",
      "File \u001b[0;32m~/.anaconda/envs/rick/lib/python3.10/site-packages/pandas/core/series.py:4771\u001b[0m, in \u001b[0;36mSeries.apply\u001b[0;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[1;32m   4661\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply\u001b[39m(\n\u001b[1;32m   4662\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   4663\u001b[0m     func: AggFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4666\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m   4667\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame \u001b[39m|\u001b[39m Series:\n\u001b[1;32m   4668\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   4669\u001b[0m \u001b[39m    Invoke function on values of Series.\u001b[39;00m\n\u001b[1;32m   4670\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4769\u001b[0m \u001b[39m    dtype: float64\u001b[39;00m\n\u001b[1;32m   4770\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 4771\u001b[0m     \u001b[39mreturn\u001b[39;00m SeriesApply(\u001b[39mself\u001b[39;49m, func, convert_dtype, args, kwargs)\u001b[39m.\u001b[39;49mapply()\n",
      "File \u001b[0;32m~/.anaconda/envs/rick/lib/python3.10/site-packages/pandas/core/apply.py:1123\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1120\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapply_str()\n\u001b[1;32m   1122\u001b[0m \u001b[39m# self.f is Callable\u001b[39;00m\n\u001b[0;32m-> 1123\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply_standard()\n",
      "File \u001b[0;32m~/.anaconda/envs/rick/lib/python3.10/site-packages/pandas/core/apply.py:1171\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1168\u001b[0m \u001b[39m# row-wise access\u001b[39;00m\n\u001b[1;32m   1169\u001b[0m \u001b[39mif\u001b[39;00m is_extension_array_dtype(obj\u001b[39m.\u001b[39mdtype) \u001b[39mand\u001b[39;00m \u001b[39mhasattr\u001b[39m(obj\u001b[39m.\u001b[39m_values, \u001b[39m\"\u001b[39m\u001b[39mmap\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m   1170\u001b[0m     \u001b[39m# GH#23179 some EAs do not have `map`\u001b[39;00m\n\u001b[0;32m-> 1171\u001b[0m     mapped \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39;49m_values\u001b[39m.\u001b[39;49mmap(f)\n\u001b[1;32m   1172\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1173\u001b[0m     values \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39mastype(\u001b[39mobject\u001b[39m)\u001b[39m.\u001b[39m_values\n",
      "File \u001b[0;32m~/.anaconda/envs/rick/lib/python3.10/site-packages/pandas/core/arrays/categorical.py:1533\u001b[0m, in \u001b[0;36mCategorical.map\u001b[0;34m(self, mapper)\u001b[0m\n\u001b[1;32m   1464\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmap\u001b[39m(\u001b[39mself\u001b[39m, mapper):\n\u001b[1;32m   1465\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1466\u001b[0m \u001b[39m    Map categories using an input mapping or function.\u001b[39;00m\n\u001b[1;32m   1467\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1531\u001b[0m \u001b[39m    Index(['first', 'second', nan], dtype='object')\u001b[39;00m\n\u001b[1;32m   1532\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1533\u001b[0m     new_categories \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcategories\u001b[39m.\u001b[39;49mmap(mapper)\n\u001b[1;32m   1534\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1535\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfrom_codes(\n\u001b[1;32m   1536\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_codes\u001b[39m.\u001b[39mcopy(), categories\u001b[39m=\u001b[39mnew_categories, ordered\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mordered\n\u001b[1;32m   1537\u001b[0m         )\n",
      "File \u001b[0;32m~/.anaconda/envs/rick/lib/python3.10/site-packages/pandas/core/indexes/base.py:6361\u001b[0m, in \u001b[0;36mIndex.map\u001b[0;34m(self, mapper, na_action)\u001b[0m\n\u001b[1;32m   6341\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   6342\u001b[0m \u001b[39mMap values using an input mapping or function.\u001b[39;00m\n\u001b[1;32m   6343\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   6357\u001b[0m \u001b[39m    a MultiIndex will be returned.\u001b[39;00m\n\u001b[1;32m   6358\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   6359\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mindexes\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmulti\u001b[39;00m \u001b[39mimport\u001b[39;00m MultiIndex\n\u001b[0;32m-> 6361\u001b[0m new_values \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_map_values(mapper, na_action\u001b[39m=\u001b[39;49mna_action)\n\u001b[1;32m   6363\u001b[0m \u001b[39m# we can return a MultiIndex\u001b[39;00m\n\u001b[1;32m   6364\u001b[0m \u001b[39mif\u001b[39;00m new_values\u001b[39m.\u001b[39msize \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(new_values[\u001b[39m0\u001b[39m], \u001b[39mtuple\u001b[39m):\n",
      "File \u001b[0;32m~/.anaconda/envs/rick/lib/python3.10/site-packages/pandas/core/base.py:890\u001b[0m, in \u001b[0;36mIndexOpsMixin._map_values\u001b[0;34m(self, mapper, na_action)\u001b[0m\n\u001b[1;32m    887\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(msg)\n\u001b[1;32m    889\u001b[0m \u001b[39m# mapper is a function\u001b[39;00m\n\u001b[0;32m--> 890\u001b[0m new_values \u001b[39m=\u001b[39m map_f(values, mapper)\n\u001b[1;32m    892\u001b[0m \u001b[39mreturn\u001b[39;00m new_values\n",
      "File \u001b[0;32m~/.anaconda/envs/rick/lib/python3.10/site-packages/pandas/_libs/lib.pyx:2924\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/.anaconda/envs/rick/lib/python3.10/site-packages/stanza/pipeline/core.py:464\u001b[0m, in \u001b[0;36mPipeline.__call__\u001b[0;34m(self, doc, processors)\u001b[0m\n\u001b[1;32m    463\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, doc, processors\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m--> 464\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mprocess(doc, processors)\n",
      "File \u001b[0;32m~/.anaconda/envs/rick/lib/python3.10/site-packages/stanza/pipeline/core.py:415\u001b[0m, in \u001b[0;36mPipeline.process\u001b[0;34m(self, doc, processors)\u001b[0m\n\u001b[1;32m    413\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprocessors\u001b[39m.\u001b[39mget(processor_name):\n\u001b[1;32m    414\u001b[0m         process \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprocessors[processor_name]\u001b[39m.\u001b[39mbulk_process \u001b[39mif\u001b[39;00m bulk \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprocessors[processor_name]\u001b[39m.\u001b[39mprocess\n\u001b[0;32m--> 415\u001b[0m         doc \u001b[39m=\u001b[39m process(doc)\n\u001b[1;32m    416\u001b[0m \u001b[39mreturn\u001b[39;00m doc\n",
      "File \u001b[0;32m~/.anaconda/envs/rick/lib/python3.10/site-packages/stanza/pipeline/constituency_processor.py:60\u001b[0m, in \u001b[0;36mConstituencyProcessor.process\u001b[0;34m(self, document)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tqdm:\n\u001b[1;32m     58\u001b[0m     words \u001b[39m=\u001b[39m tqdm(words)\n\u001b[0;32m---> 60\u001b[0m trees \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_model\u001b[39m.\u001b[39;49mparse_tagged_words(words, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_batch_size)\n\u001b[1;32m     61\u001b[0m document\u001b[39m.\u001b[39mset(CONSTITUENCY, trees, to_sentence\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m     62\u001b[0m \u001b[39mreturn\u001b[39;00m document\n",
      "File \u001b[0;32m~/.anaconda/envs/rick/lib/python3.10/site-packages/stanza/models/constituency/base_model.py:381\u001b[0m, in \u001b[0;36mBaseModel.parse_tagged_words\u001b[0;34m(self, words, batch_size)\u001b[0m\n\u001b[1;32m    378\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39meval()\n\u001b[1;32m    380\u001b[0m sentence_iterator \u001b[39m=\u001b[39m \u001b[39miter\u001b[39m(words)\n\u001b[0;32m--> 381\u001b[0m treebank \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparse_sentences_no_grad(sentence_iterator, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbuild_batch_from_tagged_words, batch_size, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpredict, keep_state\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, keep_constituents\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m    383\u001b[0m results \u001b[39m=\u001b[39m [t\u001b[39m.\u001b[39mpredictions[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mtree \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m treebank]\n\u001b[1;32m    384\u001b[0m \u001b[39mreturn\u001b[39;00m results\n",
      "File \u001b[0;32m~/.anaconda/envs/rick/lib/python3.10/site-packages/stanza/models/constituency/base_model.py:346\u001b[0m, in \u001b[0;36mBaseModel.parse_sentences_no_grad\u001b[0;34m(self, data_iterator, build_batch_fn, batch_size, transition_choice, keep_state, keep_constituents, keep_scores)\u001b[0m\n\u001b[1;32m    339\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    340\u001b[0m \u001b[39mGiven an iterator over the data and a method for building batches, returns a list of parse trees.\u001b[39;00m\n\u001b[1;32m    341\u001b[0m \n\u001b[1;32m    342\u001b[0m \u001b[39mno_grad() is so that gradients aren't kept, which makes the model\u001b[39;00m\n\u001b[1;32m    343\u001b[0m \u001b[39mrun faster and use less memory at inference time\u001b[39;00m\n\u001b[1;32m    344\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    345\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[0;32m--> 346\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparse_sentences(data_iterator, build_batch_fn, batch_size, transition_choice, keep_state, keep_constituents, keep_scores)\n",
      "File \u001b[0;32m~/.anaconda/envs/rick/lib/python3.10/site-packages/stanza/models/constituency/base_model.py:285\u001b[0m, in \u001b[0;36mBaseModel.parse_sentences\u001b[0;34m(self, data_iterator, build_batch_fn, batch_size, transition_choice, keep_state, keep_constituents, keep_scores)\u001b[0m\n\u001b[1;32m    283\u001b[0m treebank \u001b[39m=\u001b[39m []\n\u001b[1;32m    284\u001b[0m treebank_indices \u001b[39m=\u001b[39m []\n\u001b[0;32m--> 285\u001b[0m state_batch \u001b[39m=\u001b[39m build_batch_fn(batch_size, data_iterator)\n\u001b[1;32m    286\u001b[0m \u001b[39m# used to track which indices we are currently parsing\u001b[39;00m\n\u001b[1;32m    287\u001b[0m \u001b[39m# since the parses get finished at different times, this will let us unsort after\u001b[39;00m\n\u001b[1;32m    288\u001b[0m batch_indices \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(state_batch)))\n",
      "File \u001b[0;32m~/.anaconda/envs/rick/lib/python3.10/site-packages/stanza/models/constituency/base_model.py:262\u001b[0m, in \u001b[0;36mBaseModel.build_batch_from_tagged_words\u001b[0;34m(self, batch_size, data_iterator)\u001b[0m\n\u001b[1;32m    259\u001b[0m     state_batch\u001b[39m.\u001b[39mappend(sentence)\n\u001b[1;32m    261\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(state_batch) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m--> 262\u001b[0m     state_batch \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minitial_state_from_words(state_batch)\n\u001b[1;32m    263\u001b[0m \u001b[39mreturn\u001b[39;00m state_batch\n",
      "File \u001b[0;32m~/.anaconda/envs/rick/lib/python3.10/site-packages/stanza/models/constituency/base_model.py:213\u001b[0m, in \u001b[0;36mBaseModel.initial_state_from_words\u001b[0;34m(self, word_lists)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39minitial_state_from_words\u001b[39m(\u001b[39mself\u001b[39m, word_lists):\n\u001b[1;32m    211\u001b[0m     preterminal_lists \u001b[39m=\u001b[39m [[Tree(tag, Tree(word)) \u001b[39mfor\u001b[39;00m word, tag \u001b[39min\u001b[39;00m words]\n\u001b[1;32m    212\u001b[0m                          \u001b[39mfor\u001b[39;00m words \u001b[39min\u001b[39;00m word_lists]\n\u001b[0;32m--> 213\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minitial_state_from_preterminals(preterminal_lists, gold_trees\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m)\n",
      "File \u001b[0;32m~/.anaconda/envs/rick/lib/python3.10/site-packages/stanza/models/constituency/base_model.py:192\u001b[0m, in \u001b[0;36mBaseModel.initial_state_from_preterminals\u001b[0;34m(self, preterminal_lists, gold_trees)\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39minitial_state_from_preterminals\u001b[39m(\u001b[39mself\u001b[39m, preterminal_lists, gold_trees):\n\u001b[1;32m    189\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    190\u001b[0m \u001b[39m    what is passed in should be a list of list of preterminals\u001b[39;00m\n\u001b[1;32m    191\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 192\u001b[0m     word_queues \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minitial_word_queues(preterminal_lists)\n\u001b[1;32m    193\u001b[0m     \u001b[39m# this is the bottom of the TreeStack and will be the same for each State\u001b[39;00m\n\u001b[1;32m    194\u001b[0m     transitions \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minitial_transitions()\n",
      "File \u001b[0;32m~/.anaconda/envs/rick/lib/python3.10/site-packages/stanza/models/constituency/lstm_model.py:720\u001b[0m, in \u001b[0;36mLSTMModel.initial_word_queues\u001b[0;34m(self, tagged_word_lists)\u001b[0m\n\u001b[1;32m    718\u001b[0m         word_inputs\u001b[39m.\u001b[39mappend(forward_chars)\n\u001b[1;32m    719\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbackward_charlm \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 720\u001b[0m     all_backward_chars \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbackward_charlm\u001b[39m.\u001b[39;49mbuild_char_representation(all_word_labels)\n\u001b[1;32m    721\u001b[0m     \u001b[39mfor\u001b[39;00m word_inputs, backward_chars \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(all_word_inputs, all_backward_chars):\n\u001b[1;32m    722\u001b[0m         word_inputs\u001b[39m.\u001b[39mappend(backward_chars)\n",
      "File \u001b[0;32m~/.anaconda/envs/rick/lib/python3.10/site-packages/stanza/models/common/char_model.py:197\u001b[0m, in \u001b[0;36mCharacterLanguageModel.build_char_representation\u001b[0;34m(self, sentences)\u001b[0m\n\u001b[1;32m    194\u001b[0m chars \u001b[39m=\u001b[39m get_long_tensor(chars, \u001b[39mlen\u001b[39m(all_data), pad_id\u001b[39m=\u001b[39mvocab\u001b[39m.\u001b[39munit2id(CHARLM_END))\u001b[39m.\u001b[39mto(device\u001b[39m=\u001b[39mdevice)\n\u001b[1;32m    196\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[0;32m--> 197\u001b[0m     output, _, _ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mforward(chars, char_lens)\n\u001b[1;32m    198\u001b[0m     res \u001b[39m=\u001b[39m [output[i, offsets] \u001b[39mfor\u001b[39;00m i, offsets \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(char_offsets)]\n\u001b[1;32m    199\u001b[0m     res \u001b[39m=\u001b[39m unsort(res, orig_idx)\n",
      "File \u001b[0;32m~/.anaconda/envs/rick/lib/python3.10/site-packages/stanza/models/common/char_model.py:150\u001b[0m, in \u001b[0;36mCharacterLanguageModel.forward\u001b[0;34m(self, chars, charlens, hidden)\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[39mif\u001b[39;00m hidden \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m: \n\u001b[1;32m    148\u001b[0m     hidden \u001b[39m=\u001b[39m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcharlstm_h_init\u001b[39m.\u001b[39mexpand(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs[\u001b[39m'\u001b[39m\u001b[39mchar_num_layers\u001b[39m\u001b[39m'\u001b[39m], batch_size, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs[\u001b[39m'\u001b[39m\u001b[39mchar_hidden_dim\u001b[39m\u001b[39m'\u001b[39m])\u001b[39m.\u001b[39mcontiguous(),\n\u001b[1;32m    149\u001b[0m               \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcharlstm_c_init\u001b[39m.\u001b[39mexpand(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs[\u001b[39m'\u001b[39m\u001b[39mchar_num_layers\u001b[39m\u001b[39m'\u001b[39m], batch_size, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs[\u001b[39m'\u001b[39m\u001b[39mchar_hidden_dim\u001b[39m\u001b[39m'\u001b[39m])\u001b[39m.\u001b[39mcontiguous())\n\u001b[0;32m--> 150\u001b[0m output, hidden \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcharlstm(embs, charlens, hx\u001b[39m=\u001b[39;49mhidden)\n\u001b[1;32m    151\u001b[0m output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout(pad_packed_sequence(output, batch_first\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)[\u001b[39m0\u001b[39m])\n\u001b[1;32m    152\u001b[0m decoded \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdecoder(output)\n",
      "File \u001b[0;32m~/.anaconda/envs/rick/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.anaconda/envs/rick/lib/python3.10/site-packages/stanza/models/common/packed_lstm.py:22\u001b[0m, in \u001b[0;36mPackedLSTM.forward\u001b[0;34m(self, input, lengths, hx)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39minput\u001b[39m, PackedSequence):\n\u001b[1;32m     20\u001b[0m     \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m pack_padded_sequence(\u001b[39minput\u001b[39m, lengths, batch_first\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_first)\n\u001b[0;32m---> 22\u001b[0m res \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlstm(\u001b[39minput\u001b[39;49m, hx)\n\u001b[1;32m     23\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpad:\n\u001b[1;32m     24\u001b[0m     res \u001b[39m=\u001b[39m (pad_packed_sequence(res[\u001b[39m0\u001b[39m], batch_first\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_first)[\u001b[39m0\u001b[39m], res[\u001b[39m1\u001b[39m])\n",
      "File \u001b[0;32m~/.anaconda/envs/rick/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.anaconda/envs/rick/lib/python3.10/site-packages/torch/nn/modules/rnn.py:815\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    812\u001b[0m     result \u001b[39m=\u001b[39m _VF\u001b[39m.\u001b[39mlstm(\u001b[39minput\u001b[39m, hx, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_flat_weights, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbias, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_layers,\n\u001b[1;32m    813\u001b[0m                       \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbidirectional, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_first)\n\u001b[1;32m    814\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 815\u001b[0m     result \u001b[39m=\u001b[39m _VF\u001b[39m.\u001b[39;49mlstm(\u001b[39minput\u001b[39;49m, batch_sizes, hx, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_flat_weights, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias,\n\u001b[1;32m    816\u001b[0m                       \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnum_layers, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdropout, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbidirectional)\n\u001b[1;32m    817\u001b[0m output \u001b[39m=\u001b[39m result[\u001b[39m0\u001b[39m]\n\u001b[1;32m    818\u001b[0m hidden \u001b[39m=\u001b[39m result[\u001b[39m1\u001b[39m:]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "nlp = stanza.Pipeline(\"en\", verbose=False, device=\"cuda\")\n",
    "\n",
    "AGGREGATED[\"Argument\"] = AGGREGATED[\"Argument\"].astype(\"category\")\n",
    "AGGREGATED[\"Document\"] = AGGREGATED[\"Argument\"].apply(nlp)\n",
    "\n",
    "AGGREGATED"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plain Tokenization\n",
    "\n",
    "Following the typical NLP processing pipeline, we will begin by tokenizing each arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plain_tokenization(document: stanza.Document) -> list:\n",
    "    return [word for sentence in document.sentences for word in sentence.words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Issue</th>\n",
       "      <th>Stance</th>\n",
       "      <th>Argument</th>\n",
       "      <th>CO</th>\n",
       "      <th>LA</th>\n",
       "      <th>LR</th>\n",
       "      <th>LS</th>\n",
       "      <th>EF</th>\n",
       "      <th>CR</th>\n",
       "      <th>...</th>\n",
       "      <th>CL</th>\n",
       "      <th>AP</th>\n",
       "      <th>AR</th>\n",
       "      <th>RE</th>\n",
       "      <th>GA</th>\n",
       "      <th>GR</th>\n",
       "      <th>GS</th>\n",
       "      <th>OV</th>\n",
       "      <th>Document</th>\n",
       "      <th>Plain Words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1191878965</td>\n",
       "      <td>is porn wrong</td>\n",
       "      <td>yes porn is wrong</td>\n",
       "      <td>hells yeah porn is wrong. i mean wtf. film nak...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[\\n  [\\n    {\\n      \"id\": 1,\\n      \"text\": \"...</td>\n",
       "      <td>[{\\n  \"id\": 1,\\n  \"text\": \"hells\",\\n  \"lemma\":...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12365</td>\n",
       "      <td>firefox vs internet explorer</td>\n",
       "      <td>there s more browsers than the ie firefox is a...</td>\n",
       "      <td>(I am writing this through Firefox) Emotions a...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>[\\n  [\\n    {\\n      \"id\": 1,\\n      \"text\": \"...</td>\n",
       "      <td>[{\\n  \"id\": 1,\\n  \"text\": \"(\",\\n  \"lemma\": \"(\"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12367</td>\n",
       "      <td>firefox vs internet explorer</td>\n",
       "      <td>there s more browsers than the ie firefox is a...</td>\n",
       "      <td>Firefox (and the extensions) leaks memory like...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[\\n  [\\n    {\\n      \"id\": 1,\\n      \"text\": \"...</td>\n",
       "      <td>[{\\n  \"id\": 1,\\n  \"text\": \"Firefox\",\\n  \"lemma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12371</td>\n",
       "      <td>firefox vs internet explorer</td>\n",
       "      <td>there s more browsers than the ie firefox is a...</td>\n",
       "      <td>I was a IE user from the beginning, but recent...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[\\n  [\\n    {\\n      \"id\": 1,\\n      \"text\": \"...</td>\n",
       "      <td>[{\\n  \"id\": 1,\\n  \"text\": \"I\",\\n  \"lemma\": \"I\"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12380</td>\n",
       "      <td>firefox vs internet explorer</td>\n",
       "      <td>there s more browsers than the ie firefox is a...</td>\n",
       "      <td>I'm not an IE user but FFX has a lot of issues...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[\\n  [\\n    {\\n      \"id\": 1,\\n      \"text\": \"...</td>\n",
       "      <td>[{\\n  \"id\": 1,\\n  \"text\": \"I\",\\n  \"lemma\": \"I\"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>arg636360</td>\n",
       "      <td>christianity or atheism</td>\n",
       "      <td>christianity</td>\n",
       "      <td>One of the key component to Christianity is FA...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[\\n  [\\n    {\\n      \"id\": 1,\\n      \"text\": \"...</td>\n",
       "      <td>[{\\n  \"id\": 1,\\n  \"text\": \"One\",\\n  \"lemma\": \"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>arg644073</td>\n",
       "      <td>christianity or atheism</td>\n",
       "      <td>christianity</td>\n",
       "      <td>Christianity does offer hope in the world. Chr...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[\\n  [\\n    {\\n      \"id\": 1,\\n      \"text\": \"...</td>\n",
       "      <td>[{\\n  \"id\": 1,\\n  \"text\": \"Christianity\",\\n  \"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>arg649666</td>\n",
       "      <td>india has the potential to lead the world</td>\n",
       "      <td>no against</td>\n",
       "      <td>India has Strong Military Neighbors (China &amp; P...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[\\n  [\\n    {\\n      \"id\": 1,\\n      \"text\": \"...</td>\n",
       "      <td>[{\\n  \"id\": 1,\\n  \"text\": \"India\",\\n  \"lemma\":...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>arg660921</td>\n",
       "      <td>is the school uniform a good or bad idea</td>\n",
       "      <td>good</td>\n",
       "      <td>yas,of course . School uniform is important 1....</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[\\n  [\\n    {\\n      \"id\": 1,\\n      \"text\": \"...</td>\n",
       "      <td>[{\\n  \"id\": 1,\\n  \"text\": \"yas\",\\n  \"lemma\": \"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>arg7751</td>\n",
       "      <td>should physical education be mandatory in schools</td>\n",
       "      <td>yes</td>\n",
       "      <td>It should be mandatory because being active an...</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>[\\n  [\\n    {\\n      \"id\": 1,\\n      \"text\": \"...</td>\n",
       "      <td>[{\\n  \"id\": 1,\\n  \"text\": \"It\",\\n  \"lemma\": \"i...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>303 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             ID                                              Issue  \\\n",
       "0    1191878965                                      is porn wrong   \n",
       "1         12365                       firefox vs internet explorer   \n",
       "2         12367                       firefox vs internet explorer   \n",
       "3         12371                       firefox vs internet explorer   \n",
       "4         12380                       firefox vs internet explorer   \n",
       "..          ...                                                ...   \n",
       "298   arg636360                            christianity or atheism   \n",
       "299   arg644073                            christianity or atheism   \n",
       "300   arg649666          india has the potential to lead the world   \n",
       "301   arg660921           is the school uniform a good or bad idea   \n",
       "302     arg7751  should physical education be mandatory in schools   \n",
       "\n",
       "                                                Stance  \\\n",
       "0                                    yes porn is wrong   \n",
       "1    there s more browsers than the ie firefox is a...   \n",
       "2    there s more browsers than the ie firefox is a...   \n",
       "3    there s more browsers than the ie firefox is a...   \n",
       "4    there s more browsers than the ie firefox is a...   \n",
       "..                                                 ...   \n",
       "298                                       christianity   \n",
       "299                                       christianity   \n",
       "300                                         no against   \n",
       "301                                               good   \n",
       "302                                                yes   \n",
       "\n",
       "                                              Argument  CO  LA  LR  LS  EF  \\\n",
       "0    hells yeah porn is wrong. i mean wtf. film nak...   2   1   3   2   2   \n",
       "1    (I am writing this through Firefox) Emotions a...   1   2   3   1   1   \n",
       "2    Firefox (and the extensions) leaks memory like...   1   2   3   1   1   \n",
       "3    I was a IE user from the beginning, but recent...   1   2   3   1   1   \n",
       "4    I'm not an IE user but FFX has a lot of issues...   2   2   3   2   1   \n",
       "..                                                 ...  ..  ..  ..  ..  ..   \n",
       "298  One of the key component to Christianity is FA...   1   2   3   1   1   \n",
       "299  Christianity does offer hope in the world. Chr...   1   2   2   1   1   \n",
       "300  India has Strong Military Neighbors (China & P...   1   2   2   2   1   \n",
       "301  yas,of course . School uniform is important 1....   1   1   2   1   1   \n",
       "302  It should be mandatory because being active an...   2   3   3   2   2   \n",
       "\n",
       "     CR  ...  CL  AP  AR  RE  GA  GR  GS  OV  \\\n",
       "0     1  ...   1   1   2   1   1   2   1   1   \n",
       "1     2  ...   3   2   2   2   2   1   1   2   \n",
       "2     2  ...   2   2   2   2   2   2   1   1   \n",
       "3     1  ...   2   2   2   1   2   2   1   1   \n",
       "4     2  ...   1   2   1   2   2   2   1   1   \n",
       "..   ..  ...  ..  ..  ..  ..  ..  ..  ..  ..   \n",
       "298   1  ...   2   3   2   1   1   3   1   1   \n",
       "299   1  ...   2   2   1   1   2   2   1   1   \n",
       "300   2  ...   2   2   1   1   2   2   1   1   \n",
       "301   1  ...   1   1   1   1   1   2   1   1   \n",
       "302   2  ...   3   3   2   2   3   2   1   2   \n",
       "\n",
       "                                              Document  \\\n",
       "0    [\\n  [\\n    {\\n      \"id\": 1,\\n      \"text\": \"...   \n",
       "1    [\\n  [\\n    {\\n      \"id\": 1,\\n      \"text\": \"...   \n",
       "2    [\\n  [\\n    {\\n      \"id\": 1,\\n      \"text\": \"...   \n",
       "3    [\\n  [\\n    {\\n      \"id\": 1,\\n      \"text\": \"...   \n",
       "4    [\\n  [\\n    {\\n      \"id\": 1,\\n      \"text\": \"...   \n",
       "..                                                 ...   \n",
       "298  [\\n  [\\n    {\\n      \"id\": 1,\\n      \"text\": \"...   \n",
       "299  [\\n  [\\n    {\\n      \"id\": 1,\\n      \"text\": \"...   \n",
       "300  [\\n  [\\n    {\\n      \"id\": 1,\\n      \"text\": \"...   \n",
       "301  [\\n  [\\n    {\\n      \"id\": 1,\\n      \"text\": \"...   \n",
       "302  [\\n  [\\n    {\\n      \"id\": 1,\\n      \"text\": \"...   \n",
       "\n",
       "                                           Plain Words  \n",
       "0    [{\\n  \"id\": 1,\\n  \"text\": \"hells\",\\n  \"lemma\":...  \n",
       "1    [{\\n  \"id\": 1,\\n  \"text\": \"(\",\\n  \"lemma\": \"(\"...  \n",
       "2    [{\\n  \"id\": 1,\\n  \"text\": \"Firefox\",\\n  \"lemma...  \n",
       "3    [{\\n  \"id\": 1,\\n  \"text\": \"I\",\\n  \"lemma\": \"I\"...  \n",
       "4    [{\\n  \"id\": 1,\\n  \"text\": \"I\",\\n  \"lemma\": \"I\"...  \n",
       "..                                                 ...  \n",
       "298  [{\\n  \"id\": 1,\\n  \"text\": \"One\",\\n  \"lemma\": \"...  \n",
       "299  [{\\n  \"id\": 1,\\n  \"text\": \"Christianity\",\\n  \"...  \n",
       "300  [{\\n  \"id\": 1,\\n  \"text\": \"India\",\\n  \"lemma\":...  \n",
       "301  [{\\n  \"id\": 1,\\n  \"text\": \"yas\",\\n  \"lemma\": \"...  \n",
       "302  [{\\n  \"id\": 1,\\n  \"text\": \"It\",\\n  \"lemma\": \"i...  \n",
       "\n",
       "[303 rows x 21 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AGGREGATED[\"Document\"] = AGGREGATED[\"Document\"].astype(object)\n",
    "AGGREGATED[\"Plain Words\"] = AGGREGATED[\"Document\"].apply(plain_tokenization)\n",
    "\n",
    "AGGREGATED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      [\\n  [\\n    {\\n      \"id\": 1,\\n      \"text\": \"...\n",
       "1      [\\n  [\\n    {\\n      \"id\": 1,\\n      \"text\": \"...\n",
       "2      [\\n  [\\n    {\\n      \"id\": 1,\\n      \"text\": \"...\n",
       "3      [\\n  [\\n    {\\n      \"id\": 1,\\n      \"text\": \"...\n",
       "4      [\\n  [\\n    {\\n      \"id\": 1,\\n      \"text\": \"...\n",
       "                             ...                        \n",
       "298    [\\n  [\\n    {\\n      \"id\": 1,\\n      \"text\": \"...\n",
       "299    [\\n  [\\n    {\\n      \"id\": 1,\\n      \"text\": \"...\n",
       "300    [\\n  [\\n    {\\n      \"id\": 1,\\n      \"text\": \"...\n",
       "301    [\\n  [\\n    {\\n      \"id\": 1,\\n      \"text\": \"...\n",
       "302    [\\n  [\\n    {\\n      \"id\": 1,\\n      \"text\": \"...\n",
       "Name: Document, Length: 303, dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AGGREGATED[\"Document\"].astype(object)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fancy Tokenization\n",
    "\n",
    "To (potentially) help with the generalizability of our analysis, we will group semantically similar concepts appearing inside the argument. The grouping will be done on Named Entities (NEs) using the Named Entity Recognition (NER) feature of `stanza`. We will replace each NE's token with their entity type (e.g., `PER` for person, `LOC` for location, and `QUANTITY` for quantity.\n",
    "\n",
    "```text\n",
    "Steve Jobs has seven apples.\n",
    "\n",
    "[PER] has [QUANTITY] apples.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fancy_tokenization(document: stanza.Document) -> list:\n",
    "    # extract all the entities\n",
    "    entities = []\n",
    "\n",
    "    for sentence in document.sentences:\n",
    "        for entity in sentence.entities:\n",
    "            entities.append(((entity.start_char, entity.end_char),\n",
    "                             entity.type))\n",
    "\n",
    "    # extract all the tokens\n",
    "    tokens = [word for sentence in document.sentences for word in sentence.words]\n",
    "\n",
    "    if len(entities) == 0:\n",
    "        return tokens\n",
    "\n",
    "    # group and replace all tokens that are part of a named entity with type\n",
    "    fancy, (span, type) = [], entities.pop(0)\n",
    "\n",
    "    for index, token in enumerate(tokens):\n",
    "        if token.start_char < span[0]:\n",
    "            fancy.append(token)\n",
    "        elif token.start_char >= span[0] and token.end_char <= span[1]:\n",
    "            pass\n",
    "        else:\n",
    "            fancy.append(type)\n",
    "\n",
    "            if len(entities) != 0:\n",
    "                span, type = entities.pop(0)\n",
    "                fancy.append(token)\n",
    "            else:\n",
    "                fancy.extend(tokens[index:])\n",
    "                break\n",
    "\n",
    "    return fancy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Issue</th>\n",
       "      <th>Stance</th>\n",
       "      <th>Argument</th>\n",
       "      <th>CO</th>\n",
       "      <th>LA</th>\n",
       "      <th>LR</th>\n",
       "      <th>LS</th>\n",
       "      <th>EF</th>\n",
       "      <th>CR</th>\n",
       "      <th>...</th>\n",
       "      <th>AP</th>\n",
       "      <th>AR</th>\n",
       "      <th>RE</th>\n",
       "      <th>GA</th>\n",
       "      <th>GR</th>\n",
       "      <th>GS</th>\n",
       "      <th>OV</th>\n",
       "      <th>Document</th>\n",
       "      <th>Plain Words</th>\n",
       "      <th>Fancy Words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1191878965</td>\n",
       "      <td>is porn wrong</td>\n",
       "      <td>yes porn is wrong</td>\n",
       "      <td>hells yeah porn is wrong. i mean wtf. film nak...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[\\n  [\\n    {\\n      \"id\": 1,\\n      \"text\": \"...</td>\n",
       "      <td>[{\\n  \"id\": 1,\\n  \"text\": \"hells\",\\n  \"lemma\":...</td>\n",
       "      <td>[{\\n  \"id\": 1,\\n  \"text\": \"hells\",\\n  \"lemma\":...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12365</td>\n",
       "      <td>firefox vs internet explorer</td>\n",
       "      <td>there s more browsers than the ie firefox is a...</td>\n",
       "      <td>(I am writing this through Firefox) Emotions a...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>[\\n  [\\n    {\\n      \"id\": 1,\\n      \"text\": \"...</td>\n",
       "      <td>[{\\n  \"id\": 1,\\n  \"text\": \"(\",\\n  \"lemma\": \"(\"...</td>\n",
       "      <td>[{\\n  \"id\": 1,\\n  \"text\": \"(\",\\n  \"lemma\": \"(\"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12367</td>\n",
       "      <td>firefox vs internet explorer</td>\n",
       "      <td>there s more browsers than the ie firefox is a...</td>\n",
       "      <td>Firefox (and the extensions) leaks memory like...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[\\n  [\\n    {\\n      \"id\": 1,\\n      \"text\": \"...</td>\n",
       "      <td>[{\\n  \"id\": 1,\\n  \"text\": \"Firefox\",\\n  \"lemma...</td>\n",
       "      <td>[PRODUCT, {\\n  \"id\": 2,\\n  \"text\": \"(\",\\n  \"le...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12371</td>\n",
       "      <td>firefox vs internet explorer</td>\n",
       "      <td>there s more browsers than the ie firefox is a...</td>\n",
       "      <td>I was a IE user from the beginning, but recent...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[\\n  [\\n    {\\n      \"id\": 1,\\n      \"text\": \"...</td>\n",
       "      <td>[{\\n  \"id\": 1,\\n  \"text\": \"I\",\\n  \"lemma\": \"I\"...</td>\n",
       "      <td>[{\\n  \"id\": 1,\\n  \"text\": \"I\",\\n  \"lemma\": \"I\"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12380</td>\n",
       "      <td>firefox vs internet explorer</td>\n",
       "      <td>there s more browsers than the ie firefox is a...</td>\n",
       "      <td>I'm not an IE user but FFX has a lot of issues...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[\\n  [\\n    {\\n      \"id\": 1,\\n      \"text\": \"...</td>\n",
       "      <td>[{\\n  \"id\": 1,\\n  \"text\": \"I\",\\n  \"lemma\": \"I\"...</td>\n",
       "      <td>[{\\n  \"id\": 1,\\n  \"text\": \"I\",\\n  \"lemma\": \"I\"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>arg636360</td>\n",
       "      <td>christianity or atheism</td>\n",
       "      <td>christianity</td>\n",
       "      <td>One of the key component to Christianity is FA...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[\\n  [\\n    {\\n      \"id\": 1,\\n      \"text\": \"...</td>\n",
       "      <td>[{\\n  \"id\": 1,\\n  \"text\": \"One\",\\n  \"lemma\": \"...</td>\n",
       "      <td>[CARDINAL, {\\n  \"id\": 2,\\n  \"text\": \"of\",\\n  \"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>arg644073</td>\n",
       "      <td>christianity or atheism</td>\n",
       "      <td>christianity</td>\n",
       "      <td>Christianity does offer hope in the world. Chr...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[\\n  [\\n    {\\n      \"id\": 1,\\n      \"text\": \"...</td>\n",
       "      <td>[{\\n  \"id\": 1,\\n  \"text\": \"Christianity\",\\n  \"...</td>\n",
       "      <td>[NORP, {\\n  \"id\": 2,\\n  \"text\": \"does\",\\n  \"le...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>arg649666</td>\n",
       "      <td>india has the potential to lead the world</td>\n",
       "      <td>no against</td>\n",
       "      <td>India has Strong Military Neighbors (China &amp; P...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[\\n  [\\n    {\\n      \"id\": 1,\\n      \"text\": \"...</td>\n",
       "      <td>[{\\n  \"id\": 1,\\n  \"text\": \"India\",\\n  \"lemma\":...</td>\n",
       "      <td>[GPE, {\\n  \"id\": 2,\\n  \"text\": \"has\",\\n  \"lemm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>arg660921</td>\n",
       "      <td>is the school uniform a good or bad idea</td>\n",
       "      <td>good</td>\n",
       "      <td>yas,of course . School uniform is important 1....</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[\\n  [\\n    {\\n      \"id\": 1,\\n      \"text\": \"...</td>\n",
       "      <td>[{\\n  \"id\": 1,\\n  \"text\": \"yas\",\\n  \"lemma\": \"...</td>\n",
       "      <td>[{\\n  \"id\": 1,\\n  \"text\": \"yas\",\\n  \"lemma\": \"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>arg7751</td>\n",
       "      <td>should physical education be mandatory in schools</td>\n",
       "      <td>yes</td>\n",
       "      <td>It should be mandatory because being active an...</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>[\\n  [\\n    {\\n      \"id\": 1,\\n      \"text\": \"...</td>\n",
       "      <td>[{\\n  \"id\": 1,\\n  \"text\": \"It\",\\n  \"lemma\": \"i...</td>\n",
       "      <td>[{\\n  \"id\": 1,\\n  \"text\": \"It\",\\n  \"lemma\": \"i...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>303 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             ID                                              Issue  \\\n",
       "0    1191878965                                      is porn wrong   \n",
       "1         12365                       firefox vs internet explorer   \n",
       "2         12367                       firefox vs internet explorer   \n",
       "3         12371                       firefox vs internet explorer   \n",
       "4         12380                       firefox vs internet explorer   \n",
       "..          ...                                                ...   \n",
       "298   arg636360                            christianity or atheism   \n",
       "299   arg644073                            christianity or atheism   \n",
       "300   arg649666          india has the potential to lead the world   \n",
       "301   arg660921           is the school uniform a good or bad idea   \n",
       "302     arg7751  should physical education be mandatory in schools   \n",
       "\n",
       "                                                Stance  \\\n",
       "0                                    yes porn is wrong   \n",
       "1    there s more browsers than the ie firefox is a...   \n",
       "2    there s more browsers than the ie firefox is a...   \n",
       "3    there s more browsers than the ie firefox is a...   \n",
       "4    there s more browsers than the ie firefox is a...   \n",
       "..                                                 ...   \n",
       "298                                       christianity   \n",
       "299                                       christianity   \n",
       "300                                         no against   \n",
       "301                                               good   \n",
       "302                                                yes   \n",
       "\n",
       "                                              Argument  CO  LA  LR  LS  EF  \\\n",
       "0    hells yeah porn is wrong. i mean wtf. film nak...   2   1   3   2   2   \n",
       "1    (I am writing this through Firefox) Emotions a...   1   2   3   1   1   \n",
       "2    Firefox (and the extensions) leaks memory like...   1   2   3   1   1   \n",
       "3    I was a IE user from the beginning, but recent...   1   2   3   1   1   \n",
       "4    I'm not an IE user but FFX has a lot of issues...   2   2   3   2   1   \n",
       "..                                                 ...  ..  ..  ..  ..  ..   \n",
       "298  One of the key component to Christianity is FA...   1   2   3   1   1   \n",
       "299  Christianity does offer hope in the world. Chr...   1   2   2   1   1   \n",
       "300  India has Strong Military Neighbors (China & P...   1   2   2   2   1   \n",
       "301  yas,of course . School uniform is important 1....   1   1   2   1   1   \n",
       "302  It should be mandatory because being active an...   2   3   3   2   2   \n",
       "\n",
       "     CR  ...  AP  AR  RE  GA  GR  GS  OV  \\\n",
       "0     1  ...   1   2   1   1   2   1   1   \n",
       "1     2  ...   2   2   2   2   1   1   2   \n",
       "2     2  ...   2   2   2   2   2   1   1   \n",
       "3     1  ...   2   2   1   2   2   1   1   \n",
       "4     2  ...   2   1   2   2   2   1   1   \n",
       "..   ..  ...  ..  ..  ..  ..  ..  ..  ..   \n",
       "298   1  ...   3   2   1   1   3   1   1   \n",
       "299   1  ...   2   1   1   2   2   1   1   \n",
       "300   2  ...   2   1   1   2   2   1   1   \n",
       "301   1  ...   1   1   1   1   2   1   1   \n",
       "302   2  ...   3   2   2   3   2   1   2   \n",
       "\n",
       "                                              Document  \\\n",
       "0    [\\n  [\\n    {\\n      \"id\": 1,\\n      \"text\": \"...   \n",
       "1    [\\n  [\\n    {\\n      \"id\": 1,\\n      \"text\": \"...   \n",
       "2    [\\n  [\\n    {\\n      \"id\": 1,\\n      \"text\": \"...   \n",
       "3    [\\n  [\\n    {\\n      \"id\": 1,\\n      \"text\": \"...   \n",
       "4    [\\n  [\\n    {\\n      \"id\": 1,\\n      \"text\": \"...   \n",
       "..                                                 ...   \n",
       "298  [\\n  [\\n    {\\n      \"id\": 1,\\n      \"text\": \"...   \n",
       "299  [\\n  [\\n    {\\n      \"id\": 1,\\n      \"text\": \"...   \n",
       "300  [\\n  [\\n    {\\n      \"id\": 1,\\n      \"text\": \"...   \n",
       "301  [\\n  [\\n    {\\n      \"id\": 1,\\n      \"text\": \"...   \n",
       "302  [\\n  [\\n    {\\n      \"id\": 1,\\n      \"text\": \"...   \n",
       "\n",
       "                                           Plain Words  \\\n",
       "0    [{\\n  \"id\": 1,\\n  \"text\": \"hells\",\\n  \"lemma\":...   \n",
       "1    [{\\n  \"id\": 1,\\n  \"text\": \"(\",\\n  \"lemma\": \"(\"...   \n",
       "2    [{\\n  \"id\": 1,\\n  \"text\": \"Firefox\",\\n  \"lemma...   \n",
       "3    [{\\n  \"id\": 1,\\n  \"text\": \"I\",\\n  \"lemma\": \"I\"...   \n",
       "4    [{\\n  \"id\": 1,\\n  \"text\": \"I\",\\n  \"lemma\": \"I\"...   \n",
       "..                                                 ...   \n",
       "298  [{\\n  \"id\": 1,\\n  \"text\": \"One\",\\n  \"lemma\": \"...   \n",
       "299  [{\\n  \"id\": 1,\\n  \"text\": \"Christianity\",\\n  \"...   \n",
       "300  [{\\n  \"id\": 1,\\n  \"text\": \"India\",\\n  \"lemma\":...   \n",
       "301  [{\\n  \"id\": 1,\\n  \"text\": \"yas\",\\n  \"lemma\": \"...   \n",
       "302  [{\\n  \"id\": 1,\\n  \"text\": \"It\",\\n  \"lemma\": \"i...   \n",
       "\n",
       "                                           Fancy Words  \n",
       "0    [{\\n  \"id\": 1,\\n  \"text\": \"hells\",\\n  \"lemma\":...  \n",
       "1    [{\\n  \"id\": 1,\\n  \"text\": \"(\",\\n  \"lemma\": \"(\"...  \n",
       "2    [PRODUCT, {\\n  \"id\": 2,\\n  \"text\": \"(\",\\n  \"le...  \n",
       "3    [{\\n  \"id\": 1,\\n  \"text\": \"I\",\\n  \"lemma\": \"I\"...  \n",
       "4    [{\\n  \"id\": 1,\\n  \"text\": \"I\",\\n  \"lemma\": \"I\"...  \n",
       "..                                                 ...  \n",
       "298  [CARDINAL, {\\n  \"id\": 2,\\n  \"text\": \"of\",\\n  \"...  \n",
       "299  [NORP, {\\n  \"id\": 2,\\n  \"text\": \"does\",\\n  \"le...  \n",
       "300  [GPE, {\\n  \"id\": 2,\\n  \"text\": \"has\",\\n  \"lemm...  \n",
       "301  [{\\n  \"id\": 1,\\n  \"text\": \"yas\",\\n  \"lemma\": \"...  \n",
       "302  [{\\n  \"id\": 1,\\n  \"text\": \"It\",\\n  \"lemma\": \"i...  \n",
       "\n",
       "[303 rows x 22 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AGGREGATED[\"Fancy Words\"] = AGGREGATED[\"Document\"].apply(fancy_tokenization)\n",
    "\n",
    "AGGREGATED"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random majority baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CO 0.49174917491749176\n",
      "LA 0.5577557755775577\n",
      "LR 0.5115511551155115\n",
      "LS 0.5643564356435643\n",
      "EF 0.6039603960396039\n",
      "CR 0.6567656765676567\n",
      "EM 0.7755775577557755\n",
      "CL 0.6270627062706271\n",
      "AP 0.6435643564356436\n",
      "AR 0.6204620462046204\n",
      "RE 0.5247524752475248\n",
      "GA 0.5313531353135313\n",
      "GR 0.5478547854785478\n",
      "GS 0.759075907590759\n",
      "OV 0.49834983498349833\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5942794279427943"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "AGGREGATED = pd.read_csv(\"aggregated.csv\", index_col=0, converters={\"Document\": json.loads})\n",
    "# majority baseline\n",
    "from statistics import mean\n",
    "avg_list = []\n",
    "for dimension in AGGREGATED.columns[4:4 + 15]:\n",
    "    print(dimension, AGGREGATED[dimension].value_counts(normalize=True).max())\n",
    "    avg_list.append(AGGREGATED[dimension].value_counts(normalize=True).max())\n",
    "mean(avg_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#AGGREGATED.to_csv(\"aggregated.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistical Learning and Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import hstack\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DATASET, TEST_DATASET = train_test_split(AGGREGATED, train_size=0.8, random_state=621)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Issue</th>\n",
       "      <th>Stance</th>\n",
       "      <th>Argument</th>\n",
       "      <th>CO</th>\n",
       "      <th>LA</th>\n",
       "      <th>LR</th>\n",
       "      <th>LS</th>\n",
       "      <th>EF</th>\n",
       "      <th>CR</th>\n",
       "      <th>...</th>\n",
       "      <th>AP</th>\n",
       "      <th>AR</th>\n",
       "      <th>RE</th>\n",
       "      <th>GA</th>\n",
       "      <th>GR</th>\n",
       "      <th>GS</th>\n",
       "      <th>OV</th>\n",
       "      <th>Document</th>\n",
       "      <th>Plain Words</th>\n",
       "      <th>Fancy Words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>arg33342</td>\n",
       "      <td>if your spouse committed murder and he or she ...</td>\n",
       "      <td>yes</td>\n",
       "      <td>I would have to say yes. She committed murder,...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>[\\n  [\\n    {\\n      \"id\": 1,\\n      \"text\": \"...</td>\n",
       "      <td>[{\\n  \"id\": 1,\\n  \"text\": \"I\",\\n  \"lemma\": \"I\"...</td>\n",
       "      <td>[{\\n  \"id\": 1,\\n  \"text\": \"I\",\\n  \"lemma\": \"I\"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>arg238468</td>\n",
       "      <td>is the school uniform a good or bad idea</td>\n",
       "      <td>bad</td>\n",
       "      <td>I have always maintained that it is a good ide...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>[\\n  [\\n    {\\n      \"id\": 1,\\n      \"text\": \"...</td>\n",
       "      <td>[{\\n  \"id\": 1,\\n  \"text\": \"I\",\\n  \"lemma\": \"I\"...</td>\n",
       "      <td>[{\\n  \"id\": 1,\\n  \"text\": \"I\",\\n  \"lemma\": \"I\"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>arg439197</td>\n",
       "      <td>christianity or atheism</td>\n",
       "      <td>atheism</td>\n",
       "      <td>I'm sad to see the way this turned out. With n...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>[\\n  [\\n    {\\n      \"id\": 1,\\n      \"text\": \"...</td>\n",
       "      <td>[{\\n  \"id\": 1,\\n  \"text\": \"I\",\\n  \"lemma\": \"I\"...</td>\n",
       "      <td>[{\\n  \"id\": 1,\\n  \"text\": \"I\",\\n  \"lemma\": \"I\"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>arg312577</td>\n",
       "      <td>should physical education be mandatory in schools</td>\n",
       "      <td>no</td>\n",
       "      <td>P.E. should be optional in 8th grade. If stude...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[\\n  [\\n    {\\n      \"id\": 1,\\n      \"text\": \"...</td>\n",
       "      <td>[{\\n  \"id\": 1,\\n  \"text\": \"P.E.\",\\n  \"lemma\": ...</td>\n",
       "      <td>[{\\n  \"id\": 1,\\n  \"text\": \"P.E.\",\\n  \"lemma\": ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>arg168836</td>\n",
       "      <td>william farquhar ought to be honoured as the r...</td>\n",
       "      <td>no it is raffles</td>\n",
       "      <td>Farquhar has a boss!(raffles) he has to follow...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[\\n  [\\n    {\\n      \"id\": 1,\\n      \"text\": \"...</td>\n",
       "      <td>[{\\n  \"id\": 1,\\n  \"text\": \"Farquhar\",\\n  \"lemm...</td>\n",
       "      <td>[PERSON, {\\n  \"id\": 2,\\n  \"text\": \"has\",\\n  \"l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>arg223675</td>\n",
       "      <td>tv is better than books</td>\n",
       "      <td>books</td>\n",
       "      <td>I think books are better as TV can cause obesi...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>[\\n  [\\n    {\\n      \"id\": 1,\\n      \"text\": \"...</td>\n",
       "      <td>[{\\n  \"id\": 1,\\n  \"text\": \"I\",\\n  \"lemma\": \"I\"...</td>\n",
       "      <td>[{\\n  \"id\": 1,\\n  \"text\": \"I\",\\n  \"lemma\": \"I\"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>arg168834</td>\n",
       "      <td>william farquhar ought to be honoured as the r...</td>\n",
       "      <td>yes of course</td>\n",
       "      <td>Raffles doesn't care about the citizens, doesn...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>[\\n  [\\n    {\\n      \"id\": 1,\\n      \"text\": \"...</td>\n",
       "      <td>[{\\n  \"id\": 1,\\n  \"text\": \"Raffles\",\\n  \"lemma...</td>\n",
       "      <td>[PERSON, {\\n  \"id\": 2,\\n  \"text\": \"does\",\\n  \"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>65125</td>\n",
       "      <td>firefox vs internet explorer</td>\n",
       "      <td>there s more browsers than the ie firefox is a...</td>\n",
       "      <td>Chorme beats all its the fastest and the safes...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[\\n  [\\n    {\\n      \"id\": 1,\\n      \"text\": \"...</td>\n",
       "      <td>[{\\n  \"id\": 1,\\n  \"text\": \"Chorme\",\\n  \"lemma\"...</td>\n",
       "      <td>[{\\n  \"id\": 1,\\n  \"text\": \"Chorme\",\\n  \"lemma\"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>arg33099</td>\n",
       "      <td>personal pursuit or advancing the common good</td>\n",
       "      <td>advancing the common good</td>\n",
       "      <td>advancing the common good is better to me beca...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[\\n  [\\n    {\\n      \"id\": 1,\\n      \"text\": \"...</td>\n",
       "      <td>[{\\n  \"id\": 1,\\n  \"text\": \"advancing\",\\n  \"lem...</td>\n",
       "      <td>[{\\n  \"id\": 1,\\n  \"text\": \"advancing\",\\n  \"lem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>arg231620</td>\n",
       "      <td>christianity or atheism</td>\n",
       "      <td>atheism</td>\n",
       "      <td>For reasons that should be totally obvious, an...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[\\n  [\\n    {\\n      \"id\": 1,\\n      \"text\": \"...</td>\n",
       "      <td>[{\\n  \"id\": 1,\\n  \"text\": \"For\",\\n  \"lemma\": \"...</td>\n",
       "      <td>[{\\n  \"id\": 1,\\n  \"text\": \"For\",\\n  \"lemma\": \"...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>242 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            ID                                              Issue  \\\n",
       "231   arg33342  if your spouse committed murder and he or she ...   \n",
       "177  arg238468           is the school uniform a good or bad idea   \n",
       "281  arg439197                            christianity or atheism   \n",
       "190  arg312577  should physical education be mandatory in schools   \n",
       "135  arg168836  william farquhar ought to be honoured as the r...   \n",
       "..         ...                                                ...   \n",
       "168  arg223675                            tv is better than books   \n",
       "133  arg168834  william farquhar ought to be honoured as the r...   \n",
       "66       65125                       firefox vs internet explorer   \n",
       "199   arg33099      personal pursuit or advancing the common good   \n",
       "174  arg231620                            christianity or atheism   \n",
       "\n",
       "                                                Stance  \\\n",
       "231                                                yes   \n",
       "177                                                bad   \n",
       "281                                            atheism   \n",
       "190                                                 no   \n",
       "135                                   no it is raffles   \n",
       "..                                                 ...   \n",
       "168                                              books   \n",
       "133                                      yes of course   \n",
       "66   there s more browsers than the ie firefox is a...   \n",
       "199                          advancing the common good   \n",
       "174                                            atheism   \n",
       "\n",
       "                                              Argument  CO  LA  LR  LS  EF  \\\n",
       "231  I would have to say yes. She committed murder,...   2   2   3   2   1   \n",
       "177  I have always maintained that it is a good ide...   2   2   3   2   2   \n",
       "281  I'm sad to see the way this turned out. With n...   2   2   3   1   2   \n",
       "190  P.E. should be optional in 8th grade. If stude...   1   2   2   1   1   \n",
       "135  Farquhar has a boss!(raffles) he has to follow...   1   1   2   1   1   \n",
       "..                                                 ...  ..  ..  ..  ..  ..   \n",
       "168  I think books are better as TV can cause obesi...   3   2   3   3   2   \n",
       "133  Raffles doesn't care about the citizens, doesn...   2   2   3   2   2   \n",
       "66   Chorme beats all its the fastest and the safes...   1   1   1   1   1   \n",
       "199  advancing the common good is better to me beca...   1   2   2   1   1   \n",
       "174  For reasons that should be totally obvious, an...   1   1   1   1   1   \n",
       "\n",
       "     CR  ...  AP  AR  RE  GA  GR  GS  OV  \\\n",
       "231   2  ...   2   2   2   2   2   1   2   \n",
       "177   2  ...   2   2   2   3   2   2   2   \n",
       "281   1  ...   2   2   2   2   2   1   2   \n",
       "190   2  ...   2   1   1   1   1   1   1   \n",
       "135   1  ...   1   1   1   1   1   1   1   \n",
       "..   ..  ...  ..  ..  ..  ..  ..  ..  ..   \n",
       "168   2  ...   3   2   3   3   3   2   2   \n",
       "133   2  ...   2   2   2   2   3   2   2   \n",
       "66    1  ...   1   1   1   1   2   1   1   \n",
       "199   2  ...   2   1   1   2   1   1   1   \n",
       "174   1  ...   1   1   1   1   1   1   1   \n",
       "\n",
       "                                              Document  \\\n",
       "231  [\\n  [\\n    {\\n      \"id\": 1,\\n      \"text\": \"...   \n",
       "177  [\\n  [\\n    {\\n      \"id\": 1,\\n      \"text\": \"...   \n",
       "281  [\\n  [\\n    {\\n      \"id\": 1,\\n      \"text\": \"...   \n",
       "190  [\\n  [\\n    {\\n      \"id\": 1,\\n      \"text\": \"...   \n",
       "135  [\\n  [\\n    {\\n      \"id\": 1,\\n      \"text\": \"...   \n",
       "..                                                 ...   \n",
       "168  [\\n  [\\n    {\\n      \"id\": 1,\\n      \"text\": \"...   \n",
       "133  [\\n  [\\n    {\\n      \"id\": 1,\\n      \"text\": \"...   \n",
       "66   [\\n  [\\n    {\\n      \"id\": 1,\\n      \"text\": \"...   \n",
       "199  [\\n  [\\n    {\\n      \"id\": 1,\\n      \"text\": \"...   \n",
       "174  [\\n  [\\n    {\\n      \"id\": 1,\\n      \"text\": \"...   \n",
       "\n",
       "                                           Plain Words  \\\n",
       "231  [{\\n  \"id\": 1,\\n  \"text\": \"I\",\\n  \"lemma\": \"I\"...   \n",
       "177  [{\\n  \"id\": 1,\\n  \"text\": \"I\",\\n  \"lemma\": \"I\"...   \n",
       "281  [{\\n  \"id\": 1,\\n  \"text\": \"I\",\\n  \"lemma\": \"I\"...   \n",
       "190  [{\\n  \"id\": 1,\\n  \"text\": \"P.E.\",\\n  \"lemma\": ...   \n",
       "135  [{\\n  \"id\": 1,\\n  \"text\": \"Farquhar\",\\n  \"lemm...   \n",
       "..                                                 ...   \n",
       "168  [{\\n  \"id\": 1,\\n  \"text\": \"I\",\\n  \"lemma\": \"I\"...   \n",
       "133  [{\\n  \"id\": 1,\\n  \"text\": \"Raffles\",\\n  \"lemma...   \n",
       "66   [{\\n  \"id\": 1,\\n  \"text\": \"Chorme\",\\n  \"lemma\"...   \n",
       "199  [{\\n  \"id\": 1,\\n  \"text\": \"advancing\",\\n  \"lem...   \n",
       "174  [{\\n  \"id\": 1,\\n  \"text\": \"For\",\\n  \"lemma\": \"...   \n",
       "\n",
       "                                           Fancy Words  \n",
       "231  [{\\n  \"id\": 1,\\n  \"text\": \"I\",\\n  \"lemma\": \"I\"...  \n",
       "177  [{\\n  \"id\": 1,\\n  \"text\": \"I\",\\n  \"lemma\": \"I\"...  \n",
       "281  [{\\n  \"id\": 1,\\n  \"text\": \"I\",\\n  \"lemma\": \"I\"...  \n",
       "190  [{\\n  \"id\": 1,\\n  \"text\": \"P.E.\",\\n  \"lemma\": ...  \n",
       "135  [PERSON, {\\n  \"id\": 2,\\n  \"text\": \"has\",\\n  \"l...  \n",
       "..                                                 ...  \n",
       "168  [{\\n  \"id\": 1,\\n  \"text\": \"I\",\\n  \"lemma\": \"I\"...  \n",
       "133  [PERSON, {\\n  \"id\": 2,\\n  \"text\": \"does\",\\n  \"...  \n",
       "66   [{\\n  \"id\": 1,\\n  \"text\": \"Chorme\",\\n  \"lemma\"...  \n",
       "199  [{\\n  \"id\": 1,\\n  \"text\": \"advancing\",\\n  \"lem...  \n",
       "174  [{\\n  \"id\": 1,\\n  \"text\": \"For\",\\n  \"lemma\": \"...  \n",
       "\n",
       "[242 rows x 22 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRAIN_DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Issue</th>\n",
       "      <th>Stance</th>\n",
       "      <th>Argument</th>\n",
       "      <th>CO</th>\n",
       "      <th>LA</th>\n",
       "      <th>LR</th>\n",
       "      <th>LS</th>\n",
       "      <th>EF</th>\n",
       "      <th>CR</th>\n",
       "      <th>...</th>\n",
       "      <th>AP</th>\n",
       "      <th>AR</th>\n",
       "      <th>RE</th>\n",
       "      <th>GA</th>\n",
       "      <th>GR</th>\n",
       "      <th>GS</th>\n",
       "      <th>OV</th>\n",
       "      <th>Document</th>\n",
       "      <th>Plain Words</th>\n",
       "      <th>Fancy Words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>arg219245</td>\n",
       "      <td>ban plastic water bottles</td>\n",
       "      <td>no bad for the economy</td>\n",
       "      <td>U.S. alone grew by over 13%. According to rese...</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>[\\n  [\\n    {\\n      \"id\": 1,\\n      \"text\": \"...</td>\n",
       "      <td>[{\\n  \"id\": 1,\\n  \"text\": \"U.S.\",\\n  \"lemma\": ...</td>\n",
       "      <td>[GPE, {\\n  \"id\": 2,\\n  \"text\": \"alone\",\\n  \"le...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>arg35584</td>\n",
       "      <td>is it better to have a lousy father or to be f...</td>\n",
       "      <td>lousy father</td>\n",
       "      <td>It's better to have a father than to not have ...</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>[\\n  [\\n    {\\n      \"id\": 1,\\n      \"text\": \"...</td>\n",
       "      <td>[{\\n  \"id\": 1,\\n  \"text\": \"It\",\\n  \"lemma\": \"i...</td>\n",
       "      <td>[{\\n  \"id\": 1,\\n  \"text\": \"It\",\\n  \"lemma\": \"i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>arg213555</td>\n",
       "      <td>tv is better than books</td>\n",
       "      <td>books</td>\n",
       "      <td>Books enlighten the soul. Books don't destroy ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[\\n  [\\n    {\\n      \"id\": 1,\\n      \"text\": \"...</td>\n",
       "      <td>[{\\n  \"id\": 1,\\n  \"text\": \"Books\",\\n  \"lemma\":...</td>\n",
       "      <td>[{\\n  \"id\": 1,\\n  \"text\": \"Books\",\\n  \"lemma\":...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>arg336222</td>\n",
       "      <td>human growth and development should parents us...</td>\n",
       "      <td>yes</td>\n",
       "      <td>Humans have been raised for thousands of years...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[\\n  [\\n    {\\n      \"id\": 1,\\n      \"text\": \"...</td>\n",
       "      <td>[{\\n  \"id\": 1,\\n  \"text\": \"Humans\",\\n  \"lemma\"...</td>\n",
       "      <td>[{\\n  \"id\": 1,\\n  \"text\": \"Humans\",\\n  \"lemma\"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>arg33105</td>\n",
       "      <td>personal pursuit or advancing the common good</td>\n",
       "      <td>personal pursuit</td>\n",
       "      <td>it is better to help yourself before you can h...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>[\\n  [\\n    {\\n      \"id\": 1,\\n      \"text\": \"...</td>\n",
       "      <td>[{\\n  \"id\": 1,\\n  \"text\": \"it\",\\n  \"lemma\": \"i...</td>\n",
       "      <td>[{\\n  \"id\": 1,\\n  \"text\": \"it\",\\n  \"lemma\": \"i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>arg216634</td>\n",
       "      <td>should physical education be mandatory in schools</td>\n",
       "      <td>no</td>\n",
       "      <td>P.E doesn't help fat kids the fat kids just ea...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[\\n  [\\n    {\\n      \"id\": 1,\\n      \"text\": \"...</td>\n",
       "      <td>[{\\n  \"id\": 1,\\n  \"text\": \"P.E\",\\n  \"lemma\": \"...</td>\n",
       "      <td>[{\\n  \"id\": 1,\\n  \"text\": \"P.E\",\\n  \"lemma\": \"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>arg334943</td>\n",
       "      <td>human growth and development should parents us...</td>\n",
       "      <td>no</td>\n",
       "      <td>No because spanking might effects the relation...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[\\n  [\\n    {\\n      \"id\": 1,\\n      \"text\": \"...</td>\n",
       "      <td>[{\\n  \"id\": 1,\\n  \"text\": \"No\",\\n  \"lemma\": \"n...</td>\n",
       "      <td>[{\\n  \"id\": 1,\\n  \"text\": \"No\",\\n  \"lemma\": \"n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>arg219259</td>\n",
       "      <td>ban plastic water bottles</td>\n",
       "      <td>no bad for the economy</td>\n",
       "      <td>Bottled water is somewhat less likely to be fo...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>[\\n  [\\n    {\\n      \"id\": 1,\\n      \"text\": \"...</td>\n",
       "      <td>[{\\n  \"id\": 1,\\n  \"text\": \"Bottled\",\\n  \"lemma...</td>\n",
       "      <td>[{\\n  \"id\": 1,\\n  \"text\": \"Bottled\",\\n  \"lemma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>arg219268</td>\n",
       "      <td>ban plastic water bottles</td>\n",
       "      <td>no bad for the economy</td>\n",
       "      <td>Plastic is good light weight and a good for di...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[\\n  [\\n    {\\n      \"id\": 1,\\n      \"text\": \"...</td>\n",
       "      <td>[{\\n  \"id\": 1,\\n  \"text\": \"Plastic\",\\n  \"lemma...</td>\n",
       "      <td>[{\\n  \"id\": 1,\\n  \"text\": \"Plastic\",\\n  \"lemma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>arg33243</td>\n",
       "      <td>if your spouse committed murder and he or she ...</td>\n",
       "      <td>no</td>\n",
       "      <td>No I wouldn't tell on him because you never kn...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[\\n  [\\n    {\\n      \"id\": 1,\\n      \"text\": \"...</td>\n",
       "      <td>[{\\n  \"id\": 1,\\n  \"text\": \"No\",\\n  \"lemma\": \"n...</td>\n",
       "      <td>[{\\n  \"id\": 1,\\n  \"text\": \"No\",\\n  \"lemma\": \"n...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>61 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            ID                                              Issue  \\\n",
       "160  arg219245                          ban plastic water bottles   \n",
       "254   arg35584  is it better to have a lousy father or to be f...   \n",
       "150  arg213555                            tv is better than books   \n",
       "250  arg336222  human growth and development should parents us...   \n",
       "200   arg33105      personal pursuit or advancing the common good   \n",
       "..         ...                                                ...   \n",
       "151  arg216634  should physical education be mandatory in schools   \n",
       "235  arg334943  human growth and development should parents us...   \n",
       "164  arg219259                          ban plastic water bottles   \n",
       "166  arg219268                          ban plastic water bottles   \n",
       "214   arg33243  if your spouse committed murder and he or she ...   \n",
       "\n",
       "                     Stance  \\\n",
       "160  no bad for the economy   \n",
       "254            lousy father   \n",
       "150                   books   \n",
       "250                     yes   \n",
       "200        personal pursuit   \n",
       "..                      ...   \n",
       "151                      no   \n",
       "235                      no   \n",
       "164  no bad for the economy   \n",
       "166  no bad for the economy   \n",
       "214                      no   \n",
       "\n",
       "                                              Argument  CO  LA  LR  LS  EF  \\\n",
       "160  U.S. alone grew by over 13%. According to rese...   2   3   3   1   1   \n",
       "254  It's better to have a father than to not have ...   2   3   3   2   2   \n",
       "150  Books enlighten the soul. Books don't destroy ...   1   1   2   1   1   \n",
       "250  Humans have been raised for thousands of years...   1   1   2   1   1   \n",
       "200  it is better to help yourself before you can h...   2   2   2   2   1   \n",
       "..                                                 ...  ..  ..  ..  ..  ..   \n",
       "151  P.E doesn't help fat kids the fat kids just ea...   1   1   1   1   1   \n",
       "235  No because spanking might effects the relation...   1   2   2   1   2   \n",
       "164  Bottled water is somewhat less likely to be fo...   2   2   3   2   2   \n",
       "166  Plastic is good light weight and a good for di...   1   1   2   1   1   \n",
       "214  No I wouldn't tell on him because you never kn...   1   2   2   1   1   \n",
       "\n",
       "     CR  ...  AP  AR  RE  GA  GR  GS  OV  \\\n",
       "160   2  ...   2   2   2   3   2   1   2   \n",
       "254   2  ...   2   2   2   2   2   1   2   \n",
       "150   2  ...   2   2   1   1   1   1   1   \n",
       "250   1  ...   2   1   1   1   2   1   1   \n",
       "200   1  ...   2   2   2   2   2   1   2   \n",
       "..   ..  ...  ..  ..  ..  ..  ..  ..  ..   \n",
       "151   1  ...   2   1   1   1   1   1   1   \n",
       "235   1  ...   2   2   2   2   1   1   1   \n",
       "164   2  ...   3   2   2   2   3   1   2   \n",
       "166   1  ...   1   1   1   1   1   1   1   \n",
       "214   2  ...   1   1   1   2   2   1   1   \n",
       "\n",
       "                                              Document  \\\n",
       "160  [\\n  [\\n    {\\n      \"id\": 1,\\n      \"text\": \"...   \n",
       "254  [\\n  [\\n    {\\n      \"id\": 1,\\n      \"text\": \"...   \n",
       "150  [\\n  [\\n    {\\n      \"id\": 1,\\n      \"text\": \"...   \n",
       "250  [\\n  [\\n    {\\n      \"id\": 1,\\n      \"text\": \"...   \n",
       "200  [\\n  [\\n    {\\n      \"id\": 1,\\n      \"text\": \"...   \n",
       "..                                                 ...   \n",
       "151  [\\n  [\\n    {\\n      \"id\": 1,\\n      \"text\": \"...   \n",
       "235  [\\n  [\\n    {\\n      \"id\": 1,\\n      \"text\": \"...   \n",
       "164  [\\n  [\\n    {\\n      \"id\": 1,\\n      \"text\": \"...   \n",
       "166  [\\n  [\\n    {\\n      \"id\": 1,\\n      \"text\": \"...   \n",
       "214  [\\n  [\\n    {\\n      \"id\": 1,\\n      \"text\": \"...   \n",
       "\n",
       "                                           Plain Words  \\\n",
       "160  [{\\n  \"id\": 1,\\n  \"text\": \"U.S.\",\\n  \"lemma\": ...   \n",
       "254  [{\\n  \"id\": 1,\\n  \"text\": \"It\",\\n  \"lemma\": \"i...   \n",
       "150  [{\\n  \"id\": 1,\\n  \"text\": \"Books\",\\n  \"lemma\":...   \n",
       "250  [{\\n  \"id\": 1,\\n  \"text\": \"Humans\",\\n  \"lemma\"...   \n",
       "200  [{\\n  \"id\": 1,\\n  \"text\": \"it\",\\n  \"lemma\": \"i...   \n",
       "..                                                 ...   \n",
       "151  [{\\n  \"id\": 1,\\n  \"text\": \"P.E\",\\n  \"lemma\": \"...   \n",
       "235  [{\\n  \"id\": 1,\\n  \"text\": \"No\",\\n  \"lemma\": \"n...   \n",
       "164  [{\\n  \"id\": 1,\\n  \"text\": \"Bottled\",\\n  \"lemma...   \n",
       "166  [{\\n  \"id\": 1,\\n  \"text\": \"Plastic\",\\n  \"lemma...   \n",
       "214  [{\\n  \"id\": 1,\\n  \"text\": \"No\",\\n  \"lemma\": \"n...   \n",
       "\n",
       "                                           Fancy Words  \n",
       "160  [GPE, {\\n  \"id\": 2,\\n  \"text\": \"alone\",\\n  \"le...  \n",
       "254  [{\\n  \"id\": 1,\\n  \"text\": \"It\",\\n  \"lemma\": \"i...  \n",
       "150  [{\\n  \"id\": 1,\\n  \"text\": \"Books\",\\n  \"lemma\":...  \n",
       "250  [{\\n  \"id\": 1,\\n  \"text\": \"Humans\",\\n  \"lemma\"...  \n",
       "200  [{\\n  \"id\": 1,\\n  \"text\": \"it\",\\n  \"lemma\": \"i...  \n",
       "..                                                 ...  \n",
       "151  [{\\n  \"id\": 1,\\n  \"text\": \"P.E\",\\n  \"lemma\": \"...  \n",
       "235  [{\\n  \"id\": 1,\\n  \"text\": \"No\",\\n  \"lemma\": \"n...  \n",
       "164  [{\\n  \"id\": 1,\\n  \"text\": \"Bottled\",\\n  \"lemma...  \n",
       "166  [{\\n  \"id\": 1,\\n  \"text\": \"Plastic\",\\n  \"lemma...  \n",
       "214  [{\\n  \"id\": 1,\\n  \"text\": \"No\",\\n  \"lemma\": \"n...  \n",
       "\n",
       "[61 rows x 22 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEST_DATASET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frequency Based Features\n",
    "\n",
    "In this part, we will investigate the effectiveness of frequency based features in classifying an argument's quality along each dimension. We will investigate the effect of three different approaches (and their combinations):\n",
    "\n",
    "1. _Plain vs. Fancy Tokenization_: Compared to the plain tokenization, fancy tokenization abstract away from the surface text by treating semantically similar items as the same.\n",
    "2. _Word_ vs. _Lemma_: A word's lemma helps abstract away from its grammatical features (e.g., the lemma for \"dogs\" is \"dog\").\n",
    "3. _With_ vs. _Without POS_: Part-of-Speech is the ultimate abstraction from word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def words_to_string(tokens: list) -> str:\n",
    "    return \" \".join(i if isinstance(i, str) else i.text for i in tokens)\n",
    "\n",
    "def lemmas_to_string(tokens: list) -> str:\n",
    "    return \" \".join(i if isinstance(i, str) else (i.lemma or i.text) for i in tokens)\n",
    "\n",
    "def poses_to_string(tokens: list) -> str:\n",
    "    return \" \".join(i.upos for i in tokens if not isinstance(i, str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rick/.anaconda/envs/rick/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/home/rick/.anaconda/envs/rick/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/home/rick/.anaconda/envs/rick/lib/python3.10/site-packages/sklearn/preprocessing/_data.py:2627: UserWarning: n_quantiles (1000) is greater than the total number of samples (242). n_quantiles is set to n_samples.\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/home/rick/.anaconda/envs/rick/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/home/rick/.anaconda/envs/rick/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/home/rick/.anaconda/envs/rick/lib/python3.10/site-packages/sklearn/preprocessing/_data.py:2627: UserWarning: n_quantiles (1000) is greater than the total number of samples (242). n_quantiles is set to n_samples.\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/home/rick/.anaconda/envs/rick/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/home/rick/.anaconda/envs/rick/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/home/rick/.anaconda/envs/rick/lib/python3.10/site-packages/sklearn/preprocessing/_data.py:2627: UserWarning: n_quantiles (1000) is greater than the total number of samples (242). n_quantiles is set to n_samples.\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/home/rick/.anaconda/envs/rick/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/home/rick/.anaconda/envs/rick/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/home/rick/.anaconda/envs/rick/lib/python3.10/site-packages/sklearn/preprocessing/_data.py:2627: UserWarning: n_quantiles (1000) is greater than the total number of samples (242). n_quantiles is set to n_samples.\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/home/rick/.anaconda/envs/rick/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/home/rick/.anaconda/envs/rick/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/home/rick/.anaconda/envs/rick/lib/python3.10/site-packages/sklearn/preprocessing/_data.py:2627: UserWarning: n_quantiles (1000) is greater than the total number of samples (242). n_quantiles is set to n_samples.\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/home/rick/.anaconda/envs/rick/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/home/rick/.anaconda/envs/rick/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/home/rick/.anaconda/envs/rick/lib/python3.10/site-packages/sklearn/preprocessing/_data.py:2627: UserWarning: n_quantiles (1000) is greater than the total number of samples (242). n_quantiles is set to n_samples.\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/home/rick/.anaconda/envs/rick/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/home/rick/.anaconda/envs/rick/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/home/rick/.anaconda/envs/rick/lib/python3.10/site-packages/sklearn/preprocessing/_data.py:2627: UserWarning: n_quantiles (1000) is greater than the total number of samples (242). n_quantiles is set to n_samples.\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/home/rick/.anaconda/envs/rick/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/home/rick/.anaconda/envs/rick/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/home/rick/.anaconda/envs/rick/lib/python3.10/site-packages/sklearn/preprocessing/_data.py:2627: UserWarning: n_quantiles (1000) is greater than the total number of samples (242). n_quantiles is set to n_samples.\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/home/rick/.anaconda/envs/rick/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/home/rick/.anaconda/envs/rick/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/home/rick/.anaconda/envs/rick/lib/python3.10/site-packages/sklearn/preprocessing/_data.py:2627: UserWarning: n_quantiles (1000) is greater than the total number of samples (242). n_quantiles is set to n_samples.\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/home/rick/.anaconda/envs/rick/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/home/rick/.anaconda/envs/rick/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/home/rick/.anaconda/envs/rick/lib/python3.10/site-packages/sklearn/preprocessing/_data.py:2627: UserWarning: n_quantiles (1000) is greater than the total number of samples (242). n_quantiles is set to n_samples.\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/home/rick/.anaconda/envs/rick/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/home/rick/.anaconda/envs/rick/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/home/rick/.anaconda/envs/rick/lib/python3.10/site-packages/sklearn/preprocessing/_data.py:2627: UserWarning: n_quantiles (1000) is greater than the total number of samples (242). n_quantiles is set to n_samples.\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/home/rick/.anaconda/envs/rick/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/home/rick/.anaconda/envs/rick/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/home/rick/.anaconda/envs/rick/lib/python3.10/site-packages/sklearn/preprocessing/_data.py:2627: UserWarning: n_quantiles (1000) is greater than the total number of samples (242). n_quantiles is set to n_samples.\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
      "/tmp/ipykernel_5540/2095016937.py:44: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
      "/tmp/ipykernel_5540/2095016937.py:45: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n"
     ]
    }
   ],
   "source": [
    "performances = pd.DataFrame(index=pd.MultiIndex.from_product(\n",
    "    [[\"logistic\", \"svm\", \"random forest\"], [\"train\", \"test\"], [\"P\", \"F\"], [False, True], [False, True]],\n",
    "    names=[\"method\", \"section\", \"token\", \"lemma\", \"pos\"])\n",
    ")\n",
    "\n",
    "for method in [\"logistic\", \"svm\", \"random forest\"]:\n",
    "    for token in [\"P\", \"F\"]:\n",
    "        for lemma in [False, True]:\n",
    "            for pos in [False, True]:\n",
    "                # get the appropriate columns and to string functions\n",
    "                Classifier = {\n",
    "                    \"logistic\": LogisticRegression,\n",
    "                    \"svm\": SVC,\n",
    "                    \"random forest\": RandomForestClassifier\n",
    "                }[method]\n",
    "\n",
    "                train_column = TRAIN_DATASET[\"Plain Words\" if token == \"P\" else \"Fancy Words\"]\n",
    "                test_column = TEST_DATASET[\"Plain Words\" if token == \"P\" else \"Fancy Words\"]\n",
    "\n",
    "                tok_to_string = lemmas_to_string if lemma else words_to_string\n",
    "\n",
    "                # create the TF-IDF vectorizer\n",
    "                tok_vectorizer = TfidfVectorizer(tokenizer=str.split, stop_words=\"english\")\n",
    "\n",
    "                train_x = tok_vectorizer.fit_transform(train_column.apply(tok_to_string))\n",
    "                test_x = tok_vectorizer.transform(test_column.apply(tok_to_string))\n",
    "\n",
    "                # attach POS feature if needed\n",
    "                if pos:\n",
    "                    pos_vectorizer = CountVectorizer(tokenizer=str.split)\n",
    "                    transformer = QuantileTransformer()\n",
    "\n",
    "                    train_x = hstack((train_x, transformer.fit_transform(pos_vectorizer.fit_transform(train_column.apply(poses_to_string)))))\n",
    "                    test_x = hstack((test_x, transformer.transform(pos_vectorizer.transform(test_column.apply(poses_to_string)))))\n",
    "\n",
    "                # training and evaluating\n",
    "                for dimension in AGGREGATED.columns[4:4 + 15]:\n",
    "                    model = Classifier()\n",
    "                    model.fit(train_x, TRAIN_DATASET[dimension])\n",
    "\n",
    "                    train_score = model.score(train_x, TRAIN_DATASET[dimension])\n",
    "                    test_score = model.score(test_x, TEST_DATASET[dimension])\n",
    "\n",
    "                    performances.loc[(method, \"train\", token, lemma, pos), dimension] = train_score\n",
    "                    performances.loc[(method, \"test\", token, lemma, pos), dimension] = test_score\n",
    "\n",
    "performances[\"AVG\"] = performances.mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_b8b3d_row0_col0, #T_b8b3d_row2_col10, #T_b8b3d_row3_col12, #T_b8b3d_row4_col0, #T_b8b3d_row7_col12 {\n",
       "  background-color: #3c8cc3;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b8b3d_row0_col1 {\n",
       "  background-color: #a0cbe2;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b8b3d_row0_col2, #T_b8b3d_row3_col0, #T_b8b3d_row5_col0, #T_b8b3d_row6_col3 {\n",
       "  background-color: #6aaed6;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b8b3d_row0_col3, #T_b8b3d_row4_col3 {\n",
       "  background-color: #4090c5;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b8b3d_row0_col4 {\n",
       "  background-color: #3e8ec4;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b8b3d_row0_col5, #T_b8b3d_row3_col5, #T_b8b3d_row4_col5, #T_b8b3d_row4_col9, #T_b8b3d_row5_col5, #T_b8b3d_row6_col5, #T_b8b3d_row7_col9 {\n",
       "  background-color: #74b3d8;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b8b3d_row0_col6, #T_b8b3d_row4_col6, #T_b8b3d_row9_col2 {\n",
       "  background-color: #f0f6fd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b8b3d_row0_col7, #T_b8b3d_row4_col7 {\n",
       "  background-color: #a6cee4;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b8b3d_row0_col8 {\n",
       "  background-color: #bdd7ec;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b8b3d_row0_col9 {\n",
       "  background-color: #7ab6d9;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b8b3d_row0_col10, #T_b8b3d_row4_col10, #T_b8b3d_row8_col6, #T_b8b3d_row12_col6 {\n",
       "  background-color: #3888c1;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b8b3d_row0_col11, #T_b8b3d_row1_col15 {\n",
       "  background-color: #5aa2cf;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b8b3d_row0_col12 {\n",
       "  background-color: #9ac8e0;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b8b3d_row0_col13, #T_b8b3d_row4_col13, #T_b8b3d_row6_col13 {\n",
       "  background-color: #c2d9ee;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b8b3d_row0_col14, #T_b8b3d_row1_col1, #T_b8b3d_row1_col14, #T_b8b3d_row2_col14, #T_b8b3d_row3_col11, #T_b8b3d_row5_col14 {\n",
       "  background-color: #4a98c9;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b8b3d_row0_col15 {\n",
       "  background-color: #82bbdb;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b8b3d_row1_col0 {\n",
       "  background-color: #5ba3d0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b8b3d_row1_col2, #T_b8b3d_row1_col7, #T_b8b3d_row3_col7, #T_b8b3d_row3_col15, #T_b8b3d_row5_col2, #T_b8b3d_row5_col7 {\n",
       "  background-color: #5fa6d1;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b8b3d_row1_col3, #T_b8b3d_row3_col3 {\n",
       "  background-color: #8fc2de;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b8b3d_row1_col4, #T_b8b3d_row5_col4 {\n",
       "  background-color: #6caed6;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b8b3d_row1_col5, #T_b8b3d_row1_col9, #T_b8b3d_row2_col3, #T_b8b3d_row2_col5 {\n",
       "  background-color: #64a9d3;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b8b3d_row1_col6, #T_b8b3d_row3_col9, #T_b8b3d_row5_col6 {\n",
       "  background-color: #7fb9da;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b8b3d_row1_col8, #T_b8b3d_row3_col8 {\n",
       "  background-color: #66abd4;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b8b3d_row1_col10, #T_b8b3d_row5_col10 {\n",
       "  background-color: #3484bf;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b8b3d_row1_col11, #T_b8b3d_row5_col11 {\n",
       "  background-color: #4493c7;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b8b3d_row1_col12, #T_b8b3d_row6_col10 {\n",
       "  background-color: #3f8fc5;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b8b3d_row1_col13, #T_b8b3d_row7_col13 {\n",
       "  background-color: #519ccc;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b8b3d_row2_col0, #T_b8b3d_row6_col0 {\n",
       "  background-color: #4695c8;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b8b3d_row2_col1 {\n",
       "  background-color: #aed1e7;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b8b3d_row2_col2, #T_b8b3d_row4_col2, #T_b8b3d_row4_col11, #T_b8b3d_row7_col0, #T_b8b3d_row7_col2 {\n",
       "  background-color: #72b2d8;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b8b3d_row2_col4, #T_b8b3d_row5_col1 {\n",
       "  background-color: #60a7d2;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b8b3d_row2_col6, #T_b8b3d_row6_col6, #T_b8b3d_row9_col0, #T_b8b3d_row11_col0, #T_b8b3d_row11_col13, #T_b8b3d_row13_col13 {\n",
       "  background-color: #f4f9fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b8b3d_row2_col7 {\n",
       "  background-color: #bad6eb;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b8b3d_row2_col8 {\n",
       "  background-color: #c1d9ed;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b8b3d_row2_col9 {\n",
       "  background-color: #92c4de;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b8b3d_row2_col11, #T_b8b3d_row3_col4, #T_b8b3d_row6_col11 {\n",
       "  background-color: #81badb;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b8b3d_row2_col12 {\n",
       "  background-color: #bfd8ed;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b8b3d_row2_col13 {\n",
       "  background-color: #c7dcef;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b8b3d_row2_col15, #T_b8b3d_row4_col1, #T_b8b3d_row6_col9, #T_b8b3d_row7_col3 {\n",
       "  background-color: #97c6df;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b8b3d_row3_col1, #T_b8b3d_row5_col15, #T_b8b3d_row7_col1, #T_b8b3d_row7_col7 {\n",
       "  background-color: #5ca4d0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b8b3d_row3_col2, #T_b8b3d_row6_col4 {\n",
       "  background-color: #65aad4;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b8b3d_row3_col6, #T_b8b3d_row4_col15, #T_b8b3d_row5_col3 {\n",
       "  background-color: #85bcdc;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b8b3d_row3_col10, #T_b8b3d_row7_col10, #T_b8b3d_row8_col14, #T_b8b3d_row10_col3, #T_b8b3d_row14_col3 {\n",
       "  background-color: #2a7ab9;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b8b3d_row3_col13, #T_b8b3d_row5_col13 {\n",
       "  background-color: #4b98ca;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b8b3d_row3_col14 {\n",
       "  background-color: #549fcd;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b8b3d_row4_col4 {\n",
       "  background-color: #3585bf;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b8b3d_row4_col8 {\n",
       "  background-color: #c4daee;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b8b3d_row4_col12 {\n",
       "  background-color: #a9cfe5;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b8b3d_row4_col14 {\n",
       "  background-color: #4594c7;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b8b3d_row5_col8 {\n",
       "  background-color: #71b1d7;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b8b3d_row5_col9 {\n",
       "  background-color: #6dafd7;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b8b3d_row5_col12 {\n",
       "  background-color: #3989c1;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b8b3d_row6_col1 {\n",
       "  background-color: #a4cce3;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b8b3d_row6_col2 {\n",
       "  background-color: #89bedc;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b8b3d_row6_col7 {\n",
       "  background-color: #b7d4ea;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b8b3d_row6_col8 {\n",
       "  background-color: #cee0f2;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b8b3d_row6_col12 {\n",
       "  background-color: #c6dbef;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b8b3d_row6_col14, #T_b8b3d_row7_col14 {\n",
       "  background-color: #4f9bcb;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b8b3d_row6_col15 {\n",
       "  background-color: #9cc9e1;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b8b3d_row7_col4 {\n",
       "  background-color: #79b5d9;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b8b3d_row7_col5 {\n",
       "  background-color: #7cb7da;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b8b3d_row7_col6 {\n",
       "  background-color: #95c5df;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b8b3d_row7_col8 {\n",
       "  background-color: #75b4d8;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b8b3d_row7_col11 {\n",
       "  background-color: #4896c8;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b8b3d_row7_col15 {\n",
       "  background-color: #61a7d2;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b8b3d_row8_col0, #T_b8b3d_row14_col10 {\n",
       "  background-color: #1c6ab0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b8b3d_row8_col1, #T_b8b3d_row12_col1 {\n",
       "  background-color: #084c95;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b8b3d_row8_col2, #T_b8b3d_row12_col2 {\n",
       "  background-color: #125ea6;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b8b3d_row8_col3, #T_b8b3d_row12_col3 {\n",
       "  background-color: #2373b6;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b8b3d_row8_col4 {\n",
       "  background-color: #1561a9;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b8b3d_row8_col5, #T_b8b3d_row10_col5 {\n",
       "  background-color: #08519c;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b8b3d_row8_col7, #T_b8b3d_row12_col5 {\n",
       "  background-color: #084b93;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b8b3d_row8_col8, #T_b8b3d_row10_col8, #T_b8b3d_row12_col7 {\n",
       "  background-color: #08509b;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b8b3d_row8_col9, #T_b8b3d_row10_col9, #T_b8b3d_row12_col9, #T_b8b3d_row14_col9 {\n",
       "  background-color: #2777b8;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b8b3d_row8_col10, #T_b8b3d_row14_col2 {\n",
       "  background-color: #1663aa;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b8b3d_row8_col11 {\n",
       "  background-color: #083877;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b8b3d_row8_col12 {\n",
       "  background-color: #083a7a;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b8b3d_row8_col13 {\n",
       "  background-color: #08478d;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b8b3d_row8_col15 {\n",
       "  background-color: #0e59a2;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b8b3d_row9_col1, #T_b8b3d_row13_col0, #T_b8b3d_row15_col4, #T_b8b3d_row15_col14 {\n",
       "  background-color: #f1f7fd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b8b3d_row9_col3, #T_b8b3d_row11_col3 {\n",
       "  background-color: #e6f0f9;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b8b3d_row9_col4, #T_b8b3d_row9_col6, #T_b8b3d_row9_col7, #T_b8b3d_row9_col9, #T_b8b3d_row9_col12, #T_b8b3d_row9_col13, #T_b8b3d_row9_col14, #T_b8b3d_row9_col15, #T_b8b3d_row11_col2, #T_b8b3d_row11_col4, #T_b8b3d_row11_col5, #T_b8b3d_row11_col6, #T_b8b3d_row11_col7, #T_b8b3d_row11_col9, #T_b8b3d_row11_col10, #T_b8b3d_row11_col14, #T_b8b3d_row11_col15, #T_b8b3d_row13_col3, #T_b8b3d_row13_col6, #T_b8b3d_row13_col7, #T_b8b3d_row13_col8, #T_b8b3d_row13_col11, #T_b8b3d_row15_col0, #T_b8b3d_row15_col1, #T_b8b3d_row15_col3, #T_b8b3d_row15_col6, #T_b8b3d_row15_col7 {\n",
       "  background-color: #f7fbff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b8b3d_row9_col5, #T_b8b3d_row11_col1 {\n",
       "  background-color: #f3f8fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b8b3d_row9_col8, #T_b8b3d_row9_col10, #T_b8b3d_row13_col10, #T_b8b3d_row13_col15, #T_b8b3d_row15_col8, #T_b8b3d_row15_col15 {\n",
       "  background-color: #f5f9fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b8b3d_row9_col11, #T_b8b3d_row11_col11, #T_b8b3d_row11_col12, #T_b8b3d_row13_col1, #T_b8b3d_row15_col11 {\n",
       "  background-color: #f5fafe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b8b3d_row10_col0, #T_b8b3d_row14_col0 {\n",
       "  background-color: #3080bd;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b8b3d_row10_col1, #T_b8b3d_row10_col7, #T_b8b3d_row14_col7 {\n",
       "  background-color: #0b559f;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b8b3d_row10_col2 {\n",
       "  background-color: #0f5aa3;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b8b3d_row10_col4, #T_b8b3d_row12_col4 {\n",
       "  background-color: #1865ac;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b8b3d_row10_col6, #T_b8b3d_row14_col6 {\n",
       "  background-color: #3d8dc4;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b8b3d_row10_col10, #T_b8b3d_row12_col0, #T_b8b3d_row14_col4 {\n",
       "  background-color: #1f6eb3;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b8b3d_row10_col11 {\n",
       "  background-color: #08488e;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b8b3d_row10_col12 {\n",
       "  background-color: #08468b;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b8b3d_row10_col13 {\n",
       "  background-color: #1966ad;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b8b3d_row10_col14 {\n",
       "  background-color: #2e7ebc;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b8b3d_row10_col15 {\n",
       "  background-color: #1562a9;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b8b3d_row11_col8 {\n",
       "  background-color: #f2f8fd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b8b3d_row12_col8 {\n",
       "  background-color: #0a539e;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b8b3d_row12_col10, #T_b8b3d_row14_col15 {\n",
       "  background-color: #1967ad;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b8b3d_row12_col11 {\n",
       "  background-color: #083b7c;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b8b3d_row12_col12 {\n",
       "  background-color: #084184;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b8b3d_row12_col13 {\n",
       "  background-color: #0a549e;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b8b3d_row12_col14 {\n",
       "  background-color: #2575b7;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b8b3d_row12_col15 {\n",
       "  background-color: #115ca5;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b8b3d_row13_col2, #T_b8b3d_row15_col2, #T_b8b3d_row15_col13 {\n",
       "  background-color: #edf4fc;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b8b3d_row13_col4, #T_b8b3d_row13_col14 {\n",
       "  background-color: #eaf2fb;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b8b3d_row13_col5, #T_b8b3d_row15_col5 {\n",
       "  background-color: #ebf3fb;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b8b3d_row13_col9, #T_b8b3d_row15_col10 {\n",
       "  background-color: #f2f7fd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b8b3d_row13_col12, #T_b8b3d_row15_col12 {\n",
       "  background-color: #eff6fc;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b8b3d_row14_col1 {\n",
       "  background-color: #0d57a1;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b8b3d_row14_col5, #T_b8b3d_row14_col8, #T_b8b3d_row14_col12 {\n",
       "  background-color: #0c56a0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b8b3d_row14_col11 {\n",
       "  background-color: #084e98;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b8b3d_row14_col13 {\n",
       "  background-color: #2474b7;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b8b3d_row14_col14 {\n",
       "  background-color: #3787c0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b8b3d_row15_col9 {\n",
       "  background-color: #eef5fc;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b8b3d_row16_col0, #T_b8b3d_row16_col1, #T_b8b3d_row16_col2, #T_b8b3d_row16_col3, #T_b8b3d_row16_col4, #T_b8b3d_row16_col5, #T_b8b3d_row16_col6, #T_b8b3d_row16_col7, #T_b8b3d_row16_col8, #T_b8b3d_row16_col9, #T_b8b3d_row16_col10, #T_b8b3d_row16_col11, #T_b8b3d_row16_col12, #T_b8b3d_row16_col13, #T_b8b3d_row16_col14, #T_b8b3d_row16_col15, #T_b8b3d_row17_col0, #T_b8b3d_row17_col1, #T_b8b3d_row17_col2, #T_b8b3d_row17_col3, #T_b8b3d_row17_col4, #T_b8b3d_row17_col5, #T_b8b3d_row17_col6, #T_b8b3d_row17_col7, #T_b8b3d_row17_col8, #T_b8b3d_row17_col9, #T_b8b3d_row17_col10, #T_b8b3d_row17_col11, #T_b8b3d_row17_col12, #T_b8b3d_row17_col13, #T_b8b3d_row17_col14, #T_b8b3d_row17_col15, #T_b8b3d_row18_col0, #T_b8b3d_row18_col1, #T_b8b3d_row18_col2, #T_b8b3d_row18_col3, #T_b8b3d_row18_col4, #T_b8b3d_row18_col5, #T_b8b3d_row18_col6, #T_b8b3d_row18_col7, #T_b8b3d_row18_col8, #T_b8b3d_row18_col9, #T_b8b3d_row18_col10, #T_b8b3d_row18_col11, #T_b8b3d_row18_col12, #T_b8b3d_row18_col13, #T_b8b3d_row18_col14, #T_b8b3d_row18_col15, #T_b8b3d_row19_col0, #T_b8b3d_row19_col1, #T_b8b3d_row19_col2, #T_b8b3d_row19_col3, #T_b8b3d_row19_col4, #T_b8b3d_row19_col5, #T_b8b3d_row19_col6, #T_b8b3d_row19_col7, #T_b8b3d_row19_col8, #T_b8b3d_row19_col9, #T_b8b3d_row19_col10, #T_b8b3d_row19_col11, #T_b8b3d_row19_col12, #T_b8b3d_row19_col13, #T_b8b3d_row19_col14, #T_b8b3d_row19_col15, #T_b8b3d_row20_col0, #T_b8b3d_row20_col1, #T_b8b3d_row20_col2, #T_b8b3d_row20_col3, #T_b8b3d_row20_col4, #T_b8b3d_row20_col5, #T_b8b3d_row20_col6, #T_b8b3d_row20_col7, #T_b8b3d_row20_col8, #T_b8b3d_row20_col9, #T_b8b3d_row20_col10, #T_b8b3d_row20_col11, #T_b8b3d_row20_col12, #T_b8b3d_row20_col13, #T_b8b3d_row20_col14, #T_b8b3d_row20_col15, #T_b8b3d_row21_col0, #T_b8b3d_row21_col1, #T_b8b3d_row21_col2, #T_b8b3d_row21_col3, #T_b8b3d_row21_col4, #T_b8b3d_row21_col5, #T_b8b3d_row21_col6, #T_b8b3d_row21_col7, #T_b8b3d_row21_col8, #T_b8b3d_row21_col9, #T_b8b3d_row21_col10, #T_b8b3d_row21_col11, #T_b8b3d_row21_col12, #T_b8b3d_row21_col13, #T_b8b3d_row21_col14, #T_b8b3d_row21_col15, #T_b8b3d_row22_col0, #T_b8b3d_row22_col2, #T_b8b3d_row22_col3, #T_b8b3d_row22_col4, #T_b8b3d_row22_col5, #T_b8b3d_row22_col6, #T_b8b3d_row22_col7, #T_b8b3d_row22_col8, #T_b8b3d_row22_col9, #T_b8b3d_row22_col10, #T_b8b3d_row22_col11, #T_b8b3d_row22_col12, #T_b8b3d_row22_col13, #T_b8b3d_row22_col14, #T_b8b3d_row22_col15, #T_b8b3d_row23_col0, #T_b8b3d_row23_col1, #T_b8b3d_row23_col2, #T_b8b3d_row23_col3, #T_b8b3d_row23_col4, #T_b8b3d_row23_col5, #T_b8b3d_row23_col6, #T_b8b3d_row23_col7, #T_b8b3d_row23_col8, #T_b8b3d_row23_col9, #T_b8b3d_row23_col10, #T_b8b3d_row23_col11, #T_b8b3d_row23_col12, #T_b8b3d_row23_col13, #T_b8b3d_row23_col14, #T_b8b3d_row23_col15 {\n",
       "  background-color: #08306b;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b8b3d_row22_col1 {\n",
       "  background-color: #08326e;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_b8b3d\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank\" >&nbsp;</th>\n",
       "      <th class=\"blank\" >&nbsp;</th>\n",
       "      <th class=\"blank\" >&nbsp;</th>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_b8b3d_level0_col0\" class=\"col_heading level0 col0\" >CO</th>\n",
       "      <th id=\"T_b8b3d_level0_col1\" class=\"col_heading level0 col1\" >LA</th>\n",
       "      <th id=\"T_b8b3d_level0_col2\" class=\"col_heading level0 col2\" >LR</th>\n",
       "      <th id=\"T_b8b3d_level0_col3\" class=\"col_heading level0 col3\" >LS</th>\n",
       "      <th id=\"T_b8b3d_level0_col4\" class=\"col_heading level0 col4\" >EF</th>\n",
       "      <th id=\"T_b8b3d_level0_col5\" class=\"col_heading level0 col5\" >CR</th>\n",
       "      <th id=\"T_b8b3d_level0_col6\" class=\"col_heading level0 col6\" >EM</th>\n",
       "      <th id=\"T_b8b3d_level0_col7\" class=\"col_heading level0 col7\" >CL</th>\n",
       "      <th id=\"T_b8b3d_level0_col8\" class=\"col_heading level0 col8\" >AP</th>\n",
       "      <th id=\"T_b8b3d_level0_col9\" class=\"col_heading level0 col9\" >AR</th>\n",
       "      <th id=\"T_b8b3d_level0_col10\" class=\"col_heading level0 col10\" >RE</th>\n",
       "      <th id=\"T_b8b3d_level0_col11\" class=\"col_heading level0 col11\" >GA</th>\n",
       "      <th id=\"T_b8b3d_level0_col12\" class=\"col_heading level0 col12\" >GR</th>\n",
       "      <th id=\"T_b8b3d_level0_col13\" class=\"col_heading level0 col13\" >GS</th>\n",
       "      <th id=\"T_b8b3d_level0_col14\" class=\"col_heading level0 col14\" >OV</th>\n",
       "      <th id=\"T_b8b3d_level0_col15\" class=\"col_heading level0 col15\" >AVG</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >method</th>\n",
       "      <th class=\"index_name level1\" >token</th>\n",
       "      <th class=\"index_name level2\" >lemma</th>\n",
       "      <th class=\"index_name level3\" >pos</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "      <th class=\"blank col1\" >&nbsp;</th>\n",
       "      <th class=\"blank col2\" >&nbsp;</th>\n",
       "      <th class=\"blank col3\" >&nbsp;</th>\n",
       "      <th class=\"blank col4\" >&nbsp;</th>\n",
       "      <th class=\"blank col5\" >&nbsp;</th>\n",
       "      <th class=\"blank col6\" >&nbsp;</th>\n",
       "      <th class=\"blank col7\" >&nbsp;</th>\n",
       "      <th class=\"blank col8\" >&nbsp;</th>\n",
       "      <th class=\"blank col9\" >&nbsp;</th>\n",
       "      <th class=\"blank col10\" >&nbsp;</th>\n",
       "      <th class=\"blank col11\" >&nbsp;</th>\n",
       "      <th class=\"blank col12\" >&nbsp;</th>\n",
       "      <th class=\"blank col13\" >&nbsp;</th>\n",
       "      <th class=\"blank col14\" >&nbsp;</th>\n",
       "      <th class=\"blank col15\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_b8b3d_level0_row0\" class=\"row_heading level0 row0\" rowspan=\"8\">logistic</th>\n",
       "      <th id=\"T_b8b3d_level1_row0\" class=\"row_heading level1 row0\" rowspan=\"4\">P</th>\n",
       "      <th id=\"T_b8b3d_level2_row0\" class=\"row_heading level2 row0\" rowspan=\"2\">False</th>\n",
       "      <th id=\"T_b8b3d_level3_row0\" class=\"row_heading level3 row0\" >False</th>\n",
       "      <td id=\"T_b8b3d_row0_col0\" class=\"data row0 col0\" >90.91%</td>\n",
       "      <td id=\"T_b8b3d_row0_col1\" class=\"data row0 col1\" >76.03%</td>\n",
       "      <td id=\"T_b8b3d_row0_col2\" class=\"data row0 col2\" >88.43%</td>\n",
       "      <td id=\"T_b8b3d_row0_col3\" class=\"data row0 col3\" >92.98%</td>\n",
       "      <td id=\"T_b8b3d_row0_col4\" class=\"data row0 col4\" >91.32%</td>\n",
       "      <td id=\"T_b8b3d_row0_col5\" class=\"data row0 col5\" >89.67%</td>\n",
       "      <td id=\"T_b8b3d_row0_col6\" class=\"data row0 col6\" >78.93%</td>\n",
       "      <td id=\"T_b8b3d_row0_col7\" class=\"data row0 col7\" >73.97%</td>\n",
       "      <td id=\"T_b8b3d_row0_col8\" class=\"data row0 col8\" >75.62%</td>\n",
       "      <td id=\"T_b8b3d_row0_col9\" class=\"data row0 col9\" >84.71%</td>\n",
       "      <td id=\"T_b8b3d_row0_col10\" class=\"data row0 col10\" >90.08%</td>\n",
       "      <td id=\"T_b8b3d_row0_col11\" class=\"data row0 col11\" >83.88%</td>\n",
       "      <td id=\"T_b8b3d_row0_col12\" class=\"data row0 col12\" >75.62%</td>\n",
       "      <td id=\"T_b8b3d_row0_col13\" class=\"data row0 col13\" >82.64%</td>\n",
       "      <td id=\"T_b8b3d_row0_col14\" class=\"data row0 col14\" >90.08%</td>\n",
       "      <td id=\"T_b8b3d_row0_col15\" class=\"data row0 col15\" >84.33%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b8b3d_level3_row1\" class=\"row_heading level3 row1\" >True</th>\n",
       "      <td id=\"T_b8b3d_row1_col0\" class=\"data row1 col0\" >88.43%</td>\n",
       "      <td id=\"T_b8b3d_row1_col1\" class=\"data row1 col1\" >84.71%</td>\n",
       "      <td id=\"T_b8b3d_row1_col2\" class=\"data row1 col2\" >89.26%</td>\n",
       "      <td id=\"T_b8b3d_row1_col3\" class=\"data row1 col3\" >88.84%</td>\n",
       "      <td id=\"T_b8b3d_row1_col4\" class=\"data row1 col4\" >88.02%</td>\n",
       "      <td id=\"T_b8b3d_row1_col5\" class=\"data row1 col5\" >90.50%</td>\n",
       "      <td id=\"T_b8b3d_row1_col6\" class=\"data row1 col6\" >88.02%</td>\n",
       "      <td id=\"T_b8b3d_row1_col7\" class=\"data row1 col7\" >81.40%</td>\n",
       "      <td id=\"T_b8b3d_row1_col8\" class=\"data row1 col8\" >83.47%</td>\n",
       "      <td id=\"T_b8b3d_row1_col9\" class=\"data row1 col9\" >86.36%</td>\n",
       "      <td id=\"T_b8b3d_row1_col10\" class=\"data row1 col10\" >90.50%</td>\n",
       "      <td id=\"T_b8b3d_row1_col11\" class=\"data row1 col11\" >86.36%</td>\n",
       "      <td id=\"T_b8b3d_row1_col12\" class=\"data row1 col12\" >85.54%</td>\n",
       "      <td id=\"T_b8b3d_row1_col13\" class=\"data row1 col13\" >90.08%</td>\n",
       "      <td id=\"T_b8b3d_row1_col14\" class=\"data row1 col14\" >90.08%</td>\n",
       "      <td id=\"T_b8b3d_row1_col15\" class=\"data row1 col15\" >87.44%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b8b3d_level2_row2\" class=\"row_heading level2 row2\" rowspan=\"2\">True</th>\n",
       "      <th id=\"T_b8b3d_level3_row2\" class=\"row_heading level3 row2\" >False</th>\n",
       "      <td id=\"T_b8b3d_row2_col0\" class=\"data row2 col0\" >90.08%</td>\n",
       "      <td id=\"T_b8b3d_row2_col1\" class=\"data row2 col1\" >74.38%</td>\n",
       "      <td id=\"T_b8b3d_row2_col2\" class=\"data row2 col2\" >88.02%</td>\n",
       "      <td id=\"T_b8b3d_row2_col3\" class=\"data row2 col3\" >90.91%</td>\n",
       "      <td id=\"T_b8b3d_row2_col4\" class=\"data row2 col4\" >88.84%</td>\n",
       "      <td id=\"T_b8b3d_row2_col5\" class=\"data row2 col5\" >90.50%</td>\n",
       "      <td id=\"T_b8b3d_row2_col6\" class=\"data row2 col6\" >78.51%</td>\n",
       "      <td id=\"T_b8b3d_row2_col7\" class=\"data row2 col7\" >71.49%</td>\n",
       "      <td id=\"T_b8b3d_row2_col8\" class=\"data row2 col8\" >75.21%</td>\n",
       "      <td id=\"T_b8b3d_row2_col9\" class=\"data row2 col9\" >83.06%</td>\n",
       "      <td id=\"T_b8b3d_row2_col10\" class=\"data row2 col10\" >89.67%</td>\n",
       "      <td id=\"T_b8b3d_row2_col11\" class=\"data row2 col11\" >80.17%</td>\n",
       "      <td id=\"T_b8b3d_row2_col12\" class=\"data row2 col12\" >71.07%</td>\n",
       "      <td id=\"T_b8b3d_row2_col13\" class=\"data row2 col13\" >82.23%</td>\n",
       "      <td id=\"T_b8b3d_row2_col14\" class=\"data row2 col14\" >90.08%</td>\n",
       "      <td id=\"T_b8b3d_row2_col15\" class=\"data row2 col15\" >82.95%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b8b3d_level3_row3\" class=\"row_heading level3 row3\" >True</th>\n",
       "      <td id=\"T_b8b3d_row3_col0\" class=\"data row3 col0\" >87.19%</td>\n",
       "      <td id=\"T_b8b3d_row3_col1\" class=\"data row3 col1\" >82.64%</td>\n",
       "      <td id=\"T_b8b3d_row3_col2\" class=\"data row3 col2\" >88.84%</td>\n",
       "      <td id=\"T_b8b3d_row3_col3\" class=\"data row3 col3\" >88.84%</td>\n",
       "      <td id=\"T_b8b3d_row3_col4\" class=\"data row3 col4\" >86.78%</td>\n",
       "      <td id=\"T_b8b3d_row3_col5\" class=\"data row3 col5\" >89.67%</td>\n",
       "      <td id=\"T_b8b3d_row3_col6\" class=\"data row3 col6\" >87.60%</td>\n",
       "      <td id=\"T_b8b3d_row3_col7\" class=\"data row3 col7\" >81.40%</td>\n",
       "      <td id=\"T_b8b3d_row3_col8\" class=\"data row3 col8\" >83.47%</td>\n",
       "      <td id=\"T_b8b3d_row3_col9\" class=\"data row3 col9\" >84.30%</td>\n",
       "      <td id=\"T_b8b3d_row3_col10\" class=\"data row3 col10\" >91.74%</td>\n",
       "      <td id=\"T_b8b3d_row3_col11\" class=\"data row3 col11\" >85.54%</td>\n",
       "      <td id=\"T_b8b3d_row3_col12\" class=\"data row3 col12\" >85.95%</td>\n",
       "      <td id=\"T_b8b3d_row3_col13\" class=\"data row3 col13\" >90.50%</td>\n",
       "      <td id=\"T_b8b3d_row3_col14\" class=\"data row3 col14\" >89.26%</td>\n",
       "      <td id=\"T_b8b3d_row3_col15\" class=\"data row3 col15\" >86.91%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b8b3d_level1_row4\" class=\"row_heading level1 row4\" rowspan=\"4\">F</th>\n",
       "      <th id=\"T_b8b3d_level2_row4\" class=\"row_heading level2 row4\" rowspan=\"2\">False</th>\n",
       "      <th id=\"T_b8b3d_level3_row4\" class=\"row_heading level3 row4\" >False</th>\n",
       "      <td id=\"T_b8b3d_row4_col0\" class=\"data row4 col0\" >90.91%</td>\n",
       "      <td id=\"T_b8b3d_row4_col1\" class=\"data row4 col1\" >76.86%</td>\n",
       "      <td id=\"T_b8b3d_row4_col2\" class=\"data row4 col2\" >88.02%</td>\n",
       "      <td id=\"T_b8b3d_row4_col3\" class=\"data row4 col3\" >92.98%</td>\n",
       "      <td id=\"T_b8b3d_row4_col4\" class=\"data row4 col4\" >92.15%</td>\n",
       "      <td id=\"T_b8b3d_row4_col5\" class=\"data row4 col5\" >89.67%</td>\n",
       "      <td id=\"T_b8b3d_row4_col6\" class=\"data row4 col6\" >78.93%</td>\n",
       "      <td id=\"T_b8b3d_row4_col7\" class=\"data row4 col7\" >73.97%</td>\n",
       "      <td id=\"T_b8b3d_row4_col8\" class=\"data row4 col8\" >74.79%</td>\n",
       "      <td id=\"T_b8b3d_row4_col9\" class=\"data row4 col9\" >85.12%</td>\n",
       "      <td id=\"T_b8b3d_row4_col10\" class=\"data row4 col10\" >90.08%</td>\n",
       "      <td id=\"T_b8b3d_row4_col11\" class=\"data row4 col11\" >81.40%</td>\n",
       "      <td id=\"T_b8b3d_row4_col12\" class=\"data row4 col12\" >73.97%</td>\n",
       "      <td id=\"T_b8b3d_row4_col13\" class=\"data row4 col13\" >82.64%</td>\n",
       "      <td id=\"T_b8b3d_row4_col14\" class=\"data row4 col14\" >90.50%</td>\n",
       "      <td id=\"T_b8b3d_row4_col15\" class=\"data row4 col15\" >84.13%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b8b3d_level3_row5\" class=\"row_heading level3 row5\" >True</th>\n",
       "      <td id=\"T_b8b3d_row5_col0\" class=\"data row5 col0\" >87.19%</td>\n",
       "      <td id=\"T_b8b3d_row5_col1\" class=\"data row5 col1\" >82.23%</td>\n",
       "      <td id=\"T_b8b3d_row5_col2\" class=\"data row5 col2\" >89.26%</td>\n",
       "      <td id=\"T_b8b3d_row5_col3\" class=\"data row5 col3\" >89.26%</td>\n",
       "      <td id=\"T_b8b3d_row5_col4\" class=\"data row5 col4\" >88.02%</td>\n",
       "      <td id=\"T_b8b3d_row5_col5\" class=\"data row5 col5\" >89.67%</td>\n",
       "      <td id=\"T_b8b3d_row5_col6\" class=\"data row5 col6\" >88.02%</td>\n",
       "      <td id=\"T_b8b3d_row5_col7\" class=\"data row5 col7\" >81.40%</td>\n",
       "      <td id=\"T_b8b3d_row5_col8\" class=\"data row5 col8\" >82.64%</td>\n",
       "      <td id=\"T_b8b3d_row5_col9\" class=\"data row5 col9\" >85.54%</td>\n",
       "      <td id=\"T_b8b3d_row5_col10\" class=\"data row5 col10\" >90.50%</td>\n",
       "      <td id=\"T_b8b3d_row5_col11\" class=\"data row5 col11\" >86.36%</td>\n",
       "      <td id=\"T_b8b3d_row5_col12\" class=\"data row5 col12\" >86.36%</td>\n",
       "      <td id=\"T_b8b3d_row5_col13\" class=\"data row5 col13\" >90.50%</td>\n",
       "      <td id=\"T_b8b3d_row5_col14\" class=\"data row5 col14\" >90.08%</td>\n",
       "      <td id=\"T_b8b3d_row5_col15\" class=\"data row5 col15\" >87.13%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b8b3d_level2_row6\" class=\"row_heading level2 row6\" rowspan=\"2\">True</th>\n",
       "      <th id=\"T_b8b3d_level3_row6\" class=\"row_heading level3 row6\" >False</th>\n",
       "      <td id=\"T_b8b3d_row6_col0\" class=\"data row6 col0\" >90.08%</td>\n",
       "      <td id=\"T_b8b3d_row6_col1\" class=\"data row6 col1\" >75.62%</td>\n",
       "      <td id=\"T_b8b3d_row6_col2\" class=\"data row6 col2\" >86.78%</td>\n",
       "      <td id=\"T_b8b3d_row6_col3\" class=\"data row6 col3\" >90.50%</td>\n",
       "      <td id=\"T_b8b3d_row6_col4\" class=\"data row6 col4\" >88.43%</td>\n",
       "      <td id=\"T_b8b3d_row6_col5\" class=\"data row6 col5\" >89.67%</td>\n",
       "      <td id=\"T_b8b3d_row6_col6\" class=\"data row6 col6\" >78.51%</td>\n",
       "      <td id=\"T_b8b3d_row6_col7\" class=\"data row6 col7\" >71.90%</td>\n",
       "      <td id=\"T_b8b3d_row6_col8\" class=\"data row6 col8\" >73.14%</td>\n",
       "      <td id=\"T_b8b3d_row6_col9\" class=\"data row6 col9\" >82.64%</td>\n",
       "      <td id=\"T_b8b3d_row6_col10\" class=\"data row6 col10\" >89.26%</td>\n",
       "      <td id=\"T_b8b3d_row6_col11\" class=\"data row6 col11\" >80.17%</td>\n",
       "      <td id=\"T_b8b3d_row6_col12\" class=\"data row6 col12\" >70.25%</td>\n",
       "      <td id=\"T_b8b3d_row6_col13\" class=\"data row6 col13\" >82.64%</td>\n",
       "      <td id=\"T_b8b3d_row6_col14\" class=\"data row6 col14\" >89.67%</td>\n",
       "      <td id=\"T_b8b3d_row6_col15\" class=\"data row6 col15\" >82.62%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b8b3d_level3_row7\" class=\"row_heading level3 row7\" >True</th>\n",
       "      <td id=\"T_b8b3d_row7_col0\" class=\"data row7 col0\" >86.78%</td>\n",
       "      <td id=\"T_b8b3d_row7_col1\" class=\"data row7 col1\" >82.64%</td>\n",
       "      <td id=\"T_b8b3d_row7_col2\" class=\"data row7 col2\" >88.02%</td>\n",
       "      <td id=\"T_b8b3d_row7_col3\" class=\"data row7 col3\" >88.43%</td>\n",
       "      <td id=\"T_b8b3d_row7_col4\" class=\"data row7 col4\" >87.19%</td>\n",
       "      <td id=\"T_b8b3d_row7_col5\" class=\"data row7 col5\" >89.26%</td>\n",
       "      <td id=\"T_b8b3d_row7_col6\" class=\"data row7 col6\" >86.78%</td>\n",
       "      <td id=\"T_b8b3d_row7_col7\" class=\"data row7 col7\" >81.82%</td>\n",
       "      <td id=\"T_b8b3d_row7_col8\" class=\"data row7 col8\" >82.23%</td>\n",
       "      <td id=\"T_b8b3d_row7_col9\" class=\"data row7 col9\" >85.12%</td>\n",
       "      <td id=\"T_b8b3d_row7_col10\" class=\"data row7 col10\" >91.74%</td>\n",
       "      <td id=\"T_b8b3d_row7_col11\" class=\"data row7 col11\" >85.95%</td>\n",
       "      <td id=\"T_b8b3d_row7_col12\" class=\"data row7 col12\" >85.95%</td>\n",
       "      <td id=\"T_b8b3d_row7_col13\" class=\"data row7 col13\" >90.08%</td>\n",
       "      <td id=\"T_b8b3d_row7_col14\" class=\"data row7 col14\" >89.67%</td>\n",
       "      <td id=\"T_b8b3d_row7_col15\" class=\"data row7 col15\" >86.78%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b8b3d_level0_row8\" class=\"row_heading level0 row8\" rowspan=\"8\">svm</th>\n",
       "      <th id=\"T_b8b3d_level1_row8\" class=\"row_heading level1 row8\" rowspan=\"4\">P</th>\n",
       "      <th id=\"T_b8b3d_level2_row8\" class=\"row_heading level2 row8\" rowspan=\"2\">False</th>\n",
       "      <th id=\"T_b8b3d_level3_row8\" class=\"row_heading level3 row8\" >False</th>\n",
       "      <td id=\"T_b8b3d_row8_col0\" class=\"data row8 col0\" >94.21%</td>\n",
       "      <td id=\"T_b8b3d_row8_col1\" class=\"data row8 col1\" >95.87%</td>\n",
       "      <td id=\"T_b8b3d_row8_col2\" class=\"data row8 col2\" >95.87%</td>\n",
       "      <td id=\"T_b8b3d_row8_col3\" class=\"data row8 col3\" >95.04%</td>\n",
       "      <td id=\"T_b8b3d_row8_col4\" class=\"data row8 col4\" >95.45%</td>\n",
       "      <td id=\"T_b8b3d_row8_col5\" class=\"data row8 col5\" >97.52%</td>\n",
       "      <td id=\"T_b8b3d_row8_col6\" class=\"data row8 col6\" >92.56%</td>\n",
       "      <td id=\"T_b8b3d_row8_col7\" class=\"data row8 col7\" >95.87%</td>\n",
       "      <td id=\"T_b8b3d_row8_col8\" class=\"data row8 col8\" >95.87%</td>\n",
       "      <td id=\"T_b8b3d_row8_col9\" class=\"data row8 col9\" >92.15%</td>\n",
       "      <td id=\"T_b8b3d_row8_col10\" class=\"data row8 col10\" >94.21%</td>\n",
       "      <td id=\"T_b8b3d_row8_col11\" class=\"data row8 col11\" >98.76%</td>\n",
       "      <td id=\"T_b8b3d_row8_col12\" class=\"data row8 col12\" >98.35%</td>\n",
       "      <td id=\"T_b8b3d_row8_col13\" class=\"data row8 col13\" >97.93%</td>\n",
       "      <td id=\"T_b8b3d_row8_col14\" class=\"data row8 col14\" >92.98%</td>\n",
       "      <td id=\"T_b8b3d_row8_col15\" class=\"data row8 col15\" >95.51%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b8b3d_level3_row9\" class=\"row_heading level3 row9\" >True</th>\n",
       "      <td id=\"T_b8b3d_row9_col0\" class=\"data row9 col0\" >74.79%</td>\n",
       "      <td id=\"T_b8b3d_row9_col1\" class=\"data row9 col1\" >63.22%</td>\n",
       "      <td id=\"T_b8b3d_row9_col2\" class=\"data row9 col2\" >77.69%</td>\n",
       "      <td id=\"T_b8b3d_row9_col3\" class=\"data row9 col3\" >82.64%</td>\n",
       "      <td id=\"T_b8b3d_row9_col4\" class=\"data row9 col4\" >76.03%</td>\n",
       "      <td id=\"T_b8b3d_row9_col5\" class=\"data row9 col5\" >80.58%</td>\n",
       "      <td id=\"T_b8b3d_row9_col6\" class=\"data row9 col6\" >78.10%</td>\n",
       "      <td id=\"T_b8b3d_row9_col7\" class=\"data row9 col7\" >59.92%</td>\n",
       "      <td id=\"T_b8b3d_row9_col8\" class=\"data row9 col8\" >66.53%</td>\n",
       "      <td id=\"T_b8b3d_row9_col9\" class=\"data row9 col9\" >71.49%</td>\n",
       "      <td id=\"T_b8b3d_row9_col10\" class=\"data row9 col10\" >71.07%</td>\n",
       "      <td id=\"T_b8b3d_row9_col11\" class=\"data row9 col11\" >64.46%</td>\n",
       "      <td id=\"T_b8b3d_row9_col12\" class=\"data row9 col12\" >60.33%</td>\n",
       "      <td id=\"T_b8b3d_row9_col13\" class=\"data row9 col13\" >76.45%</td>\n",
       "      <td id=\"T_b8b3d_row9_col14\" class=\"data row9 col14\" >75.21%</td>\n",
       "      <td id=\"T_b8b3d_row9_col15\" class=\"data row9 col15\" >71.90%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b8b3d_level2_row10\" class=\"row_heading level2 row10\" rowspan=\"2\">True</th>\n",
       "      <th id=\"T_b8b3d_level3_row10\" class=\"row_heading level3 row10\" >False</th>\n",
       "      <td id=\"T_b8b3d_row10_col0\" class=\"data row10 col0\" >92.15%</td>\n",
       "      <td id=\"T_b8b3d_row10_col1\" class=\"data row10 col1\" >94.63%</td>\n",
       "      <td id=\"T_b8b3d_row10_col2\" class=\"data row10 col2\" >96.28%</td>\n",
       "      <td id=\"T_b8b3d_row10_col3\" class=\"data row10 col3\" >94.63%</td>\n",
       "      <td id=\"T_b8b3d_row10_col4\" class=\"data row10 col4\" >95.04%</td>\n",
       "      <td id=\"T_b8b3d_row10_col5\" class=\"data row10 col5\" >97.52%</td>\n",
       "      <td id=\"T_b8b3d_row10_col6\" class=\"data row10 col6\" >92.15%</td>\n",
       "      <td id=\"T_b8b3d_row10_col7\" class=\"data row10 col7\" >94.21%</td>\n",
       "      <td id=\"T_b8b3d_row10_col8\" class=\"data row10 col8\" >95.87%</td>\n",
       "      <td id=\"T_b8b3d_row10_col9\" class=\"data row10 col9\" >92.15%</td>\n",
       "      <td id=\"T_b8b3d_row10_col10\" class=\"data row10 col10\" >92.98%</td>\n",
       "      <td id=\"T_b8b3d_row10_col11\" class=\"data row10 col11\" >96.69%</td>\n",
       "      <td id=\"T_b8b3d_row10_col12\" class=\"data row10 col12\" >96.69%</td>\n",
       "      <td id=\"T_b8b3d_row10_col13\" class=\"data row10 col13\" >95.04%</td>\n",
       "      <td id=\"T_b8b3d_row10_col14\" class=\"data row10 col14\" >92.56%</td>\n",
       "      <td id=\"T_b8b3d_row10_col15\" class=\"data row10 col15\" >94.57%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b8b3d_level3_row11\" class=\"row_heading level3 row11\" >True</th>\n",
       "      <td id=\"T_b8b3d_row11_col0\" class=\"data row11 col0\" >74.79%</td>\n",
       "      <td id=\"T_b8b3d_row11_col1\" class=\"data row11 col1\" >62.81%</td>\n",
       "      <td id=\"T_b8b3d_row11_col2\" class=\"data row11 col2\" >76.86%</td>\n",
       "      <td id=\"T_b8b3d_row11_col3\" class=\"data row11 col3\" >82.64%</td>\n",
       "      <td id=\"T_b8b3d_row11_col4\" class=\"data row11 col4\" >76.03%</td>\n",
       "      <td id=\"T_b8b3d_row11_col5\" class=\"data row11 col5\" >80.17%</td>\n",
       "      <td id=\"T_b8b3d_row11_col6\" class=\"data row11 col6\" >78.10%</td>\n",
       "      <td id=\"T_b8b3d_row11_col7\" class=\"data row11 col7\" >59.92%</td>\n",
       "      <td id=\"T_b8b3d_row11_col8\" class=\"data row11 col8\" >66.94%</td>\n",
       "      <td id=\"T_b8b3d_row11_col9\" class=\"data row11 col9\" >71.49%</td>\n",
       "      <td id=\"T_b8b3d_row11_col10\" class=\"data row11 col10\" >70.66%</td>\n",
       "      <td id=\"T_b8b3d_row11_col11\" class=\"data row11 col11\" >64.46%</td>\n",
       "      <td id=\"T_b8b3d_row11_col12\" class=\"data row11 col12\" >60.74%</td>\n",
       "      <td id=\"T_b8b3d_row11_col13\" class=\"data row11 col13\" >76.86%</td>\n",
       "      <td id=\"T_b8b3d_row11_col14\" class=\"data row11 col14\" >75.21%</td>\n",
       "      <td id=\"T_b8b3d_row11_col15\" class=\"data row11 col15\" >71.85%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b8b3d_level1_row12\" class=\"row_heading level1 row12\" rowspan=\"4\">F</th>\n",
       "      <th id=\"T_b8b3d_level2_row12\" class=\"row_heading level2 row12\" rowspan=\"2\">False</th>\n",
       "      <th id=\"T_b8b3d_level3_row12\" class=\"row_heading level3 row12\" >False</th>\n",
       "      <td id=\"T_b8b3d_row12_col0\" class=\"data row12 col0\" >93.80%</td>\n",
       "      <td id=\"T_b8b3d_row12_col1\" class=\"data row12 col1\" >95.87%</td>\n",
       "      <td id=\"T_b8b3d_row12_col2\" class=\"data row12 col2\" >95.87%</td>\n",
       "      <td id=\"T_b8b3d_row12_col3\" class=\"data row12 col3\" >95.04%</td>\n",
       "      <td id=\"T_b8b3d_row12_col4\" class=\"data row12 col4\" >95.04%</td>\n",
       "      <td id=\"T_b8b3d_row12_col5\" class=\"data row12 col5\" >97.93%</td>\n",
       "      <td id=\"T_b8b3d_row12_col6\" class=\"data row12 col6\" >92.56%</td>\n",
       "      <td id=\"T_b8b3d_row12_col7\" class=\"data row12 col7\" >95.04%</td>\n",
       "      <td id=\"T_b8b3d_row12_col8\" class=\"data row12 col8\" >95.45%</td>\n",
       "      <td id=\"T_b8b3d_row12_col9\" class=\"data row12 col9\" >92.15%</td>\n",
       "      <td id=\"T_b8b3d_row12_col10\" class=\"data row12 col10\" >93.80%</td>\n",
       "      <td id=\"T_b8b3d_row12_col11\" class=\"data row12 col11\" >98.35%</td>\n",
       "      <td id=\"T_b8b3d_row12_col12\" class=\"data row12 col12\" >97.52%</td>\n",
       "      <td id=\"T_b8b3d_row12_col13\" class=\"data row12 col13\" >96.69%</td>\n",
       "      <td id=\"T_b8b3d_row12_col14\" class=\"data row12 col14\" >93.39%</td>\n",
       "      <td id=\"T_b8b3d_row12_col15\" class=\"data row12 col15\" >95.23%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b8b3d_level3_row13\" class=\"row_heading level3 row13\" >True</th>\n",
       "      <td id=\"T_b8b3d_row13_col0\" class=\"data row13 col0\" >75.21%</td>\n",
       "      <td id=\"T_b8b3d_row13_col1\" class=\"data row13 col1\" >62.40%</td>\n",
       "      <td id=\"T_b8b3d_row13_col2\" class=\"data row13 col2\" >78.10%</td>\n",
       "      <td id=\"T_b8b3d_row13_col3\" class=\"data row13 col3\" >80.99%</td>\n",
       "      <td id=\"T_b8b3d_row13_col4\" class=\"data row13 col4\" >77.69%</td>\n",
       "      <td id=\"T_b8b3d_row13_col5\" class=\"data row13 col5\" >81.40%</td>\n",
       "      <td id=\"T_b8b3d_row13_col6\" class=\"data row13 col6\" >78.10%</td>\n",
       "      <td id=\"T_b8b3d_row13_col7\" class=\"data row13 col7\" >59.92%</td>\n",
       "      <td id=\"T_b8b3d_row13_col8\" class=\"data row13 col8\" >66.12%</td>\n",
       "      <td id=\"T_b8b3d_row13_col9\" class=\"data row13 col9\" >72.31%</td>\n",
       "      <td id=\"T_b8b3d_row13_col10\" class=\"data row13 col10\" >71.07%</td>\n",
       "      <td id=\"T_b8b3d_row13_col11\" class=\"data row13 col11\" >64.05%</td>\n",
       "      <td id=\"T_b8b3d_row13_col12\" class=\"data row13 col12\" >61.98%</td>\n",
       "      <td id=\"T_b8b3d_row13_col13\" class=\"data row13 col13\" >76.86%</td>\n",
       "      <td id=\"T_b8b3d_row13_col14\" class=\"data row13 col14\" >76.86%</td>\n",
       "      <td id=\"T_b8b3d_row13_col15\" class=\"data row13 col15\" >72.20%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b8b3d_level2_row14\" class=\"row_heading level2 row14\" rowspan=\"2\">True</th>\n",
       "      <th id=\"T_b8b3d_level3_row14\" class=\"row_heading level3 row14\" >False</th>\n",
       "      <td id=\"T_b8b3d_row14_col0\" class=\"data row14 col0\" >92.15%</td>\n",
       "      <td id=\"T_b8b3d_row14_col1\" class=\"data row14 col1\" >94.21%</td>\n",
       "      <td id=\"T_b8b3d_row14_col2\" class=\"data row14 col2\" >95.45%</td>\n",
       "      <td id=\"T_b8b3d_row14_col3\" class=\"data row14 col3\" >94.63%</td>\n",
       "      <td id=\"T_b8b3d_row14_col4\" class=\"data row14 col4\" >94.21%</td>\n",
       "      <td id=\"T_b8b3d_row14_col5\" class=\"data row14 col5\" >97.11%</td>\n",
       "      <td id=\"T_b8b3d_row14_col6\" class=\"data row14 col6\" >92.15%</td>\n",
       "      <td id=\"T_b8b3d_row14_col7\" class=\"data row14 col7\" >94.21%</td>\n",
       "      <td id=\"T_b8b3d_row14_col8\" class=\"data row14 col8\" >95.04%</td>\n",
       "      <td id=\"T_b8b3d_row14_col9\" class=\"data row14 col9\" >92.15%</td>\n",
       "      <td id=\"T_b8b3d_row14_col10\" class=\"data row14 col10\" >93.39%</td>\n",
       "      <td id=\"T_b8b3d_row14_col11\" class=\"data row14 col11\" >95.87%</td>\n",
       "      <td id=\"T_b8b3d_row14_col12\" class=\"data row14 col12\" >94.21%</td>\n",
       "      <td id=\"T_b8b3d_row14_col13\" class=\"data row14 col13\" >93.80%</td>\n",
       "      <td id=\"T_b8b3d_row14_col14\" class=\"data row14 col14\" >91.74%</td>\n",
       "      <td id=\"T_b8b3d_row14_col15\" class=\"data row14 col15\" >94.02%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b8b3d_level3_row15\" class=\"row_heading level3 row15\" >True</th>\n",
       "      <td id=\"T_b8b3d_row15_col0\" class=\"data row15 col0\" >74.38%</td>\n",
       "      <td id=\"T_b8b3d_row15_col1\" class=\"data row15 col1\" >61.98%</td>\n",
       "      <td id=\"T_b8b3d_row15_col2\" class=\"data row15 col2\" >78.10%</td>\n",
       "      <td id=\"T_b8b3d_row15_col3\" class=\"data row15 col3\" >80.99%</td>\n",
       "      <td id=\"T_b8b3d_row15_col4\" class=\"data row15 col4\" >76.86%</td>\n",
       "      <td id=\"T_b8b3d_row15_col5\" class=\"data row15 col5\" >81.40%</td>\n",
       "      <td id=\"T_b8b3d_row15_col6\" class=\"data row15 col6\" >78.10%</td>\n",
       "      <td id=\"T_b8b3d_row15_col7\" class=\"data row15 col7\" >59.92%</td>\n",
       "      <td id=\"T_b8b3d_row15_col8\" class=\"data row15 col8\" >66.53%</td>\n",
       "      <td id=\"T_b8b3d_row15_col9\" class=\"data row15 col9\" >72.73%</td>\n",
       "      <td id=\"T_b8b3d_row15_col10\" class=\"data row15 col10\" >71.49%</td>\n",
       "      <td id=\"T_b8b3d_row15_col11\" class=\"data row15 col11\" >64.46%</td>\n",
       "      <td id=\"T_b8b3d_row15_col12\" class=\"data row15 col12\" >61.98%</td>\n",
       "      <td id=\"T_b8b3d_row15_col13\" class=\"data row15 col13\" >77.69%</td>\n",
       "      <td id=\"T_b8b3d_row15_col14\" class=\"data row15 col14\" >76.03%</td>\n",
       "      <td id=\"T_b8b3d_row15_col15\" class=\"data row15 col15\" >72.18%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b8b3d_level0_row16\" class=\"row_heading level0 row16\" rowspan=\"8\">random forest</th>\n",
       "      <th id=\"T_b8b3d_level1_row16\" class=\"row_heading level1 row16\" rowspan=\"4\">P</th>\n",
       "      <th id=\"T_b8b3d_level2_row16\" class=\"row_heading level2 row16\" rowspan=\"2\">False</th>\n",
       "      <th id=\"T_b8b3d_level3_row16\" class=\"row_heading level3 row16\" >False</th>\n",
       "      <td id=\"T_b8b3d_row16_col0\" class=\"data row16 col0\" >100.00%</td>\n",
       "      <td id=\"T_b8b3d_row16_col1\" class=\"data row16 col1\" >100.00%</td>\n",
       "      <td id=\"T_b8b3d_row16_col2\" class=\"data row16 col2\" >100.00%</td>\n",
       "      <td id=\"T_b8b3d_row16_col3\" class=\"data row16 col3\" >100.00%</td>\n",
       "      <td id=\"T_b8b3d_row16_col4\" class=\"data row16 col4\" >100.00%</td>\n",
       "      <td id=\"T_b8b3d_row16_col5\" class=\"data row16 col5\" >100.00%</td>\n",
       "      <td id=\"T_b8b3d_row16_col6\" class=\"data row16 col6\" >100.00%</td>\n",
       "      <td id=\"T_b8b3d_row16_col7\" class=\"data row16 col7\" >100.00%</td>\n",
       "      <td id=\"T_b8b3d_row16_col8\" class=\"data row16 col8\" >100.00%</td>\n",
       "      <td id=\"T_b8b3d_row16_col9\" class=\"data row16 col9\" >100.00%</td>\n",
       "      <td id=\"T_b8b3d_row16_col10\" class=\"data row16 col10\" >100.00%</td>\n",
       "      <td id=\"T_b8b3d_row16_col11\" class=\"data row16 col11\" >100.00%</td>\n",
       "      <td id=\"T_b8b3d_row16_col12\" class=\"data row16 col12\" >100.00%</td>\n",
       "      <td id=\"T_b8b3d_row16_col13\" class=\"data row16 col13\" >100.00%</td>\n",
       "      <td id=\"T_b8b3d_row16_col14\" class=\"data row16 col14\" >100.00%</td>\n",
       "      <td id=\"T_b8b3d_row16_col15\" class=\"data row16 col15\" >100.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b8b3d_level3_row17\" class=\"row_heading level3 row17\" >True</th>\n",
       "      <td id=\"T_b8b3d_row17_col0\" class=\"data row17 col0\" >100.00%</td>\n",
       "      <td id=\"T_b8b3d_row17_col1\" class=\"data row17 col1\" >100.00%</td>\n",
       "      <td id=\"T_b8b3d_row17_col2\" class=\"data row17 col2\" >100.00%</td>\n",
       "      <td id=\"T_b8b3d_row17_col3\" class=\"data row17 col3\" >100.00%</td>\n",
       "      <td id=\"T_b8b3d_row17_col4\" class=\"data row17 col4\" >100.00%</td>\n",
       "      <td id=\"T_b8b3d_row17_col5\" class=\"data row17 col5\" >100.00%</td>\n",
       "      <td id=\"T_b8b3d_row17_col6\" class=\"data row17 col6\" >100.00%</td>\n",
       "      <td id=\"T_b8b3d_row17_col7\" class=\"data row17 col7\" >100.00%</td>\n",
       "      <td id=\"T_b8b3d_row17_col8\" class=\"data row17 col8\" >100.00%</td>\n",
       "      <td id=\"T_b8b3d_row17_col9\" class=\"data row17 col9\" >100.00%</td>\n",
       "      <td id=\"T_b8b3d_row17_col10\" class=\"data row17 col10\" >100.00%</td>\n",
       "      <td id=\"T_b8b3d_row17_col11\" class=\"data row17 col11\" >100.00%</td>\n",
       "      <td id=\"T_b8b3d_row17_col12\" class=\"data row17 col12\" >100.00%</td>\n",
       "      <td id=\"T_b8b3d_row17_col13\" class=\"data row17 col13\" >100.00%</td>\n",
       "      <td id=\"T_b8b3d_row17_col14\" class=\"data row17 col14\" >100.00%</td>\n",
       "      <td id=\"T_b8b3d_row17_col15\" class=\"data row17 col15\" >100.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b8b3d_level2_row18\" class=\"row_heading level2 row18\" rowspan=\"2\">True</th>\n",
       "      <th id=\"T_b8b3d_level3_row18\" class=\"row_heading level3 row18\" >False</th>\n",
       "      <td id=\"T_b8b3d_row18_col0\" class=\"data row18 col0\" >100.00%</td>\n",
       "      <td id=\"T_b8b3d_row18_col1\" class=\"data row18 col1\" >100.00%</td>\n",
       "      <td id=\"T_b8b3d_row18_col2\" class=\"data row18 col2\" >100.00%</td>\n",
       "      <td id=\"T_b8b3d_row18_col3\" class=\"data row18 col3\" >100.00%</td>\n",
       "      <td id=\"T_b8b3d_row18_col4\" class=\"data row18 col4\" >100.00%</td>\n",
       "      <td id=\"T_b8b3d_row18_col5\" class=\"data row18 col5\" >100.00%</td>\n",
       "      <td id=\"T_b8b3d_row18_col6\" class=\"data row18 col6\" >100.00%</td>\n",
       "      <td id=\"T_b8b3d_row18_col7\" class=\"data row18 col7\" >100.00%</td>\n",
       "      <td id=\"T_b8b3d_row18_col8\" class=\"data row18 col8\" >100.00%</td>\n",
       "      <td id=\"T_b8b3d_row18_col9\" class=\"data row18 col9\" >100.00%</td>\n",
       "      <td id=\"T_b8b3d_row18_col10\" class=\"data row18 col10\" >100.00%</td>\n",
       "      <td id=\"T_b8b3d_row18_col11\" class=\"data row18 col11\" >100.00%</td>\n",
       "      <td id=\"T_b8b3d_row18_col12\" class=\"data row18 col12\" >100.00%</td>\n",
       "      <td id=\"T_b8b3d_row18_col13\" class=\"data row18 col13\" >100.00%</td>\n",
       "      <td id=\"T_b8b3d_row18_col14\" class=\"data row18 col14\" >100.00%</td>\n",
       "      <td id=\"T_b8b3d_row18_col15\" class=\"data row18 col15\" >100.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b8b3d_level3_row19\" class=\"row_heading level3 row19\" >True</th>\n",
       "      <td id=\"T_b8b3d_row19_col0\" class=\"data row19 col0\" >100.00%</td>\n",
       "      <td id=\"T_b8b3d_row19_col1\" class=\"data row19 col1\" >100.00%</td>\n",
       "      <td id=\"T_b8b3d_row19_col2\" class=\"data row19 col2\" >100.00%</td>\n",
       "      <td id=\"T_b8b3d_row19_col3\" class=\"data row19 col3\" >100.00%</td>\n",
       "      <td id=\"T_b8b3d_row19_col4\" class=\"data row19 col4\" >100.00%</td>\n",
       "      <td id=\"T_b8b3d_row19_col5\" class=\"data row19 col5\" >100.00%</td>\n",
       "      <td id=\"T_b8b3d_row19_col6\" class=\"data row19 col6\" >100.00%</td>\n",
       "      <td id=\"T_b8b3d_row19_col7\" class=\"data row19 col7\" >100.00%</td>\n",
       "      <td id=\"T_b8b3d_row19_col8\" class=\"data row19 col8\" >100.00%</td>\n",
       "      <td id=\"T_b8b3d_row19_col9\" class=\"data row19 col9\" >100.00%</td>\n",
       "      <td id=\"T_b8b3d_row19_col10\" class=\"data row19 col10\" >100.00%</td>\n",
       "      <td id=\"T_b8b3d_row19_col11\" class=\"data row19 col11\" >100.00%</td>\n",
       "      <td id=\"T_b8b3d_row19_col12\" class=\"data row19 col12\" >100.00%</td>\n",
       "      <td id=\"T_b8b3d_row19_col13\" class=\"data row19 col13\" >100.00%</td>\n",
       "      <td id=\"T_b8b3d_row19_col14\" class=\"data row19 col14\" >100.00%</td>\n",
       "      <td id=\"T_b8b3d_row19_col15\" class=\"data row19 col15\" >100.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b8b3d_level1_row20\" class=\"row_heading level1 row20\" rowspan=\"4\">F</th>\n",
       "      <th id=\"T_b8b3d_level2_row20\" class=\"row_heading level2 row20\" rowspan=\"2\">False</th>\n",
       "      <th id=\"T_b8b3d_level3_row20\" class=\"row_heading level3 row20\" >False</th>\n",
       "      <td id=\"T_b8b3d_row20_col0\" class=\"data row20 col0\" >100.00%</td>\n",
       "      <td id=\"T_b8b3d_row20_col1\" class=\"data row20 col1\" >100.00%</td>\n",
       "      <td id=\"T_b8b3d_row20_col2\" class=\"data row20 col2\" >100.00%</td>\n",
       "      <td id=\"T_b8b3d_row20_col3\" class=\"data row20 col3\" >100.00%</td>\n",
       "      <td id=\"T_b8b3d_row20_col4\" class=\"data row20 col4\" >100.00%</td>\n",
       "      <td id=\"T_b8b3d_row20_col5\" class=\"data row20 col5\" >100.00%</td>\n",
       "      <td id=\"T_b8b3d_row20_col6\" class=\"data row20 col6\" >100.00%</td>\n",
       "      <td id=\"T_b8b3d_row20_col7\" class=\"data row20 col7\" >100.00%</td>\n",
       "      <td id=\"T_b8b3d_row20_col8\" class=\"data row20 col8\" >100.00%</td>\n",
       "      <td id=\"T_b8b3d_row20_col9\" class=\"data row20 col9\" >100.00%</td>\n",
       "      <td id=\"T_b8b3d_row20_col10\" class=\"data row20 col10\" >100.00%</td>\n",
       "      <td id=\"T_b8b3d_row20_col11\" class=\"data row20 col11\" >100.00%</td>\n",
       "      <td id=\"T_b8b3d_row20_col12\" class=\"data row20 col12\" >100.00%</td>\n",
       "      <td id=\"T_b8b3d_row20_col13\" class=\"data row20 col13\" >100.00%</td>\n",
       "      <td id=\"T_b8b3d_row20_col14\" class=\"data row20 col14\" >100.00%</td>\n",
       "      <td id=\"T_b8b3d_row20_col15\" class=\"data row20 col15\" >100.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b8b3d_level3_row21\" class=\"row_heading level3 row21\" >True</th>\n",
       "      <td id=\"T_b8b3d_row21_col0\" class=\"data row21 col0\" >100.00%</td>\n",
       "      <td id=\"T_b8b3d_row21_col1\" class=\"data row21 col1\" >100.00%</td>\n",
       "      <td id=\"T_b8b3d_row21_col2\" class=\"data row21 col2\" >100.00%</td>\n",
       "      <td id=\"T_b8b3d_row21_col3\" class=\"data row21 col3\" >100.00%</td>\n",
       "      <td id=\"T_b8b3d_row21_col4\" class=\"data row21 col4\" >100.00%</td>\n",
       "      <td id=\"T_b8b3d_row21_col5\" class=\"data row21 col5\" >100.00%</td>\n",
       "      <td id=\"T_b8b3d_row21_col6\" class=\"data row21 col6\" >100.00%</td>\n",
       "      <td id=\"T_b8b3d_row21_col7\" class=\"data row21 col7\" >100.00%</td>\n",
       "      <td id=\"T_b8b3d_row21_col8\" class=\"data row21 col8\" >100.00%</td>\n",
       "      <td id=\"T_b8b3d_row21_col9\" class=\"data row21 col9\" >100.00%</td>\n",
       "      <td id=\"T_b8b3d_row21_col10\" class=\"data row21 col10\" >100.00%</td>\n",
       "      <td id=\"T_b8b3d_row21_col11\" class=\"data row21 col11\" >100.00%</td>\n",
       "      <td id=\"T_b8b3d_row21_col12\" class=\"data row21 col12\" >100.00%</td>\n",
       "      <td id=\"T_b8b3d_row21_col13\" class=\"data row21 col13\" >100.00%</td>\n",
       "      <td id=\"T_b8b3d_row21_col14\" class=\"data row21 col14\" >100.00%</td>\n",
       "      <td id=\"T_b8b3d_row21_col15\" class=\"data row21 col15\" >100.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b8b3d_level2_row22\" class=\"row_heading level2 row22\" rowspan=\"2\">True</th>\n",
       "      <th id=\"T_b8b3d_level3_row22\" class=\"row_heading level3 row22\" >False</th>\n",
       "      <td id=\"T_b8b3d_row22_col0\" class=\"data row22 col0\" >100.00%</td>\n",
       "      <td id=\"T_b8b3d_row22_col1\" class=\"data row22 col1\" >99.59%</td>\n",
       "      <td id=\"T_b8b3d_row22_col2\" class=\"data row22 col2\" >100.00%</td>\n",
       "      <td id=\"T_b8b3d_row22_col3\" class=\"data row22 col3\" >100.00%</td>\n",
       "      <td id=\"T_b8b3d_row22_col4\" class=\"data row22 col4\" >100.00%</td>\n",
       "      <td id=\"T_b8b3d_row22_col5\" class=\"data row22 col5\" >100.00%</td>\n",
       "      <td id=\"T_b8b3d_row22_col6\" class=\"data row22 col6\" >100.00%</td>\n",
       "      <td id=\"T_b8b3d_row22_col7\" class=\"data row22 col7\" >100.00%</td>\n",
       "      <td id=\"T_b8b3d_row22_col8\" class=\"data row22 col8\" >100.00%</td>\n",
       "      <td id=\"T_b8b3d_row22_col9\" class=\"data row22 col9\" >100.00%</td>\n",
       "      <td id=\"T_b8b3d_row22_col10\" class=\"data row22 col10\" >100.00%</td>\n",
       "      <td id=\"T_b8b3d_row22_col11\" class=\"data row22 col11\" >100.00%</td>\n",
       "      <td id=\"T_b8b3d_row22_col12\" class=\"data row22 col12\" >100.00%</td>\n",
       "      <td id=\"T_b8b3d_row22_col13\" class=\"data row22 col13\" >100.00%</td>\n",
       "      <td id=\"T_b8b3d_row22_col14\" class=\"data row22 col14\" >100.00%</td>\n",
       "      <td id=\"T_b8b3d_row22_col15\" class=\"data row22 col15\" >99.97%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b8b3d_level3_row23\" class=\"row_heading level3 row23\" >True</th>\n",
       "      <td id=\"T_b8b3d_row23_col0\" class=\"data row23 col0\" >100.00%</td>\n",
       "      <td id=\"T_b8b3d_row23_col1\" class=\"data row23 col1\" >100.00%</td>\n",
       "      <td id=\"T_b8b3d_row23_col2\" class=\"data row23 col2\" >100.00%</td>\n",
       "      <td id=\"T_b8b3d_row23_col3\" class=\"data row23 col3\" >100.00%</td>\n",
       "      <td id=\"T_b8b3d_row23_col4\" class=\"data row23 col4\" >100.00%</td>\n",
       "      <td id=\"T_b8b3d_row23_col5\" class=\"data row23 col5\" >100.00%</td>\n",
       "      <td id=\"T_b8b3d_row23_col6\" class=\"data row23 col6\" >100.00%</td>\n",
       "      <td id=\"T_b8b3d_row23_col7\" class=\"data row23 col7\" >100.00%</td>\n",
       "      <td id=\"T_b8b3d_row23_col8\" class=\"data row23 col8\" >100.00%</td>\n",
       "      <td id=\"T_b8b3d_row23_col9\" class=\"data row23 col9\" >100.00%</td>\n",
       "      <td id=\"T_b8b3d_row23_col10\" class=\"data row23 col10\" >100.00%</td>\n",
       "      <td id=\"T_b8b3d_row23_col11\" class=\"data row23 col11\" >100.00%</td>\n",
       "      <td id=\"T_b8b3d_row23_col12\" class=\"data row23 col12\" >100.00%</td>\n",
       "      <td id=\"T_b8b3d_row23_col13\" class=\"data row23 col13\" >100.00%</td>\n",
       "      <td id=\"T_b8b3d_row23_col14\" class=\"data row23 col14\" >100.00%</td>\n",
       "      <td id=\"T_b8b3d_row23_col15\" class=\"data row23 col15\" >100.00%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f1a0bf334f0>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performances.xs(\"train\", level=1).style.format(\"{:.2%}\").background_gradient(\"Blues\", axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5540/2322317960.py:3: FutureWarning: this method is deprecated in favour of `Styler.to_html()`\n",
      "  f.write(test_plot.render())\n"
     ]
    }
   ],
   "source": [
    "test_plot = performances.xs(\"test\", level=1).style.format(\"{:.2%}\").background_gradient(\"Greens\", axis=0)\n",
    "with open('statistical_approach_test.html', 'w') as f:\n",
    "    f.write(test_plot.render())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_6acd5_row0_col0, #T_6acd5_row0_col3, #T_6acd5_row0_col5, #T_6acd5_row0_col14, #T_6acd5_row0_col15, #T_6acd5_row1_col0, #T_6acd5_row1_col6, #T_6acd5_row1_col7, #T_6acd5_row1_col8, #T_6acd5_row1_col12, #T_6acd5_row2_col0, #T_6acd5_row2_col5, #T_6acd5_row3_col0, #T_6acd5_row3_col5, #T_6acd5_row5_col5, #T_6acd5_row5_col9, #T_6acd5_row5_col12, #T_6acd5_row6_col0, #T_6acd5_row6_col2, #T_6acd5_row7_col7, #T_6acd5_row7_col8, #T_6acd5_row7_col12, #T_6acd5_row7_col13, #T_6acd5_row8_col5, #T_6acd5_row8_col12, #T_6acd5_row9_col0, #T_6acd5_row9_col2, #T_6acd5_row10_col5, #T_6acd5_row11_col5, #T_6acd5_row12_col10, #T_6acd5_row12_col12, #T_6acd5_row13_col10, #T_6acd5_row13_col12, #T_6acd5_row14_col10, #T_6acd5_row14_col12, #T_6acd5_row15_col6, #T_6acd5_row16_col10, #T_6acd5_row16_col12, #T_6acd5_row17_col2, #T_6acd5_row17_col11, #T_6acd5_row17_col12, #T_6acd5_row18_col0, #T_6acd5_row20_col1, #T_6acd5_row20_col5, #T_6acd5_row21_col4, #T_6acd5_row23_col11 {\n",
       "  background-color: #f7fcf5;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_6acd5_row0_col1, #T_6acd5_row0_col7, #T_6acd5_row1_col9, #T_6acd5_row2_col7, #T_6acd5_row2_col8, #T_6acd5_row2_col9, #T_6acd5_row3_col7, #T_6acd5_row3_col8, #T_6acd5_row3_col9, #T_6acd5_row4_col7, #T_6acd5_row5_col7, #T_6acd5_row6_col7, #T_6acd5_row6_col8, #T_6acd5_row7_col9, #T_6acd5_row8_col8, #T_6acd5_row8_col13, #T_6acd5_row9_col7, #T_6acd5_row9_col8, #T_6acd5_row10_col8, #T_6acd5_row10_col13, #T_6acd5_row12_col4, #T_6acd5_row12_col7, #T_6acd5_row12_col8, #T_6acd5_row13_col7, #T_6acd5_row13_col8, #T_6acd5_row14_col2, #T_6acd5_row14_col4, #T_6acd5_row14_col7, #T_6acd5_row14_col8, #T_6acd5_row15_col5, #T_6acd5_row16_col0, #T_6acd5_row16_col7, #T_6acd5_row16_col8, #T_6acd5_row17_col3, #T_6acd5_row17_col7, #T_6acd5_row18_col11, #T_6acd5_row20_col9, #T_6acd5_row20_col10, #T_6acd5_row20_col12, #T_6acd5_row21_col5, #T_6acd5_row21_col14, #T_6acd5_row22_col8, #T_6acd5_row23_col3, #T_6acd5_row23_col5, #T_6acd5_row23_col6, #T_6acd5_row23_col9, #T_6acd5_row23_col15 {\n",
       "  background-color: #00441b;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_6acd5_row0_col2, #T_6acd5_row6_col10, #T_6acd5_row7_col10, #T_6acd5_row8_col7, #T_6acd5_row10_col2, #T_6acd5_row10_col7, #T_6acd5_row11_col2, #T_6acd5_row11_col7, #T_6acd5_row18_col7, #T_6acd5_row19_col2, #T_6acd5_row19_col7, #T_6acd5_row20_col7, #T_6acd5_row21_col10, #T_6acd5_row22_col2 {\n",
       "  background-color: #4bb062;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_6acd5_row0_col4, #T_6acd5_row5_col0, #T_6acd5_row6_col4, #T_6acd5_row10_col4, #T_6acd5_row18_col4, #T_6acd5_row21_col0, #T_6acd5_row22_col0, #T_6acd5_row22_col4, #T_6acd5_row23_col0, #T_6acd5_row23_col4 {\n",
       "  background-color: #56b567;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_6acd5_row0_col6, #T_6acd5_row2_col1, #T_6acd5_row2_col6, #T_6acd5_row2_col14, #T_6acd5_row3_col1, #T_6acd5_row3_col6, #T_6acd5_row4_col6, #T_6acd5_row5_col6, #T_6acd5_row6_col1, #T_6acd5_row6_col6, #T_6acd5_row6_col14, #T_6acd5_row8_col1, #T_6acd5_row8_col6, #T_6acd5_row9_col1, #T_6acd5_row9_col6, #T_6acd5_row10_col1, #T_6acd5_row10_col6, #T_6acd5_row11_col1, #T_6acd5_row11_col6, #T_6acd5_row12_col1, #T_6acd5_row12_col6, #T_6acd5_row13_col1, #T_6acd5_row13_col6, #T_6acd5_row14_col1, #T_6acd5_row14_col6, #T_6acd5_row14_col15, #T_6acd5_row15_col12, #T_6acd5_row15_col15, #T_6acd5_row16_col1, #T_6acd5_row16_col6, #T_6acd5_row17_col1, #T_6acd5_row17_col6, #T_6acd5_row18_col6, #T_6acd5_row18_col12, #T_6acd5_row18_col14, #T_6acd5_row19_col1, #T_6acd5_row19_col6, #T_6acd5_row19_col12, #T_6acd5_row19_col14, #T_6acd5_row20_col6, #T_6acd5_row21_col6, #T_6acd5_row22_col1, #T_6acd5_row22_col6 {\n",
       "  background-color: #37a055;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_6acd5_row0_col8, #T_6acd5_row9_col4, #T_6acd5_row12_col0, #T_6acd5_row13_col0, #T_6acd5_row13_col4, #T_6acd5_row14_col0, #T_6acd5_row15_col8, #T_6acd5_row21_col8, #T_6acd5_row23_col8 {\n",
       "  background-color: #2c944c;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_6acd5_row0_col9, #T_6acd5_row1_col11, #T_6acd5_row6_col9, #T_6acd5_row8_col9, #T_6acd5_row9_col9, #T_6acd5_row17_col9, #T_6acd5_row18_col9, #T_6acd5_row19_col9, #T_6acd5_row21_col9, #T_6acd5_row22_col9 {\n",
       "  background-color: #238b45;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_6acd5_row0_col10, #T_6acd5_row3_col2, #T_6acd5_row5_col10 {\n",
       "  background-color: #b8e3b2;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_6acd5_row0_col11, #T_6acd5_row6_col11, #T_6acd5_row9_col11 {\n",
       "  background-color: #e5f5e0;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_6acd5_row0_col12, #T_6acd5_row2_col12, #T_6acd5_row3_col12, #T_6acd5_row4_col12, #T_6acd5_row5_col15, #T_6acd5_row6_col12, #T_6acd5_row7_col6, #T_6acd5_row9_col12, #T_6acd5_row10_col12, #T_6acd5_row11_col12, #T_6acd5_row14_col14, #T_6acd5_row21_col12, #T_6acd5_row22_col12, #T_6acd5_row23_col1, #T_6acd5_row23_col12 {\n",
       "  background-color: #aedea7;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_6acd5_row0_col13, #T_6acd5_row1_col1, #T_6acd5_row1_col2, #T_6acd5_row3_col10, #T_6acd5_row3_col14, #T_6acd5_row4_col1, #T_6acd5_row5_col2, #T_6acd5_row6_col3, #T_6acd5_row9_col3, #T_6acd5_row9_col10, #T_6acd5_row10_col10, #T_6acd5_row11_col3, #T_6acd5_row11_col13, #T_6acd5_row11_col15, #T_6acd5_row12_col13, #T_6acd5_row13_col3, #T_6acd5_row13_col13, #T_6acd5_row14_col13, #T_6acd5_row15_col13, #T_6acd5_row16_col3, #T_6acd5_row17_col13, #T_6acd5_row18_col2, #T_6acd5_row19_col3, #T_6acd5_row19_col10, #T_6acd5_row19_col13, #T_6acd5_row20_col2, #T_6acd5_row20_col13, #T_6acd5_row21_col1, #T_6acd5_row22_col13, #T_6acd5_row23_col2 {\n",
       "  background-color: #73c476;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_6acd5_row1_col3, #T_6acd5_row7_col3, #T_6acd5_row9_col14, #T_6acd5_row15_col14, #T_6acd5_row18_col15, #T_6acd5_row19_col15, #T_6acd5_row20_col14, #T_6acd5_row22_col3, #T_6acd5_row23_col13, #T_6acd5_row23_col14 {\n",
       "  background-color: #228a44;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_6acd5_row1_col4, #T_6acd5_row4_col0, #T_6acd5_row5_col4, #T_6acd5_row8_col0, #T_6acd5_row17_col0, #T_6acd5_row20_col4 {\n",
       "  background-color: #8ed08b;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_6acd5_row1_col5, #T_6acd5_row7_col5, #T_6acd5_row10_col9, #T_6acd5_row12_col9, #T_6acd5_row13_col9, #T_6acd5_row14_col9, #T_6acd5_row15_col9, #T_6acd5_row16_col9 {\n",
       "  background-color: #75c477;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_6acd5_row1_col10, #T_6acd5_row4_col10, #T_6acd5_row7_col2 {\n",
       "  background-color: #2f974e;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_6acd5_row1_col13, #T_6acd5_row1_col15, #T_6acd5_row2_col11, #T_6acd5_row2_col13, #T_6acd5_row3_col11, #T_6acd5_row3_col13, #T_6acd5_row4_col5, #T_6acd5_row4_col13, #T_6acd5_row5_col11, #T_6acd5_row5_col13, #T_6acd5_row6_col5, #T_6acd5_row6_col13, #T_6acd5_row8_col11, #T_6acd5_row9_col5, #T_6acd5_row9_col13, #T_6acd5_row10_col11, #T_6acd5_row12_col5, #T_6acd5_row12_col11, #T_6acd5_row12_col14, #T_6acd5_row13_col5, #T_6acd5_row13_col11, #T_6acd5_row14_col5, #T_6acd5_row14_col11, #T_6acd5_row15_col11, #T_6acd5_row16_col5, #T_6acd5_row16_col11, #T_6acd5_row16_col13, #T_6acd5_row17_col5, #T_6acd5_row18_col5, #T_6acd5_row18_col13, #T_6acd5_row19_col5, #T_6acd5_row21_col13, #T_6acd5_row22_col5 {\n",
       "  background-color: #c7e9c0;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_6acd5_row1_col14, #T_6acd5_row7_col14, #T_6acd5_row8_col14, #T_6acd5_row11_col14, #T_6acd5_row12_col15 {\n",
       "  background-color: #52b365;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_6acd5_row2_col2, #T_6acd5_row15_col2 {\n",
       "  background-color: #d3eecd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_6acd5_row2_col3, #T_6acd5_row3_col3, #T_6acd5_row8_col3, #T_6acd5_row10_col3, #T_6acd5_row12_col3, #T_6acd5_row14_col3 {\n",
       "  background-color: #a2d99c;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_6acd5_row2_col4, #T_6acd5_row3_col4, #T_6acd5_row4_col4, #T_6acd5_row7_col4, #T_6acd5_row8_col4, #T_6acd5_row15_col0, #T_6acd5_row15_col4, #T_6acd5_row17_col4, #T_6acd5_row18_col8, #T_6acd5_row20_col8 {\n",
       "  background-color: #bce4b5;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_6acd5_row2_col10, #T_6acd5_row4_col2, #T_6acd5_row8_col2, #T_6acd5_row8_col10, #T_6acd5_row11_col10, #T_6acd5_row21_col2, #T_6acd5_row23_col7 {\n",
       "  background-color: #98d594;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_6acd5_row2_col15, #T_6acd5_row3_col15, #T_6acd5_row4_col15 {\n",
       "  background-color: #bbe4b4;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_6acd5_row4_col3, #T_6acd5_row4_col9, #T_6acd5_row11_col9 {\n",
       "  background-color: #c8e9c1;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_6acd5_row4_col8, #T_6acd5_row5_col8, #T_6acd5_row11_col0, #T_6acd5_row11_col8, #T_6acd5_row16_col4, #T_6acd5_row17_col8, #T_6acd5_row19_col0, #T_6acd5_row19_col8 {\n",
       "  background-color: #05712f;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_6acd5_row4_col11, #T_6acd5_row13_col15, #T_6acd5_row22_col11 {\n",
       "  background-color: #42ab5d;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_6acd5_row4_col14, #T_6acd5_row18_col1, #T_6acd5_row22_col14 {\n",
       "  background-color: #dbf1d6;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_6acd5_row5_col1, #T_6acd5_row7_col1, #T_6acd5_row15_col1, #T_6acd5_row17_col14, #T_6acd5_row20_col15 {\n",
       "  background-color: #0b7734;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_6acd5_row5_col3, #T_6acd5_row15_col3 {\n",
       "  background-color: #40aa5d;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_6acd5_row5_col14, #T_6acd5_row7_col15, #T_6acd5_row8_col15, #T_6acd5_row9_col15, #T_6acd5_row10_col14, #T_6acd5_row13_col14, #T_6acd5_row16_col14 {\n",
       "  background-color: #92d28f;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_6acd5_row6_col15, #T_6acd5_row11_col11, #T_6acd5_row19_col11, #T_6acd5_row21_col11 {\n",
       "  background-color: #a0d99b;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_6acd5_row7_col0, #T_6acd5_row10_col0, #T_6acd5_row11_col4, #T_6acd5_row19_col4, #T_6acd5_row20_col0 {\n",
       "  background-color: #e1f3dc;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_6acd5_row7_col11, #T_6acd5_row20_col11 {\n",
       "  background-color: #006d2c;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_6acd5_row10_col15 {\n",
       "  background-color: #83cb82;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_6acd5_row12_col2, #T_6acd5_row13_col2, #T_6acd5_row16_col2, #T_6acd5_row17_col10, #T_6acd5_row18_col10, #T_6acd5_row22_col10 {\n",
       "  background-color: #006428;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_6acd5_row15_col7, #T_6acd5_row15_col10, #T_6acd5_row21_col7, #T_6acd5_row22_col7, #T_6acd5_row23_col10 {\n",
       "  background-color: #157f3b;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_6acd5_row16_col15, #T_6acd5_row17_col15 {\n",
       "  background-color: #2d954d;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_6acd5_row18_col3, #T_6acd5_row20_col3, #T_6acd5_row21_col3, #T_6acd5_row21_col15 {\n",
       "  background-color: #006c2c;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_6acd5_row22_col15 {\n",
       "  background-color: #005f26;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_6acd5\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank\" >&nbsp;</th>\n",
       "      <th class=\"blank\" >&nbsp;</th>\n",
       "      <th class=\"blank\" >&nbsp;</th>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_6acd5_level0_col0\" class=\"col_heading level0 col0\" >CO</th>\n",
       "      <th id=\"T_6acd5_level0_col1\" class=\"col_heading level0 col1\" >LA</th>\n",
       "      <th id=\"T_6acd5_level0_col2\" class=\"col_heading level0 col2\" >LR</th>\n",
       "      <th id=\"T_6acd5_level0_col3\" class=\"col_heading level0 col3\" >LS</th>\n",
       "      <th id=\"T_6acd5_level0_col4\" class=\"col_heading level0 col4\" >EF</th>\n",
       "      <th id=\"T_6acd5_level0_col5\" class=\"col_heading level0 col5\" >CR</th>\n",
       "      <th id=\"T_6acd5_level0_col6\" class=\"col_heading level0 col6\" >EM</th>\n",
       "      <th id=\"T_6acd5_level0_col7\" class=\"col_heading level0 col7\" >CL</th>\n",
       "      <th id=\"T_6acd5_level0_col8\" class=\"col_heading level0 col8\" >AP</th>\n",
       "      <th id=\"T_6acd5_level0_col9\" class=\"col_heading level0 col9\" >AR</th>\n",
       "      <th id=\"T_6acd5_level0_col10\" class=\"col_heading level0 col10\" >RE</th>\n",
       "      <th id=\"T_6acd5_level0_col11\" class=\"col_heading level0 col11\" >GA</th>\n",
       "      <th id=\"T_6acd5_level0_col12\" class=\"col_heading level0 col12\" >GR</th>\n",
       "      <th id=\"T_6acd5_level0_col13\" class=\"col_heading level0 col13\" >GS</th>\n",
       "      <th id=\"T_6acd5_level0_col14\" class=\"col_heading level0 col14\" >OV</th>\n",
       "      <th id=\"T_6acd5_level0_col15\" class=\"col_heading level0 col15\" >AVG</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >method</th>\n",
       "      <th class=\"index_name level1\" >token</th>\n",
       "      <th class=\"index_name level2\" >lemma</th>\n",
       "      <th class=\"index_name level3\" >pos</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "      <th class=\"blank col1\" >&nbsp;</th>\n",
       "      <th class=\"blank col2\" >&nbsp;</th>\n",
       "      <th class=\"blank col3\" >&nbsp;</th>\n",
       "      <th class=\"blank col4\" >&nbsp;</th>\n",
       "      <th class=\"blank col5\" >&nbsp;</th>\n",
       "      <th class=\"blank col6\" >&nbsp;</th>\n",
       "      <th class=\"blank col7\" >&nbsp;</th>\n",
       "      <th class=\"blank col8\" >&nbsp;</th>\n",
       "      <th class=\"blank col9\" >&nbsp;</th>\n",
       "      <th class=\"blank col10\" >&nbsp;</th>\n",
       "      <th class=\"blank col11\" >&nbsp;</th>\n",
       "      <th class=\"blank col12\" >&nbsp;</th>\n",
       "      <th class=\"blank col13\" >&nbsp;</th>\n",
       "      <th class=\"blank col14\" >&nbsp;</th>\n",
       "      <th class=\"blank col15\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_6acd5_level0_row0\" class=\"row_heading level0 row0\" >random forest</th>\n",
       "      <th id=\"T_6acd5_level1_row0\" class=\"row_heading level1 row0\" >F</th>\n",
       "      <th id=\"T_6acd5_level2_row0\" class=\"row_heading level2 row0\" >False</th>\n",
       "      <th id=\"T_6acd5_level3_row0\" class=\"row_heading level3 row0\" >False</th>\n",
       "      <td id=\"T_6acd5_row0_col0\" class=\"data row0 col0\" >55.74%</td>\n",
       "      <td id=\"T_6acd5_row0_col1\" class=\"data row0 col1\" >50.82%</td>\n",
       "      <td id=\"T_6acd5_row0_col2\" class=\"data row0 col2\" >62.30%</td>\n",
       "      <td id=\"T_6acd5_row0_col3\" class=\"data row0 col3\" >62.30%</td>\n",
       "      <td id=\"T_6acd5_row0_col4\" class=\"data row0 col4\" >72.13%</td>\n",
       "      <td id=\"T_6acd5_row0_col5\" class=\"data row0 col5\" >52.46%</td>\n",
       "      <td id=\"T_6acd5_row0_col6\" class=\"data row0 col6\" >75.41%</td>\n",
       "      <td id=\"T_6acd5_row0_col7\" class=\"data row0 col7\" >73.77%</td>\n",
       "      <td id=\"T_6acd5_row0_col8\" class=\"data row0 col8\" >70.49%</td>\n",
       "      <td id=\"T_6acd5_row0_col9\" class=\"data row0 col9\" >68.85%</td>\n",
       "      <td id=\"T_6acd5_row0_col10\" class=\"data row0 col10\" >59.02%</td>\n",
       "      <td id=\"T_6acd5_row0_col11\" class=\"data row0 col11\" >50.82%</td>\n",
       "      <td id=\"T_6acd5_row0_col12\" class=\"data row0 col12\" >50.82%</td>\n",
       "      <td id=\"T_6acd5_row0_col13\" class=\"data row0 col13\" >81.97%</td>\n",
       "      <td id=\"T_6acd5_row0_col14\" class=\"data row0 col14\" >49.18%</td>\n",
       "      <td id=\"T_6acd5_row0_col15\" class=\"data row0 col15\" >62.40%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6acd5_level0_row1\" class=\"row_heading level0 row1\" >logistic</th>\n",
       "      <th id=\"T_6acd5_level1_row1\" class=\"row_heading level1 row1\" >P</th>\n",
       "      <th id=\"T_6acd5_level2_row1\" class=\"row_heading level2 row1\" >False</th>\n",
       "      <th id=\"T_6acd5_level3_row1\" class=\"row_heading level3 row1\" >True</th>\n",
       "      <td id=\"T_6acd5_row1_col0\" class=\"data row1 col0\" >55.74%</td>\n",
       "      <td id=\"T_6acd5_row1_col1\" class=\"data row1 col1\" >45.90%</td>\n",
       "      <td id=\"T_6acd5_row1_col2\" class=\"data row1 col2\" >60.66%</td>\n",
       "      <td id=\"T_6acd5_row1_col3\" class=\"data row1 col3\" >72.13%</td>\n",
       "      <td id=\"T_6acd5_row1_col4\" class=\"data row1 col4\" >70.49%</td>\n",
       "      <td id=\"T_6acd5_row1_col5\" class=\"data row1 col5\" >55.74%</td>\n",
       "      <td id=\"T_6acd5_row1_col6\" class=\"data row1 col6\" >72.13%</td>\n",
       "      <td id=\"T_6acd5_row1_col7\" class=\"data row1 col7\" >65.57%</td>\n",
       "      <td id=\"T_6acd5_row1_col8\" class=\"data row1 col8\" >62.30%</td>\n",
       "      <td id=\"T_6acd5_row1_col9\" class=\"data row1 col9\" >70.49%</td>\n",
       "      <td id=\"T_6acd5_row1_col10\" class=\"data row1 col10\" >65.57%</td>\n",
       "      <td id=\"T_6acd5_row1_col11\" class=\"data row1 col11\" >59.02%</td>\n",
       "      <td id=\"T_6acd5_row1_col12\" class=\"data row1 col12\" >49.18%</td>\n",
       "      <td id=\"T_6acd5_row1_col13\" class=\"data row1 col13\" >80.33%</td>\n",
       "      <td id=\"T_6acd5_row1_col14\" class=\"data row1 col14\" >60.66%</td>\n",
       "      <td id=\"T_6acd5_row1_col15\" class=\"data row1 col15\" >63.06%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6acd5_level0_row2\" class=\"row_heading level0 row2\" rowspan=\"2\">svm</th>\n",
       "      <th id=\"T_6acd5_level1_row2\" class=\"row_heading level1 row2\" rowspan=\"2\">P</th>\n",
       "      <th id=\"T_6acd5_level2_row2\" class=\"row_heading level2 row2\" >False</th>\n",
       "      <th id=\"T_6acd5_level3_row2\" class=\"row_heading level3 row2\" >True</th>\n",
       "      <td id=\"T_6acd5_row2_col0\" class=\"data row2 col0\" >55.74%</td>\n",
       "      <td id=\"T_6acd5_row2_col1\" class=\"data row2 col1\" >47.54%</td>\n",
       "      <td id=\"T_6acd5_row2_col2\" class=\"data row2 col2\" >55.74%</td>\n",
       "      <td id=\"T_6acd5_row2_col3\" class=\"data row2 col3\" >67.21%</td>\n",
       "      <td id=\"T_6acd5_row2_col4\" class=\"data row2 col4\" >68.85%</td>\n",
       "      <td id=\"T_6acd5_row2_col5\" class=\"data row2 col5\" >52.46%</td>\n",
       "      <td id=\"T_6acd5_row2_col6\" class=\"data row2 col6\" >75.41%</td>\n",
       "      <td id=\"T_6acd5_row2_col7\" class=\"data row2 col7\" >73.77%</td>\n",
       "      <td id=\"T_6acd5_row2_col8\" class=\"data row2 col8\" >73.77%</td>\n",
       "      <td id=\"T_6acd5_row2_col9\" class=\"data row2 col9\" >70.49%</td>\n",
       "      <td id=\"T_6acd5_row2_col10\" class=\"data row2 col10\" >60.66%</td>\n",
       "      <td id=\"T_6acd5_row2_col11\" class=\"data row2 col11\" >52.46%</td>\n",
       "      <td id=\"T_6acd5_row2_col12\" class=\"data row2 col12\" >50.82%</td>\n",
       "      <td id=\"T_6acd5_row2_col13\" class=\"data row2 col13\" >80.33%</td>\n",
       "      <td id=\"T_6acd5_row2_col14\" class=\"data row2 col14\" >62.30%</td>\n",
       "      <td id=\"T_6acd5_row2_col15\" class=\"data row2 col15\" >63.17%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6acd5_level2_row3\" class=\"row_heading level2 row3\" >True</th>\n",
       "      <th id=\"T_6acd5_level3_row3\" class=\"row_heading level3 row3\" >True</th>\n",
       "      <td id=\"T_6acd5_row3_col0\" class=\"data row3 col0\" >55.74%</td>\n",
       "      <td id=\"T_6acd5_row3_col1\" class=\"data row3 col1\" >47.54%</td>\n",
       "      <td id=\"T_6acd5_row3_col2\" class=\"data row3 col2\" >57.38%</td>\n",
       "      <td id=\"T_6acd5_row3_col3\" class=\"data row3 col3\" >67.21%</td>\n",
       "      <td id=\"T_6acd5_row3_col4\" class=\"data row3 col4\" >68.85%</td>\n",
       "      <td id=\"T_6acd5_row3_col5\" class=\"data row3 col5\" >52.46%</td>\n",
       "      <td id=\"T_6acd5_row3_col6\" class=\"data row3 col6\" >75.41%</td>\n",
       "      <td id=\"T_6acd5_row3_col7\" class=\"data row3 col7\" >73.77%</td>\n",
       "      <td id=\"T_6acd5_row3_col8\" class=\"data row3 col8\" >73.77%</td>\n",
       "      <td id=\"T_6acd5_row3_col9\" class=\"data row3 col9\" >70.49%</td>\n",
       "      <td id=\"T_6acd5_row3_col10\" class=\"data row3 col10\" >62.30%</td>\n",
       "      <td id=\"T_6acd5_row3_col11\" class=\"data row3 col11\" >52.46%</td>\n",
       "      <td id=\"T_6acd5_row3_col12\" class=\"data row3 col12\" >50.82%</td>\n",
       "      <td id=\"T_6acd5_row3_col13\" class=\"data row3 col13\" >80.33%</td>\n",
       "      <td id=\"T_6acd5_row3_col14\" class=\"data row3 col14\" >59.02%</td>\n",
       "      <td id=\"T_6acd5_row3_col15\" class=\"data row3 col15\" >63.17%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6acd5_level0_row4\" class=\"row_heading level0 row4\" rowspan=\"2\">random forest</th>\n",
       "      <th id=\"T_6acd5_level1_row4\" class=\"row_heading level1 row4\" rowspan=\"2\">P</th>\n",
       "      <th id=\"T_6acd5_level2_row4\" class=\"row_heading level2 row4\" >False</th>\n",
       "      <th id=\"T_6acd5_level3_row4\" class=\"row_heading level3 row4\" >False</th>\n",
       "      <td id=\"T_6acd5_row4_col0\" class=\"data row4 col0\" >60.66%</td>\n",
       "      <td id=\"T_6acd5_row4_col1\" class=\"data row4 col1\" >45.90%</td>\n",
       "      <td id=\"T_6acd5_row4_col2\" class=\"data row4 col2\" >59.02%</td>\n",
       "      <td id=\"T_6acd5_row4_col3\" class=\"data row4 col3\" >65.57%</td>\n",
       "      <td id=\"T_6acd5_row4_col4\" class=\"data row4 col4\" >68.85%</td>\n",
       "      <td id=\"T_6acd5_row4_col5\" class=\"data row4 col5\" >54.10%</td>\n",
       "      <td id=\"T_6acd5_row4_col6\" class=\"data row4 col6\" >75.41%</td>\n",
       "      <td id=\"T_6acd5_row4_col7\" class=\"data row4 col7\" >73.77%</td>\n",
       "      <td id=\"T_6acd5_row4_col8\" class=\"data row4 col8\" >72.13%</td>\n",
       "      <td id=\"T_6acd5_row4_col9\" class=\"data row4 col9\" >65.57%</td>\n",
       "      <td id=\"T_6acd5_row4_col10\" class=\"data row4 col10\" >65.57%</td>\n",
       "      <td id=\"T_6acd5_row4_col11\" class=\"data row4 col11\" >57.38%</td>\n",
       "      <td id=\"T_6acd5_row4_col12\" class=\"data row4 col12\" >50.82%</td>\n",
       "      <td id=\"T_6acd5_row4_col13\" class=\"data row4 col13\" >80.33%</td>\n",
       "      <td id=\"T_6acd5_row4_col14\" class=\"data row4 col14\" >52.46%</td>\n",
       "      <td id=\"T_6acd5_row4_col15\" class=\"data row4 col15\" >63.17%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6acd5_level2_row5\" class=\"row_heading level2 row5\" >True</th>\n",
       "      <th id=\"T_6acd5_level3_row5\" class=\"row_heading level3 row5\" >False</th>\n",
       "      <td id=\"T_6acd5_row5_col0\" class=\"data row5 col0\" >62.30%</td>\n",
       "      <td id=\"T_6acd5_row5_col1\" class=\"data row5 col1\" >49.18%</td>\n",
       "      <td id=\"T_6acd5_row5_col2\" class=\"data row5 col2\" >60.66%</td>\n",
       "      <td id=\"T_6acd5_row5_col3\" class=\"data row5 col3\" >70.49%</td>\n",
       "      <td id=\"T_6acd5_row5_col4\" class=\"data row5 col4\" >70.49%</td>\n",
       "      <td id=\"T_6acd5_row5_col5\" class=\"data row5 col5\" >52.46%</td>\n",
       "      <td id=\"T_6acd5_row5_col6\" class=\"data row5 col6\" >75.41%</td>\n",
       "      <td id=\"T_6acd5_row5_col7\" class=\"data row5 col7\" >73.77%</td>\n",
       "      <td id=\"T_6acd5_row5_col8\" class=\"data row5 col8\" >72.13%</td>\n",
       "      <td id=\"T_6acd5_row5_col9\" class=\"data row5 col9\" >63.93%</td>\n",
       "      <td id=\"T_6acd5_row5_col10\" class=\"data row5 col10\" >59.02%</td>\n",
       "      <td id=\"T_6acd5_row5_col11\" class=\"data row5 col11\" >52.46%</td>\n",
       "      <td id=\"T_6acd5_row5_col12\" class=\"data row5 col12\" >49.18%</td>\n",
       "      <td id=\"T_6acd5_row5_col13\" class=\"data row5 col13\" >80.33%</td>\n",
       "      <td id=\"T_6acd5_row5_col14\" class=\"data row5 col14\" >57.38%</td>\n",
       "      <td id=\"T_6acd5_row5_col15\" class=\"data row5 col15\" >63.28%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6acd5_level0_row6\" class=\"row_heading level0 row6\" >svm</th>\n",
       "      <th id=\"T_6acd5_level1_row6\" class=\"row_heading level1 row6\" >F</th>\n",
       "      <th id=\"T_6acd5_level2_row6\" class=\"row_heading level2 row6\" >True</th>\n",
       "      <th id=\"T_6acd5_level3_row6\" class=\"row_heading level3 row6\" >True</th>\n",
       "      <td id=\"T_6acd5_row6_col0\" class=\"data row6 col0\" >55.74%</td>\n",
       "      <td id=\"T_6acd5_row6_col1\" class=\"data row6 col1\" >47.54%</td>\n",
       "      <td id=\"T_6acd5_row6_col2\" class=\"data row6 col2\" >52.46%</td>\n",
       "      <td id=\"T_6acd5_row6_col3\" class=\"data row6 col3\" >68.85%</td>\n",
       "      <td id=\"T_6acd5_row6_col4\" class=\"data row6 col4\" >72.13%</td>\n",
       "      <td id=\"T_6acd5_row6_col5\" class=\"data row6 col5\" >54.10%</td>\n",
       "      <td id=\"T_6acd5_row6_col6\" class=\"data row6 col6\" >75.41%</td>\n",
       "      <td id=\"T_6acd5_row6_col7\" class=\"data row6 col7\" >73.77%</td>\n",
       "      <td id=\"T_6acd5_row6_col8\" class=\"data row6 col8\" >73.77%</td>\n",
       "      <td id=\"T_6acd5_row6_col9\" class=\"data row6 col9\" >68.85%</td>\n",
       "      <td id=\"T_6acd5_row6_col10\" class=\"data row6 col10\" >63.93%</td>\n",
       "      <td id=\"T_6acd5_row6_col11\" class=\"data row6 col11\" >50.82%</td>\n",
       "      <td id=\"T_6acd5_row6_col12\" class=\"data row6 col12\" >50.82%</td>\n",
       "      <td id=\"T_6acd5_row6_col13\" class=\"data row6 col13\" >80.33%</td>\n",
       "      <td id=\"T_6acd5_row6_col14\" class=\"data row6 col14\" >62.30%</td>\n",
       "      <td id=\"T_6acd5_row6_col15\" class=\"data row6 col15\" >63.39%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6acd5_level0_row7\" class=\"row_heading level0 row7\" rowspan=\"2\">logistic</th>\n",
       "      <th id=\"T_6acd5_level1_row7\" class=\"row_heading level1 row7\" >P</th>\n",
       "      <th id=\"T_6acd5_level2_row7\" class=\"row_heading level2 row7\" >True</th>\n",
       "      <th id=\"T_6acd5_level3_row7\" class=\"row_heading level3 row7\" >True</th>\n",
       "      <td id=\"T_6acd5_row7_col0\" class=\"data row7 col0\" >57.38%</td>\n",
       "      <td id=\"T_6acd5_row7_col1\" class=\"data row7 col1\" >49.18%</td>\n",
       "      <td id=\"T_6acd5_row7_col2\" class=\"data row7 col2\" >63.93%</td>\n",
       "      <td id=\"T_6acd5_row7_col3\" class=\"data row7 col3\" >72.13%</td>\n",
       "      <td id=\"T_6acd5_row7_col4\" class=\"data row7 col4\" >68.85%</td>\n",
       "      <td id=\"T_6acd5_row7_col5\" class=\"data row7 col5\" >55.74%</td>\n",
       "      <td id=\"T_6acd5_row7_col6\" class=\"data row7 col6\" >73.77%</td>\n",
       "      <td id=\"T_6acd5_row7_col7\" class=\"data row7 col7\" >65.57%</td>\n",
       "      <td id=\"T_6acd5_row7_col8\" class=\"data row7 col8\" >62.30%</td>\n",
       "      <td id=\"T_6acd5_row7_col9\" class=\"data row7 col9\" >70.49%</td>\n",
       "      <td id=\"T_6acd5_row7_col10\" class=\"data row7 col10\" >63.93%</td>\n",
       "      <td id=\"T_6acd5_row7_col11\" class=\"data row7 col11\" >60.66%</td>\n",
       "      <td id=\"T_6acd5_row7_col12\" class=\"data row7 col12\" >49.18%</td>\n",
       "      <td id=\"T_6acd5_row7_col13\" class=\"data row7 col13\" >78.69%</td>\n",
       "      <td id=\"T_6acd5_row7_col14\" class=\"data row7 col14\" >60.66%</td>\n",
       "      <td id=\"T_6acd5_row7_col15\" class=\"data row7 col15\" >63.50%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6acd5_level1_row8\" class=\"row_heading level1 row8\" >F</th>\n",
       "      <th id=\"T_6acd5_level2_row8\" class=\"row_heading level2 row8\" >False</th>\n",
       "      <th id=\"T_6acd5_level3_row8\" class=\"row_heading level3 row8\" >False</th>\n",
       "      <td id=\"T_6acd5_row8_col0\" class=\"data row8 col0\" >60.66%</td>\n",
       "      <td id=\"T_6acd5_row8_col1\" class=\"data row8 col1\" >47.54%</td>\n",
       "      <td id=\"T_6acd5_row8_col2\" class=\"data row8 col2\" >59.02%</td>\n",
       "      <td id=\"T_6acd5_row8_col3\" class=\"data row8 col3\" >67.21%</td>\n",
       "      <td id=\"T_6acd5_row8_col4\" class=\"data row8 col4\" >68.85%</td>\n",
       "      <td id=\"T_6acd5_row8_col5\" class=\"data row8 col5\" >52.46%</td>\n",
       "      <td id=\"T_6acd5_row8_col6\" class=\"data row8 col6\" >75.41%</td>\n",
       "      <td id=\"T_6acd5_row8_col7\" class=\"data row8 col7\" >70.49%</td>\n",
       "      <td id=\"T_6acd5_row8_col8\" class=\"data row8 col8\" >73.77%</td>\n",
       "      <td id=\"T_6acd5_row8_col9\" class=\"data row8 col9\" >68.85%</td>\n",
       "      <td id=\"T_6acd5_row8_col10\" class=\"data row8 col10\" >60.66%</td>\n",
       "      <td id=\"T_6acd5_row8_col11\" class=\"data row8 col11\" >52.46%</td>\n",
       "      <td id=\"T_6acd5_row8_col12\" class=\"data row8 col12\" >49.18%</td>\n",
       "      <td id=\"T_6acd5_row8_col13\" class=\"data row8 col13\" >85.25%</td>\n",
       "      <td id=\"T_6acd5_row8_col14\" class=\"data row8 col14\" >60.66%</td>\n",
       "      <td id=\"T_6acd5_row8_col15\" class=\"data row8 col15\" >63.50%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6acd5_level0_row9\" class=\"row_heading level0 row9\" >svm</th>\n",
       "      <th id=\"T_6acd5_level1_row9\" class=\"row_heading level1 row9\" >F</th>\n",
       "      <th id=\"T_6acd5_level2_row9\" class=\"row_heading level2 row9\" >False</th>\n",
       "      <th id=\"T_6acd5_level3_row9\" class=\"row_heading level3 row9\" >True</th>\n",
       "      <td id=\"T_6acd5_row9_col0\" class=\"data row9 col0\" >55.74%</td>\n",
       "      <td id=\"T_6acd5_row9_col1\" class=\"data row9 col1\" >47.54%</td>\n",
       "      <td id=\"T_6acd5_row9_col2\" class=\"data row9 col2\" >52.46%</td>\n",
       "      <td id=\"T_6acd5_row9_col3\" class=\"data row9 col3\" >68.85%</td>\n",
       "      <td id=\"T_6acd5_row9_col4\" class=\"data row9 col4\" >73.77%</td>\n",
       "      <td id=\"T_6acd5_row9_col5\" class=\"data row9 col5\" >54.10%</td>\n",
       "      <td id=\"T_6acd5_row9_col6\" class=\"data row9 col6\" >75.41%</td>\n",
       "      <td id=\"T_6acd5_row9_col7\" class=\"data row9 col7\" >73.77%</td>\n",
       "      <td id=\"T_6acd5_row9_col8\" class=\"data row9 col8\" >73.77%</td>\n",
       "      <td id=\"T_6acd5_row9_col9\" class=\"data row9 col9\" >68.85%</td>\n",
       "      <td id=\"T_6acd5_row9_col10\" class=\"data row9 col10\" >62.30%</td>\n",
       "      <td id=\"T_6acd5_row9_col11\" class=\"data row9 col11\" >50.82%</td>\n",
       "      <td id=\"T_6acd5_row9_col12\" class=\"data row9 col12\" >50.82%</td>\n",
       "      <td id=\"T_6acd5_row9_col13\" class=\"data row9 col13\" >80.33%</td>\n",
       "      <td id=\"T_6acd5_row9_col14\" class=\"data row9 col14\" >63.93%</td>\n",
       "      <td id=\"T_6acd5_row9_col15\" class=\"data row9 col15\" >63.50%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6acd5_level0_row10\" class=\"row_heading level0 row10\" rowspan=\"2\">logistic</th>\n",
       "      <th id=\"T_6acd5_level1_row10\" class=\"row_heading level1 row10\" rowspan=\"2\">P</th>\n",
       "      <th id=\"T_6acd5_level2_row10\" class=\"row_heading level2 row10\" >False</th>\n",
       "      <th id=\"T_6acd5_level3_row10\" class=\"row_heading level3 row10\" >False</th>\n",
       "      <td id=\"T_6acd5_row10_col0\" class=\"data row10 col0\" >57.38%</td>\n",
       "      <td id=\"T_6acd5_row10_col1\" class=\"data row10 col1\" >47.54%</td>\n",
       "      <td id=\"T_6acd5_row10_col2\" class=\"data row10 col2\" >62.30%</td>\n",
       "      <td id=\"T_6acd5_row10_col3\" class=\"data row10 col3\" >67.21%</td>\n",
       "      <td id=\"T_6acd5_row10_col4\" class=\"data row10 col4\" >72.13%</td>\n",
       "      <td id=\"T_6acd5_row10_col5\" class=\"data row10 col5\" >52.46%</td>\n",
       "      <td id=\"T_6acd5_row10_col6\" class=\"data row10 col6\" >75.41%</td>\n",
       "      <td id=\"T_6acd5_row10_col7\" class=\"data row10 col7\" >70.49%</td>\n",
       "      <td id=\"T_6acd5_row10_col8\" class=\"data row10 col8\" >73.77%</td>\n",
       "      <td id=\"T_6acd5_row10_col9\" class=\"data row10 col9\" >67.21%</td>\n",
       "      <td id=\"T_6acd5_row10_col10\" class=\"data row10 col10\" >62.30%</td>\n",
       "      <td id=\"T_6acd5_row10_col11\" class=\"data row10 col11\" >52.46%</td>\n",
       "      <td id=\"T_6acd5_row10_col12\" class=\"data row10 col12\" >50.82%</td>\n",
       "      <td id=\"T_6acd5_row10_col13\" class=\"data row10 col13\" >85.25%</td>\n",
       "      <td id=\"T_6acd5_row10_col14\" class=\"data row10 col14\" >57.38%</td>\n",
       "      <td id=\"T_6acd5_row10_col15\" class=\"data row10 col15\" >63.61%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6acd5_level2_row11\" class=\"row_heading level2 row11\" >True</th>\n",
       "      <th id=\"T_6acd5_level3_row11\" class=\"row_heading level3 row11\" >False</th>\n",
       "      <td id=\"T_6acd5_row11_col0\" class=\"data row11 col0\" >65.57%</td>\n",
       "      <td id=\"T_6acd5_row11_col1\" class=\"data row11 col1\" >47.54%</td>\n",
       "      <td id=\"T_6acd5_row11_col2\" class=\"data row11 col2\" >62.30%</td>\n",
       "      <td id=\"T_6acd5_row11_col3\" class=\"data row11 col3\" >68.85%</td>\n",
       "      <td id=\"T_6acd5_row11_col4\" class=\"data row11 col4\" >67.21%</td>\n",
       "      <td id=\"T_6acd5_row11_col5\" class=\"data row11 col5\" >52.46%</td>\n",
       "      <td id=\"T_6acd5_row11_col6\" class=\"data row11 col6\" >75.41%</td>\n",
       "      <td id=\"T_6acd5_row11_col7\" class=\"data row11 col7\" >70.49%</td>\n",
       "      <td id=\"T_6acd5_row11_col8\" class=\"data row11 col8\" >72.13%</td>\n",
       "      <td id=\"T_6acd5_row11_col9\" class=\"data row11 col9\" >65.57%</td>\n",
       "      <td id=\"T_6acd5_row11_col10\" class=\"data row11 col10\" >60.66%</td>\n",
       "      <td id=\"T_6acd5_row11_col11\" class=\"data row11 col11\" >54.10%</td>\n",
       "      <td id=\"T_6acd5_row11_col12\" class=\"data row11 col12\" >50.82%</td>\n",
       "      <td id=\"T_6acd5_row11_col13\" class=\"data row11 col13\" >81.97%</td>\n",
       "      <td id=\"T_6acd5_row11_col14\" class=\"data row11 col14\" >60.66%</td>\n",
       "      <td id=\"T_6acd5_row11_col15\" class=\"data row11 col15\" >63.72%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6acd5_level0_row12\" class=\"row_heading level0 row12\" rowspan=\"3\">svm</th>\n",
       "      <th id=\"T_6acd5_level1_row12\" class=\"row_heading level1 row12\" >P</th>\n",
       "      <th id=\"T_6acd5_level2_row12\" class=\"row_heading level2 row12\" >False</th>\n",
       "      <th id=\"T_6acd5_level3_row12\" class=\"row_heading level3 row12\" >False</th>\n",
       "      <td id=\"T_6acd5_row12_col0\" class=\"data row12 col0\" >63.93%</td>\n",
       "      <td id=\"T_6acd5_row12_col1\" class=\"data row12 col1\" >47.54%</td>\n",
       "      <td id=\"T_6acd5_row12_col2\" class=\"data row12 col2\" >67.21%</td>\n",
       "      <td id=\"T_6acd5_row12_col3\" class=\"data row12 col3\" >67.21%</td>\n",
       "      <td id=\"T_6acd5_row12_col4\" class=\"data row12 col4\" >77.05%</td>\n",
       "      <td id=\"T_6acd5_row12_col5\" class=\"data row12 col5\" >54.10%</td>\n",
       "      <td id=\"T_6acd5_row12_col6\" class=\"data row12 col6\" >75.41%</td>\n",
       "      <td id=\"T_6acd5_row12_col7\" class=\"data row12 col7\" >73.77%</td>\n",
       "      <td id=\"T_6acd5_row12_col8\" class=\"data row12 col8\" >73.77%</td>\n",
       "      <td id=\"T_6acd5_row12_col9\" class=\"data row12 col9\" >67.21%</td>\n",
       "      <td id=\"T_6acd5_row12_col10\" class=\"data row12 col10\" >54.10%</td>\n",
       "      <td id=\"T_6acd5_row12_col11\" class=\"data row12 col11\" >52.46%</td>\n",
       "      <td id=\"T_6acd5_row12_col12\" class=\"data row12 col12\" >49.18%</td>\n",
       "      <td id=\"T_6acd5_row12_col13\" class=\"data row12 col13\" >81.97%</td>\n",
       "      <td id=\"T_6acd5_row12_col14\" class=\"data row12 col14\" >54.10%</td>\n",
       "      <td id=\"T_6acd5_row12_col15\" class=\"data row12 col15\" >63.93%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6acd5_level1_row13\" class=\"row_heading level1 row13\" rowspan=\"2\">F</th>\n",
       "      <th id=\"T_6acd5_level2_row13\" class=\"row_heading level2 row13\" >True</th>\n",
       "      <th id=\"T_6acd5_level3_row13\" class=\"row_heading level3 row13\" >False</th>\n",
       "      <td id=\"T_6acd5_row13_col0\" class=\"data row13 col0\" >63.93%</td>\n",
       "      <td id=\"T_6acd5_row13_col1\" class=\"data row13 col1\" >47.54%</td>\n",
       "      <td id=\"T_6acd5_row13_col2\" class=\"data row13 col2\" >67.21%</td>\n",
       "      <td id=\"T_6acd5_row13_col3\" class=\"data row13 col3\" >68.85%</td>\n",
       "      <td id=\"T_6acd5_row13_col4\" class=\"data row13 col4\" >73.77%</td>\n",
       "      <td id=\"T_6acd5_row13_col5\" class=\"data row13 col5\" >54.10%</td>\n",
       "      <td id=\"T_6acd5_row13_col6\" class=\"data row13 col6\" >75.41%</td>\n",
       "      <td id=\"T_6acd5_row13_col7\" class=\"data row13 col7\" >73.77%</td>\n",
       "      <td id=\"T_6acd5_row13_col8\" class=\"data row13 col8\" >73.77%</td>\n",
       "      <td id=\"T_6acd5_row13_col9\" class=\"data row13 col9\" >67.21%</td>\n",
       "      <td id=\"T_6acd5_row13_col10\" class=\"data row13 col10\" >54.10%</td>\n",
       "      <td id=\"T_6acd5_row13_col11\" class=\"data row13 col11\" >52.46%</td>\n",
       "      <td id=\"T_6acd5_row13_col12\" class=\"data row13 col12\" >49.18%</td>\n",
       "      <td id=\"T_6acd5_row13_col13\" class=\"data row13 col13\" >81.97%</td>\n",
       "      <td id=\"T_6acd5_row13_col14\" class=\"data row13 col14\" >57.38%</td>\n",
       "      <td id=\"T_6acd5_row13_col15\" class=\"data row13 col15\" >64.04%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6acd5_level2_row14\" class=\"row_heading level2 row14\" >False</th>\n",
       "      <th id=\"T_6acd5_level3_row14\" class=\"row_heading level3 row14\" >False</th>\n",
       "      <td id=\"T_6acd5_row14_col0\" class=\"data row14 col0\" >63.93%</td>\n",
       "      <td id=\"T_6acd5_row14_col1\" class=\"data row14 col1\" >47.54%</td>\n",
       "      <td id=\"T_6acd5_row14_col2\" class=\"data row14 col2\" >68.85%</td>\n",
       "      <td id=\"T_6acd5_row14_col3\" class=\"data row14 col3\" >67.21%</td>\n",
       "      <td id=\"T_6acd5_row14_col4\" class=\"data row14 col4\" >77.05%</td>\n",
       "      <td id=\"T_6acd5_row14_col5\" class=\"data row14 col5\" >54.10%</td>\n",
       "      <td id=\"T_6acd5_row14_col6\" class=\"data row14 col6\" >75.41%</td>\n",
       "      <td id=\"T_6acd5_row14_col7\" class=\"data row14 col7\" >73.77%</td>\n",
       "      <td id=\"T_6acd5_row14_col8\" class=\"data row14 col8\" >73.77%</td>\n",
       "      <td id=\"T_6acd5_row14_col9\" class=\"data row14 col9\" >67.21%</td>\n",
       "      <td id=\"T_6acd5_row14_col10\" class=\"data row14 col10\" >54.10%</td>\n",
       "      <td id=\"T_6acd5_row14_col11\" class=\"data row14 col11\" >52.46%</td>\n",
       "      <td id=\"T_6acd5_row14_col12\" class=\"data row14 col12\" >49.18%</td>\n",
       "      <td id=\"T_6acd5_row14_col13\" class=\"data row14 col13\" >81.97%</td>\n",
       "      <td id=\"T_6acd5_row14_col14\" class=\"data row14 col14\" >55.74%</td>\n",
       "      <td id=\"T_6acd5_row14_col15\" class=\"data row14 col15\" >64.15%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6acd5_level0_row15\" class=\"row_heading level0 row15\" >random forest</th>\n",
       "      <th id=\"T_6acd5_level1_row15\" class=\"row_heading level1 row15\" >P</th>\n",
       "      <th id=\"T_6acd5_level2_row15\" class=\"row_heading level2 row15\" >True</th>\n",
       "      <th id=\"T_6acd5_level3_row15\" class=\"row_heading level3 row15\" >True</th>\n",
       "      <td id=\"T_6acd5_row15_col0\" class=\"data row15 col0\" >59.02%</td>\n",
       "      <td id=\"T_6acd5_row15_col1\" class=\"data row15 col1\" >49.18%</td>\n",
       "      <td id=\"T_6acd5_row15_col2\" class=\"data row15 col2\" >55.74%</td>\n",
       "      <td id=\"T_6acd5_row15_col3\" class=\"data row15 col3\" >70.49%</td>\n",
       "      <td id=\"T_6acd5_row15_col4\" class=\"data row15 col4\" >68.85%</td>\n",
       "      <td id=\"T_6acd5_row15_col5\" class=\"data row15 col5\" >59.02%</td>\n",
       "      <td id=\"T_6acd5_row15_col6\" class=\"data row15 col6\" >72.13%</td>\n",
       "      <td id=\"T_6acd5_row15_col7\" class=\"data row15 col7\" >72.13%</td>\n",
       "      <td id=\"T_6acd5_row15_col8\" class=\"data row15 col8\" >70.49%</td>\n",
       "      <td id=\"T_6acd5_row15_col9\" class=\"data row15 col9\" >67.21%</td>\n",
       "      <td id=\"T_6acd5_row15_col10\" class=\"data row15 col10\" >67.21%</td>\n",
       "      <td id=\"T_6acd5_row15_col11\" class=\"data row15 col11\" >52.46%</td>\n",
       "      <td id=\"T_6acd5_row15_col12\" class=\"data row15 col12\" >52.46%</td>\n",
       "      <td id=\"T_6acd5_row15_col13\" class=\"data row15 col13\" >81.97%</td>\n",
       "      <td id=\"T_6acd5_row15_col14\" class=\"data row15 col14\" >63.93%</td>\n",
       "      <td id=\"T_6acd5_row15_col15\" class=\"data row15 col15\" >64.15%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6acd5_level0_row16\" class=\"row_heading level0 row16\" >svm</th>\n",
       "      <th id=\"T_6acd5_level1_row16\" class=\"row_heading level1 row16\" >P</th>\n",
       "      <th id=\"T_6acd5_level2_row16\" class=\"row_heading level2 row16\" >True</th>\n",
       "      <th id=\"T_6acd5_level3_row16\" class=\"row_heading level3 row16\" >False</th>\n",
       "      <td id=\"T_6acd5_row16_col0\" class=\"data row16 col0\" >67.21%</td>\n",
       "      <td id=\"T_6acd5_row16_col1\" class=\"data row16 col1\" >47.54%</td>\n",
       "      <td id=\"T_6acd5_row16_col2\" class=\"data row16 col2\" >67.21%</td>\n",
       "      <td id=\"T_6acd5_row16_col3\" class=\"data row16 col3\" >68.85%</td>\n",
       "      <td id=\"T_6acd5_row16_col4\" class=\"data row16 col4\" >75.41%</td>\n",
       "      <td id=\"T_6acd5_row16_col5\" class=\"data row16 col5\" >54.10%</td>\n",
       "      <td id=\"T_6acd5_row16_col6\" class=\"data row16 col6\" >75.41%</td>\n",
       "      <td id=\"T_6acd5_row16_col7\" class=\"data row16 col7\" >73.77%</td>\n",
       "      <td id=\"T_6acd5_row16_col8\" class=\"data row16 col8\" >73.77%</td>\n",
       "      <td id=\"T_6acd5_row16_col9\" class=\"data row16 col9\" >67.21%</td>\n",
       "      <td id=\"T_6acd5_row16_col10\" class=\"data row16 col10\" >54.10%</td>\n",
       "      <td id=\"T_6acd5_row16_col11\" class=\"data row16 col11\" >52.46%</td>\n",
       "      <td id=\"T_6acd5_row16_col12\" class=\"data row16 col12\" >49.18%</td>\n",
       "      <td id=\"T_6acd5_row16_col13\" class=\"data row16 col13\" >80.33%</td>\n",
       "      <td id=\"T_6acd5_row16_col14\" class=\"data row16 col14\" >57.38%</td>\n",
       "      <td id=\"T_6acd5_row16_col15\" class=\"data row16 col15\" >64.26%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6acd5_level0_row17\" class=\"row_heading level0 row17\" >random forest</th>\n",
       "      <th id=\"T_6acd5_level1_row17\" class=\"row_heading level1 row17\" >F</th>\n",
       "      <th id=\"T_6acd5_level2_row17\" class=\"row_heading level2 row17\" >False</th>\n",
       "      <th id=\"T_6acd5_level3_row17\" class=\"row_heading level3 row17\" >True</th>\n",
       "      <td id=\"T_6acd5_row17_col0\" class=\"data row17 col0\" >60.66%</td>\n",
       "      <td id=\"T_6acd5_row17_col1\" class=\"data row17 col1\" >47.54%</td>\n",
       "      <td id=\"T_6acd5_row17_col2\" class=\"data row17 col2\" >52.46%</td>\n",
       "      <td id=\"T_6acd5_row17_col3\" class=\"data row17 col3\" >75.41%</td>\n",
       "      <td id=\"T_6acd5_row17_col4\" class=\"data row17 col4\" >68.85%</td>\n",
       "      <td id=\"T_6acd5_row17_col5\" class=\"data row17 col5\" >54.10%</td>\n",
       "      <td id=\"T_6acd5_row17_col6\" class=\"data row17 col6\" >75.41%</td>\n",
       "      <td id=\"T_6acd5_row17_col7\" class=\"data row17 col7\" >73.77%</td>\n",
       "      <td id=\"T_6acd5_row17_col8\" class=\"data row17 col8\" >72.13%</td>\n",
       "      <td id=\"T_6acd5_row17_col9\" class=\"data row17 col9\" >68.85%</td>\n",
       "      <td id=\"T_6acd5_row17_col10\" class=\"data row17 col10\" >68.85%</td>\n",
       "      <td id=\"T_6acd5_row17_col11\" class=\"data row17 col11\" >49.18%</td>\n",
       "      <td id=\"T_6acd5_row17_col12\" class=\"data row17 col12\" >49.18%</td>\n",
       "      <td id=\"T_6acd5_row17_col13\" class=\"data row17 col13\" >81.97%</td>\n",
       "      <td id=\"T_6acd5_row17_col14\" class=\"data row17 col14\" >65.57%</td>\n",
       "      <td id=\"T_6acd5_row17_col15\" class=\"data row17 col15\" >64.26%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6acd5_level0_row18\" class=\"row_heading level0 row18\" rowspan=\"3\">logistic</th>\n",
       "      <th id=\"T_6acd5_level1_row18\" class=\"row_heading level1 row18\" rowspan=\"3\">F</th>\n",
       "      <th id=\"T_6acd5_level2_row18\" class=\"row_heading level2 row18\" rowspan=\"2\">True</th>\n",
       "      <th id=\"T_6acd5_level3_row18\" class=\"row_heading level3 row18\" >True</th>\n",
       "      <td id=\"T_6acd5_row18_col0\" class=\"data row18 col0\" >55.74%</td>\n",
       "      <td id=\"T_6acd5_row18_col1\" class=\"data row18 col1\" >42.62%</td>\n",
       "      <td id=\"T_6acd5_row18_col2\" class=\"data row18 col2\" >60.66%</td>\n",
       "      <td id=\"T_6acd5_row18_col3\" class=\"data row18 col3\" >73.77%</td>\n",
       "      <td id=\"T_6acd5_row18_col4\" class=\"data row18 col4\" >72.13%</td>\n",
       "      <td id=\"T_6acd5_row18_col5\" class=\"data row18 col5\" >54.10%</td>\n",
       "      <td id=\"T_6acd5_row18_col6\" class=\"data row18 col6\" >75.41%</td>\n",
       "      <td id=\"T_6acd5_row18_col7\" class=\"data row18 col7\" >70.49%</td>\n",
       "      <td id=\"T_6acd5_row18_col8\" class=\"data row18 col8\" >65.57%</td>\n",
       "      <td id=\"T_6acd5_row18_col9\" class=\"data row18 col9\" >68.85%</td>\n",
       "      <td id=\"T_6acd5_row18_col10\" class=\"data row18 col10\" >68.85%</td>\n",
       "      <td id=\"T_6acd5_row18_col11\" class=\"data row18 col11\" >62.30%</td>\n",
       "      <td id=\"T_6acd5_row18_col12\" class=\"data row18 col12\" >52.46%</td>\n",
       "      <td id=\"T_6acd5_row18_col13\" class=\"data row18 col13\" >80.33%</td>\n",
       "      <td id=\"T_6acd5_row18_col14\" class=\"data row18 col14\" >62.30%</td>\n",
       "      <td id=\"T_6acd5_row18_col15\" class=\"data row18 col15\" >64.37%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6acd5_level3_row19\" class=\"row_heading level3 row19\" >False</th>\n",
       "      <td id=\"T_6acd5_row19_col0\" class=\"data row19 col0\" >65.57%</td>\n",
       "      <td id=\"T_6acd5_row19_col1\" class=\"data row19 col1\" >47.54%</td>\n",
       "      <td id=\"T_6acd5_row19_col2\" class=\"data row19 col2\" >62.30%</td>\n",
       "      <td id=\"T_6acd5_row19_col3\" class=\"data row19 col3\" >68.85%</td>\n",
       "      <td id=\"T_6acd5_row19_col4\" class=\"data row19 col4\" >67.21%</td>\n",
       "      <td id=\"T_6acd5_row19_col5\" class=\"data row19 col5\" >54.10%</td>\n",
       "      <td id=\"T_6acd5_row19_col6\" class=\"data row19 col6\" >75.41%</td>\n",
       "      <td id=\"T_6acd5_row19_col7\" class=\"data row19 col7\" >70.49%</td>\n",
       "      <td id=\"T_6acd5_row19_col8\" class=\"data row19 col8\" >72.13%</td>\n",
       "      <td id=\"T_6acd5_row19_col9\" class=\"data row19 col9\" >68.85%</td>\n",
       "      <td id=\"T_6acd5_row19_col10\" class=\"data row19 col10\" >62.30%</td>\n",
       "      <td id=\"T_6acd5_row19_col11\" class=\"data row19 col11\" >54.10%</td>\n",
       "      <td id=\"T_6acd5_row19_col12\" class=\"data row19 col12\" >52.46%</td>\n",
       "      <td id=\"T_6acd5_row19_col13\" class=\"data row19 col13\" >81.97%</td>\n",
       "      <td id=\"T_6acd5_row19_col14\" class=\"data row19 col14\" >62.30%</td>\n",
       "      <td id=\"T_6acd5_row19_col15\" class=\"data row19 col15\" >64.37%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6acd5_level2_row20\" class=\"row_heading level2 row20\" >False</th>\n",
       "      <th id=\"T_6acd5_level3_row20\" class=\"row_heading level3 row20\" >True</th>\n",
       "      <td id=\"T_6acd5_row20_col0\" class=\"data row20 col0\" >57.38%</td>\n",
       "      <td id=\"T_6acd5_row20_col1\" class=\"data row20 col1\" >40.98%</td>\n",
       "      <td id=\"T_6acd5_row20_col2\" class=\"data row20 col2\" >60.66%</td>\n",
       "      <td id=\"T_6acd5_row20_col3\" class=\"data row20 col3\" >73.77%</td>\n",
       "      <td id=\"T_6acd5_row20_col4\" class=\"data row20 col4\" >70.49%</td>\n",
       "      <td id=\"T_6acd5_row20_col5\" class=\"data row20 col5\" >52.46%</td>\n",
       "      <td id=\"T_6acd5_row20_col6\" class=\"data row20 col6\" >75.41%</td>\n",
       "      <td id=\"T_6acd5_row20_col7\" class=\"data row20 col7\" >70.49%</td>\n",
       "      <td id=\"T_6acd5_row20_col8\" class=\"data row20 col8\" >65.57%</td>\n",
       "      <td id=\"T_6acd5_row20_col9\" class=\"data row20 col9\" >70.49%</td>\n",
       "      <td id=\"T_6acd5_row20_col10\" class=\"data row20 col10\" >70.49%</td>\n",
       "      <td id=\"T_6acd5_row20_col11\" class=\"data row20 col11\" >60.66%</td>\n",
       "      <td id=\"T_6acd5_row20_col12\" class=\"data row20 col12\" >54.10%</td>\n",
       "      <td id=\"T_6acd5_row20_col13\" class=\"data row20 col13\" >81.97%</td>\n",
       "      <td id=\"T_6acd5_row20_col14\" class=\"data row20 col14\" >63.93%</td>\n",
       "      <td id=\"T_6acd5_row20_col15\" class=\"data row20 col15\" >64.59%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6acd5_level0_row21\" class=\"row_heading level0 row21\" rowspan=\"3\">random forest</th>\n",
       "      <th id=\"T_6acd5_level1_row21\" class=\"row_heading level1 row21\" >P</th>\n",
       "      <th id=\"T_6acd5_level2_row21\" class=\"row_heading level2 row21\" >False</th>\n",
       "      <th id=\"T_6acd5_level3_row21\" class=\"row_heading level3 row21\" >True</th>\n",
       "      <td id=\"T_6acd5_row21_col0\" class=\"data row21 col0\" >62.30%</td>\n",
       "      <td id=\"T_6acd5_row21_col1\" class=\"data row21 col1\" >45.90%</td>\n",
       "      <td id=\"T_6acd5_row21_col2\" class=\"data row21 col2\" >59.02%</td>\n",
       "      <td id=\"T_6acd5_row21_col3\" class=\"data row21 col3\" >73.77%</td>\n",
       "      <td id=\"T_6acd5_row21_col4\" class=\"data row21 col4\" >65.57%</td>\n",
       "      <td id=\"T_6acd5_row21_col5\" class=\"data row21 col5\" >59.02%</td>\n",
       "      <td id=\"T_6acd5_row21_col6\" class=\"data row21 col6\" >75.41%</td>\n",
       "      <td id=\"T_6acd5_row21_col7\" class=\"data row21 col7\" >72.13%</td>\n",
       "      <td id=\"T_6acd5_row21_col8\" class=\"data row21 col8\" >70.49%</td>\n",
       "      <td id=\"T_6acd5_row21_col9\" class=\"data row21 col9\" >68.85%</td>\n",
       "      <td id=\"T_6acd5_row21_col10\" class=\"data row21 col10\" >63.93%</td>\n",
       "      <td id=\"T_6acd5_row21_col11\" class=\"data row21 col11\" >54.10%</td>\n",
       "      <td id=\"T_6acd5_row21_col12\" class=\"data row21 col12\" >50.82%</td>\n",
       "      <td id=\"T_6acd5_row21_col13\" class=\"data row21 col13\" >80.33%</td>\n",
       "      <td id=\"T_6acd5_row21_col14\" class=\"data row21 col14\" >68.85%</td>\n",
       "      <td id=\"T_6acd5_row21_col15\" class=\"data row21 col15\" >64.70%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6acd5_level1_row22\" class=\"row_heading level1 row22\" rowspan=\"2\">F</th>\n",
       "      <th id=\"T_6acd5_level2_row22\" class=\"row_heading level2 row22\" rowspan=\"2\">True</th>\n",
       "      <th id=\"T_6acd5_level3_row22\" class=\"row_heading level3 row22\" >False</th>\n",
       "      <td id=\"T_6acd5_row22_col0\" class=\"data row22 col0\" >62.30%</td>\n",
       "      <td id=\"T_6acd5_row22_col1\" class=\"data row22 col1\" >47.54%</td>\n",
       "      <td id=\"T_6acd5_row22_col2\" class=\"data row22 col2\" >62.30%</td>\n",
       "      <td id=\"T_6acd5_row22_col3\" class=\"data row22 col3\" >72.13%</td>\n",
       "      <td id=\"T_6acd5_row22_col4\" class=\"data row22 col4\" >72.13%</td>\n",
       "      <td id=\"T_6acd5_row22_col5\" class=\"data row22 col5\" >54.10%</td>\n",
       "      <td id=\"T_6acd5_row22_col6\" class=\"data row22 col6\" >75.41%</td>\n",
       "      <td id=\"T_6acd5_row22_col7\" class=\"data row22 col7\" >72.13%</td>\n",
       "      <td id=\"T_6acd5_row22_col8\" class=\"data row22 col8\" >73.77%</td>\n",
       "      <td id=\"T_6acd5_row22_col9\" class=\"data row22 col9\" >68.85%</td>\n",
       "      <td id=\"T_6acd5_row22_col10\" class=\"data row22 col10\" >68.85%</td>\n",
       "      <td id=\"T_6acd5_row22_col11\" class=\"data row22 col11\" >57.38%</td>\n",
       "      <td id=\"T_6acd5_row22_col12\" class=\"data row22 col12\" >50.82%</td>\n",
       "      <td id=\"T_6acd5_row22_col13\" class=\"data row22 col13\" >81.97%</td>\n",
       "      <td id=\"T_6acd5_row22_col14\" class=\"data row22 col14\" >52.46%</td>\n",
       "      <td id=\"T_6acd5_row22_col15\" class=\"data row22 col15\" >64.81%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6acd5_level3_row23\" class=\"row_heading level3 row23\" >True</th>\n",
       "      <td id=\"T_6acd5_row23_col0\" class=\"data row23 col0\" >62.30%</td>\n",
       "      <td id=\"T_6acd5_row23_col1\" class=\"data row23 col1\" >44.26%</td>\n",
       "      <td id=\"T_6acd5_row23_col2\" class=\"data row23 col2\" >60.66%</td>\n",
       "      <td id=\"T_6acd5_row23_col3\" class=\"data row23 col3\" >75.41%</td>\n",
       "      <td id=\"T_6acd5_row23_col4\" class=\"data row23 col4\" >72.13%</td>\n",
       "      <td id=\"T_6acd5_row23_col5\" class=\"data row23 col5\" >59.02%</td>\n",
       "      <td id=\"T_6acd5_row23_col6\" class=\"data row23 col6\" >77.05%</td>\n",
       "      <td id=\"T_6acd5_row23_col7\" class=\"data row23 col7\" >68.85%</td>\n",
       "      <td id=\"T_6acd5_row23_col8\" class=\"data row23 col8\" >70.49%</td>\n",
       "      <td id=\"T_6acd5_row23_col9\" class=\"data row23 col9\" >70.49%</td>\n",
       "      <td id=\"T_6acd5_row23_col10\" class=\"data row23 col10\" >67.21%</td>\n",
       "      <td id=\"T_6acd5_row23_col11\" class=\"data row23 col11\" >49.18%</td>\n",
       "      <td id=\"T_6acd5_row23_col12\" class=\"data row23 col12\" >50.82%</td>\n",
       "      <td id=\"T_6acd5_row23_col13\" class=\"data row23 col13\" >83.61%</td>\n",
       "      <td id=\"T_6acd5_row23_col14\" class=\"data row23 col14\" >63.93%</td>\n",
       "      <td id=\"T_6acd5_row23_col15\" class=\"data row23 col15\" >65.03%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f1a583ebe50>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performances.xs(\"test\", level=1).sort_values(\"AVG\").style.format(\"{:.2%}\").background_gradient(\"Greens\", axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We only consider adjactive of each argument "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      wrong naked much stupid wrong younger uncomfor...\n",
       "1                                     unusable least new\n",
       "2                                                       \n",
       "3      obvious avaible other significant different be...\n",
       "4                   old more less such young better best\n",
       "                             ...                        \n",
       "298                                             key same\n",
       "299                                                     \n",
       "300    strong military bad territorial tense due terr...\n",
       "301                          important positive negative\n",
       "302                 mandatory active involved good other\n",
       "Name: Document, Length: 303, dtype: object"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def adj_to_string(x):\n",
    "    return \" \".join(word.text.lower() for sentence in x.sentences for word in sentence.words if word.upos == \"ADJ\")\n",
    "sentences = AGGREGATED[\"Document\"].apply(adj_to_string)\n",
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rick/.anaconda/envs/rick/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(tokenizer=str.split, min_df=5)\n",
    "X = vectorizer.fit_transform(sentences)\n",
    "Y = AGGREGATED[\"EM\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7953795379537953"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogisticRegression()\n",
    "model.fit(X, Y)\n",
    "\n",
    "model.score(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 51)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.coef_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "level_1 = model.coef_[0]\n",
    "level_2 = model.coef_[1]\n",
    "level_3 = model.coef_[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    0.775578\n",
       "1    0.155116\n",
       "3    0.069307\n",
       "Name: EM, dtype: float64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('right', -0.5724581107304583),\n",
       " ('much', -0.4893313943945828),\n",
       " ('best', -0.4399044782956019),\n",
       " ('other', -0.43936750426715143),\n",
       " ('married', -0.40599306427492954),\n",
       " ('bad', -0.3766454188809203),\n",
       " ('different', -0.35504787381739766),\n",
       " ('scientific', -0.29622515253204773),\n",
       " ('common', -0.2951293714246473),\n",
       " ('unborn', -0.2744693274951817),\n",
       " ('human', -0.24112641215279956),\n",
       " ('little', -0.24098577795741882),\n",
       " ('long', -0.23024469631108688),\n",
       " ('equal', -0.21479448522851072),\n",
       " ('such', -0.20833531006904674),\n",
       " ('least', -0.2002910428069758),\n",
       " ('new', -0.19498927355869258),\n",
       " ('physical', -0.18101024371275906),\n",
       " ('certain', -0.17624995908995905),\n",
       " ('wrong', -0.17609355039560615),\n",
       " ('real', -0.1751677784175516),\n",
       " ('selfish', -0.16789554467514922),\n",
       " ('high', -0.12772461847577568),\n",
       " ('likely', -0.12741425599392156),\n",
       " ('easy', -0.125612495674967),\n",
       " ('able', -0.1248812268934567),\n",
       " ('easier', -0.1130872952504821),\n",
       " ('good', -0.103591517178394),\n",
       " ('mandatory', -0.08705690883111065),\n",
       " ('big', -0.0696755845352129),\n",
       " ('religious', -0.04916903960225262),\n",
       " ('more', -0.027255209976224284),\n",
       " ('personal', -0.0133098207331923),\n",
       " ('same', 0.0007678056603712841),\n",
       " ('better', 0.01771793969899101),\n",
       " ('great', 0.04650961259281011),\n",
       " ('many', 0.09832427376986379),\n",
       " ('sexual', 0.14351017601999838),\n",
       " ('most', 0.18224707141784108),\n",
       " ('huge', 0.3582197193894172),\n",
       " ('whole', 0.36599479729038176),\n",
       " ('only', 0.3718351873266908),\n",
       " ('own', 0.3721787429218506),\n",
       " ('important', 0.4078054508347308),\n",
       " ('fatherless', 0.5248478543679511),\n",
       " ('involved', 0.526306064415553),\n",
       " ('happy', 0.5407868546694069),\n",
       " ('else', 0.5441513154687037),\n",
       " ('lousy', 0.5902259754374489),\n",
       " ('gay', 1.0559261646183966),\n",
       " ('less', 1.0623153711763584)]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adj = [word for word, _ in sorted(vectorizer.vocabulary_.items(), key=lambda x: x[1])]\n",
    "\n",
    "adj_weight = dict(zip(adj, level_3))\n",
    "sorted(adj_weight.items(), key=lambda x: x[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate argument quality based on different POS tags in arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def POS_tags_to_string(x, tag: str):\n",
    "    return \" \".join(word.text.lower() for sentence in x.sentences for word in sentence.words if word.upos == tag)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rick/.anaconda/envs/rick/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/home/rick/.anaconda/envs/rick/lib/python3.10/site-packages/sklearn/preprocessing/_data.py:2627: UserWarning: n_quantiles (1000) is greater than the total number of samples (242). n_quantiles is set to n_samples.\n",
      "  warnings.warn(\n",
      "/home/rick/.anaconda/envs/rick/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/home/rick/.anaconda/envs/rick/lib/python3.10/site-packages/sklearn/preprocessing/_data.py:2627: UserWarning: n_quantiles (1000) is greater than the total number of samples (242). n_quantiles is set to n_samples.\n",
      "  warnings.warn(\n",
      "/home/rick/.anaconda/envs/rick/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/home/rick/.anaconda/envs/rick/lib/python3.10/site-packages/sklearn/preprocessing/_data.py:2627: UserWarning: n_quantiles (1000) is greater than the total number of samples (242). n_quantiles is set to n_samples.\n",
      "  warnings.warn(\n",
      "/home/rick/.anaconda/envs/rick/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/home/rick/.anaconda/envs/rick/lib/python3.10/site-packages/sklearn/preprocessing/_data.py:2627: UserWarning: n_quantiles (1000) is greater than the total number of samples (242). n_quantiles is set to n_samples.\n",
      "  warnings.warn(\n",
      "/home/rick/.anaconda/envs/rick/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/home/rick/.anaconda/envs/rick/lib/python3.10/site-packages/sklearn/preprocessing/_data.py:2627: UserWarning: n_quantiles (1000) is greater than the total number of samples (242). n_quantiles is set to n_samples.\n",
      "  warnings.warn(\n",
      "/home/rick/.anaconda/envs/rick/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/home/rick/.anaconda/envs/rick/lib/python3.10/site-packages/sklearn/preprocessing/_data.py:2627: UserWarning: n_quantiles (1000) is greater than the total number of samples (242). n_quantiles is set to n_samples.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "pos_performances = pd.DataFrame(index=pd.MultiIndex.from_product(\n",
    "    [[\"logistic\"], [\"train\", \"test\"], [\"ADJ\", \"ADV\", \"INTJ\", \"NOUN\", \"PROPN\", \"VERB\"]],\n",
    "    names=[\"method\", \"section\", \"pos\"])\n",
    ")\n",
    "\n",
    "for method in [\"logistic\"]:\n",
    "    # get the appropriate columns and to string functions\n",
    "    Classifier = {\n",
    "        \"logistic\": LogisticRegression\n",
    "    }[method]\n",
    "\n",
    "    # training and evaluating\n",
    "\n",
    "    train_column = TRAIN_DATASET[\"Document\"]\n",
    "    test_column = TEST_DATASET[\"Document\"]\n",
    "\n",
    "    train_text = TRAIN_DATASET[\"Plain Words\"]\n",
    "    test_text = TEST_DATASET[\"Plain Words\"]\n",
    "\n",
    "    tok_vectorizer = TfidfVectorizer(tokenizer=str.split, stop_words=\"english\")\n",
    "\n",
    "    train_x = tok_vectorizer.fit_transform(train_text.apply(words_to_string))\n",
    "    test_x = tok_vectorizer.transform(test_text.apply(words_to_string))\n",
    "\n",
    "    for pos in [\"ADJ\", \"ADV\", \"INTJ\", \"NOUN\", \"PROPN\", \"VERB\"]:\n",
    "        # keep only needed POS tags if needed\n",
    "        pos_vectorizer = CountVectorizer(tokenizer=str.split)\n",
    "        transformer = QuantileTransformer()\n",
    "\n",
    "        train_x = hstack((train_x, transformer.fit_transform(pos_vectorizer.fit_transform(train_column.apply(POS_tags_to_string, tag=pos)))))\n",
    "        test_x = hstack((test_x, transformer.transform(pos_vectorizer.transform(test_column.apply(POS_tags_to_string, tag=pos)))))\n",
    "\n",
    "        # training and evaluating\n",
    "        for dimension in AGGREGATED.columns[4:4 + 15]:\n",
    "            model = Classifier()\n",
    "            model.fit(train_x, TRAIN_DATASET[dimension])\n",
    "\n",
    "            train_score = model.score(train_x, TRAIN_DATASET[dimension])\n",
    "            test_score = model.score(test_x, TEST_DATASET[dimension])\n",
    "\n",
    "            pos_performances.loc[(method, \"train\", pos), dimension] = train_score\n",
    "            pos_performances.loc[(method, \"test\", pos), dimension] = test_score\n",
    "\n",
    "pos_performances[\"AVG\"] = pos_performances.mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      wrong naked much stupid wrong younger uncomfor...\n",
       "1                                     unusable least new\n",
       "2                                                       \n",
       "3      obvious avaible other significant different be...\n",
       "4                   old more less such young better best\n",
       "                             ...                        \n",
       "298                                             key same\n",
       "299                                                     \n",
       "300    strong military bad territorial tense due terr...\n",
       "301                          important positive negative\n",
       "302                 mandatory active involved good other\n",
       "Name: Document, Length: 303, dtype: object"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AGGREGATED[\"Document\"].apply(POS_tags_to_string, tag=\"ADJ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_7530d_row0_col0, #T_7530d_row1_col9, #T_7530d_row1_col14 {\n",
       "  background-color: #abd0e6;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_7530d_row0_col1, #T_7530d_row0_col2, #T_7530d_row0_col3, #T_7530d_row0_col4, #T_7530d_row0_col5, #T_7530d_row0_col6, #T_7530d_row0_col7, #T_7530d_row0_col8, #T_7530d_row0_col9, #T_7530d_row0_col10, #T_7530d_row0_col11, #T_7530d_row0_col12, #T_7530d_row0_col13, #T_7530d_row0_col14, #T_7530d_row0_col15, #T_7530d_row1_col0, #T_7530d_row2_col0, #T_7530d_row2_col9, #T_7530d_row2_col14 {\n",
       "  background-color: #f7fbff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_7530d_row1_col1 {\n",
       "  background-color: #08509b;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_7530d_row1_col2 {\n",
       "  background-color: #1b69af;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_7530d_row1_col3 {\n",
       "  background-color: #89bedc;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_7530d_row1_col4, #T_7530d_row2_col4 {\n",
       "  background-color: #c6dbef;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_7530d_row1_col5, #T_7530d_row2_col1, #T_7530d_row2_col5, #T_7530d_row3_col0, #T_7530d_row3_col1, #T_7530d_row3_col2, #T_7530d_row3_col3, #T_7530d_row3_col4, #T_7530d_row3_col5, #T_7530d_row3_col7, #T_7530d_row3_col8, #T_7530d_row3_col9, #T_7530d_row3_col10, #T_7530d_row3_col11, #T_7530d_row3_col12, #T_7530d_row3_col13, #T_7530d_row3_col14, #T_7530d_row4_col0, #T_7530d_row4_col1, #T_7530d_row4_col2, #T_7530d_row4_col3, #T_7530d_row4_col4, #T_7530d_row4_col5, #T_7530d_row4_col7, #T_7530d_row4_col8, #T_7530d_row4_col9, #T_7530d_row4_col10, #T_7530d_row4_col11, #T_7530d_row4_col12, #T_7530d_row4_col13, #T_7530d_row4_col14, #T_7530d_row5_col0, #T_7530d_row5_col1, #T_7530d_row5_col2, #T_7530d_row5_col3, #T_7530d_row5_col4, #T_7530d_row5_col5, #T_7530d_row5_col6, #T_7530d_row5_col7, #T_7530d_row5_col8, #T_7530d_row5_col9, #T_7530d_row5_col10, #T_7530d_row5_col11, #T_7530d_row5_col12, #T_7530d_row5_col13, #T_7530d_row5_col14, #T_7530d_row5_col15 {\n",
       "  background-color: #08306b;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_7530d_row1_col6, #T_7530d_row2_col6 {\n",
       "  background-color: #6caed6;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_7530d_row1_col7 {\n",
       "  background-color: #60a7d2;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_7530d_row1_col8, #T_7530d_row1_col13, #T_7530d_row2_col13 {\n",
       "  background-color: #2070b4;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_7530d_row1_col10, #T_7530d_row2_col10 {\n",
       "  background-color: #6aaed6;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_7530d_row1_col11, #T_7530d_row1_col12, #T_7530d_row2_col11, #T_7530d_row2_col12 {\n",
       "  background-color: #3787c0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_7530d_row1_col15, #T_7530d_row2_col7 {\n",
       "  background-color: #4a98c9;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_7530d_row2_col2 {\n",
       "  background-color: #084d96;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_7530d_row2_col3 {\n",
       "  background-color: #539ecd;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_7530d_row2_col8 {\n",
       "  background-color: #105ba4;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_7530d_row2_col15 {\n",
       "  background-color: #4090c5;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_7530d_row3_col6, #T_7530d_row4_col6 {\n",
       "  background-color: #084a91;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_7530d_row3_col15, #T_7530d_row4_col15 {\n",
       "  background-color: #08326e;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_7530d\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank\" >&nbsp;</th>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_7530d_level0_col0\" class=\"col_heading level0 col0\" >CO</th>\n",
       "      <th id=\"T_7530d_level0_col1\" class=\"col_heading level0 col1\" >LA</th>\n",
       "      <th id=\"T_7530d_level0_col2\" class=\"col_heading level0 col2\" >LR</th>\n",
       "      <th id=\"T_7530d_level0_col3\" class=\"col_heading level0 col3\" >LS</th>\n",
       "      <th id=\"T_7530d_level0_col4\" class=\"col_heading level0 col4\" >EF</th>\n",
       "      <th id=\"T_7530d_level0_col5\" class=\"col_heading level0 col5\" >CR</th>\n",
       "      <th id=\"T_7530d_level0_col6\" class=\"col_heading level0 col6\" >EM</th>\n",
       "      <th id=\"T_7530d_level0_col7\" class=\"col_heading level0 col7\" >CL</th>\n",
       "      <th id=\"T_7530d_level0_col8\" class=\"col_heading level0 col8\" >AP</th>\n",
       "      <th id=\"T_7530d_level0_col9\" class=\"col_heading level0 col9\" >AR</th>\n",
       "      <th id=\"T_7530d_level0_col10\" class=\"col_heading level0 col10\" >RE</th>\n",
       "      <th id=\"T_7530d_level0_col11\" class=\"col_heading level0 col11\" >GA</th>\n",
       "      <th id=\"T_7530d_level0_col12\" class=\"col_heading level0 col12\" >GR</th>\n",
       "      <th id=\"T_7530d_level0_col13\" class=\"col_heading level0 col13\" >GS</th>\n",
       "      <th id=\"T_7530d_level0_col14\" class=\"col_heading level0 col14\" >OV</th>\n",
       "      <th id=\"T_7530d_level0_col15\" class=\"col_heading level0 col15\" >AVG</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >method</th>\n",
       "      <th class=\"index_name level1\" >pos</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "      <th class=\"blank col1\" >&nbsp;</th>\n",
       "      <th class=\"blank col2\" >&nbsp;</th>\n",
       "      <th class=\"blank col3\" >&nbsp;</th>\n",
       "      <th class=\"blank col4\" >&nbsp;</th>\n",
       "      <th class=\"blank col5\" >&nbsp;</th>\n",
       "      <th class=\"blank col6\" >&nbsp;</th>\n",
       "      <th class=\"blank col7\" >&nbsp;</th>\n",
       "      <th class=\"blank col8\" >&nbsp;</th>\n",
       "      <th class=\"blank col9\" >&nbsp;</th>\n",
       "      <th class=\"blank col10\" >&nbsp;</th>\n",
       "      <th class=\"blank col11\" >&nbsp;</th>\n",
       "      <th class=\"blank col12\" >&nbsp;</th>\n",
       "      <th class=\"blank col13\" >&nbsp;</th>\n",
       "      <th class=\"blank col14\" >&nbsp;</th>\n",
       "      <th class=\"blank col15\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_7530d_level0_row0\" class=\"row_heading level0 row0\" rowspan=\"6\">logistic</th>\n",
       "      <th id=\"T_7530d_level1_row0\" class=\"row_heading level1 row0\" >ADJ</th>\n",
       "      <td id=\"T_7530d_row0_col0\" class=\"data row0 col0\" >99.17%</td>\n",
       "      <td id=\"T_7530d_row0_col1\" class=\"data row0 col1\" >96.69%</td>\n",
       "      <td id=\"T_7530d_row0_col2\" class=\"data row0 col2\" >96.28%</td>\n",
       "      <td id=\"T_7530d_row0_col3\" class=\"data row0 col3\" >97.11%</td>\n",
       "      <td id=\"T_7530d_row0_col4\" class=\"data row0 col4\" >98.35%</td>\n",
       "      <td id=\"T_7530d_row0_col5\" class=\"data row0 col5\" >98.35%</td>\n",
       "      <td id=\"T_7530d_row0_col6\" class=\"data row0 col6\" >95.87%</td>\n",
       "      <td id=\"T_7530d_row0_col7\" class=\"data row0 col7\" >93.80%</td>\n",
       "      <td id=\"T_7530d_row0_col8\" class=\"data row0 col8\" >95.04%</td>\n",
       "      <td id=\"T_7530d_row0_col9\" class=\"data row0 col9\" >98.76%</td>\n",
       "      <td id=\"T_7530d_row0_col10\" class=\"data row0 col10\" >99.17%</td>\n",
       "      <td id=\"T_7530d_row0_col11\" class=\"data row0 col11\" >98.76%</td>\n",
       "      <td id=\"T_7530d_row0_col12\" class=\"data row0 col12\" >96.28%</td>\n",
       "      <td id=\"T_7530d_row0_col13\" class=\"data row0 col13\" >98.35%</td>\n",
       "      <td id=\"T_7530d_row0_col14\" class=\"data row0 col14\" >98.76%</td>\n",
       "      <td id=\"T_7530d_row0_col15\" class=\"data row0 col15\" >97.38%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7530d_level1_row1\" class=\"row_heading level1 row1\" >ADV</th>\n",
       "      <td id=\"T_7530d_row1_col0\" class=\"data row1 col0\" >98.76%</td>\n",
       "      <td id=\"T_7530d_row1_col1\" class=\"data row1 col1\" >99.59%</td>\n",
       "      <td id=\"T_7530d_row1_col2\" class=\"data row1 col2\" >99.17%</td>\n",
       "      <td id=\"T_7530d_row1_col3\" class=\"data row1 col3\" >98.35%</td>\n",
       "      <td id=\"T_7530d_row1_col4\" class=\"data row1 col4\" >98.76%</td>\n",
       "      <td id=\"T_7530d_row1_col5\" class=\"data row1 col5\" >100.00%</td>\n",
       "      <td id=\"T_7530d_row1_col6\" class=\"data row1 col6\" >97.93%</td>\n",
       "      <td id=\"T_7530d_row1_col7\" class=\"data row1 col7\" >97.11%</td>\n",
       "      <td id=\"T_7530d_row1_col8\" class=\"data row1 col8\" >98.76%</td>\n",
       "      <td id=\"T_7530d_row1_col9\" class=\"data row1 col9\" >99.17%</td>\n",
       "      <td id=\"T_7530d_row1_col10\" class=\"data row1 col10\" >99.59%</td>\n",
       "      <td id=\"T_7530d_row1_col11\" class=\"data row1 col11\" >99.59%</td>\n",
       "      <td id=\"T_7530d_row1_col12\" class=\"data row1 col12\" >98.76%</td>\n",
       "      <td id=\"T_7530d_row1_col13\" class=\"data row1 col13\" >99.59%</td>\n",
       "      <td id=\"T_7530d_row1_col14\" class=\"data row1 col14\" >99.17%</td>\n",
       "      <td id=\"T_7530d_row1_col15\" class=\"data row1 col15\" >98.95%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7530d_level1_row2\" class=\"row_heading level1 row2\" >INTJ</th>\n",
       "      <td id=\"T_7530d_row2_col0\" class=\"data row2 col0\" >98.76%</td>\n",
       "      <td id=\"T_7530d_row2_col1\" class=\"data row2 col1\" >100.00%</td>\n",
       "      <td id=\"T_7530d_row2_col2\" class=\"data row2 col2\" >99.59%</td>\n",
       "      <td id=\"T_7530d_row2_col3\" class=\"data row2 col3\" >98.76%</td>\n",
       "      <td id=\"T_7530d_row2_col4\" class=\"data row2 col4\" >98.76%</td>\n",
       "      <td id=\"T_7530d_row2_col5\" class=\"data row2 col5\" >100.00%</td>\n",
       "      <td id=\"T_7530d_row2_col6\" class=\"data row2 col6\" >97.93%</td>\n",
       "      <td id=\"T_7530d_row2_col7\" class=\"data row2 col7\" >97.52%</td>\n",
       "      <td id=\"T_7530d_row2_col8\" class=\"data row2 col8\" >99.17%</td>\n",
       "      <td id=\"T_7530d_row2_col9\" class=\"data row2 col9\" >98.76%</td>\n",
       "      <td id=\"T_7530d_row2_col10\" class=\"data row2 col10\" >99.59%</td>\n",
       "      <td id=\"T_7530d_row2_col11\" class=\"data row2 col11\" >99.59%</td>\n",
       "      <td id=\"T_7530d_row2_col12\" class=\"data row2 col12\" >98.76%</td>\n",
       "      <td id=\"T_7530d_row2_col13\" class=\"data row2 col13\" >99.59%</td>\n",
       "      <td id=\"T_7530d_row2_col14\" class=\"data row2 col14\" >98.76%</td>\n",
       "      <td id=\"T_7530d_row2_col15\" class=\"data row2 col15\" >99.04%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7530d_level1_row3\" class=\"row_heading level1 row3\" >NOUN</th>\n",
       "      <td id=\"T_7530d_row3_col0\" class=\"data row3 col0\" >100.00%</td>\n",
       "      <td id=\"T_7530d_row3_col1\" class=\"data row3 col1\" >100.00%</td>\n",
       "      <td id=\"T_7530d_row3_col2\" class=\"data row3 col2\" >100.00%</td>\n",
       "      <td id=\"T_7530d_row3_col3\" class=\"data row3 col3\" >100.00%</td>\n",
       "      <td id=\"T_7530d_row3_col4\" class=\"data row3 col4\" >100.00%</td>\n",
       "      <td id=\"T_7530d_row3_col5\" class=\"data row3 col5\" >100.00%</td>\n",
       "      <td id=\"T_7530d_row3_col6\" class=\"data row3 col6\" >99.59%</td>\n",
       "      <td id=\"T_7530d_row3_col7\" class=\"data row3 col7\" >100.00%</td>\n",
       "      <td id=\"T_7530d_row3_col8\" class=\"data row3 col8\" >100.00%</td>\n",
       "      <td id=\"T_7530d_row3_col9\" class=\"data row3 col9\" >100.00%</td>\n",
       "      <td id=\"T_7530d_row3_col10\" class=\"data row3 col10\" >100.00%</td>\n",
       "      <td id=\"T_7530d_row3_col11\" class=\"data row3 col11\" >100.00%</td>\n",
       "      <td id=\"T_7530d_row3_col12\" class=\"data row3 col12\" >100.00%</td>\n",
       "      <td id=\"T_7530d_row3_col13\" class=\"data row3 col13\" >100.00%</td>\n",
       "      <td id=\"T_7530d_row3_col14\" class=\"data row3 col14\" >100.00%</td>\n",
       "      <td id=\"T_7530d_row3_col15\" class=\"data row3 col15\" >99.97%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7530d_level1_row4\" class=\"row_heading level1 row4\" >PROPN</th>\n",
       "      <td id=\"T_7530d_row4_col0\" class=\"data row4 col0\" >100.00%</td>\n",
       "      <td id=\"T_7530d_row4_col1\" class=\"data row4 col1\" >100.00%</td>\n",
       "      <td id=\"T_7530d_row4_col2\" class=\"data row4 col2\" >100.00%</td>\n",
       "      <td id=\"T_7530d_row4_col3\" class=\"data row4 col3\" >100.00%</td>\n",
       "      <td id=\"T_7530d_row4_col4\" class=\"data row4 col4\" >100.00%</td>\n",
       "      <td id=\"T_7530d_row4_col5\" class=\"data row4 col5\" >100.00%</td>\n",
       "      <td id=\"T_7530d_row4_col6\" class=\"data row4 col6\" >99.59%</td>\n",
       "      <td id=\"T_7530d_row4_col7\" class=\"data row4 col7\" >100.00%</td>\n",
       "      <td id=\"T_7530d_row4_col8\" class=\"data row4 col8\" >100.00%</td>\n",
       "      <td id=\"T_7530d_row4_col9\" class=\"data row4 col9\" >100.00%</td>\n",
       "      <td id=\"T_7530d_row4_col10\" class=\"data row4 col10\" >100.00%</td>\n",
       "      <td id=\"T_7530d_row4_col11\" class=\"data row4 col11\" >100.00%</td>\n",
       "      <td id=\"T_7530d_row4_col12\" class=\"data row4 col12\" >100.00%</td>\n",
       "      <td id=\"T_7530d_row4_col13\" class=\"data row4 col13\" >100.00%</td>\n",
       "      <td id=\"T_7530d_row4_col14\" class=\"data row4 col14\" >100.00%</td>\n",
       "      <td id=\"T_7530d_row4_col15\" class=\"data row4 col15\" >99.97%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7530d_level1_row5\" class=\"row_heading level1 row5\" >VERB</th>\n",
       "      <td id=\"T_7530d_row5_col0\" class=\"data row5 col0\" >100.00%</td>\n",
       "      <td id=\"T_7530d_row5_col1\" class=\"data row5 col1\" >100.00%</td>\n",
       "      <td id=\"T_7530d_row5_col2\" class=\"data row5 col2\" >100.00%</td>\n",
       "      <td id=\"T_7530d_row5_col3\" class=\"data row5 col3\" >100.00%</td>\n",
       "      <td id=\"T_7530d_row5_col4\" class=\"data row5 col4\" >100.00%</td>\n",
       "      <td id=\"T_7530d_row5_col5\" class=\"data row5 col5\" >100.00%</td>\n",
       "      <td id=\"T_7530d_row5_col6\" class=\"data row5 col6\" >100.00%</td>\n",
       "      <td id=\"T_7530d_row5_col7\" class=\"data row5 col7\" >100.00%</td>\n",
       "      <td id=\"T_7530d_row5_col8\" class=\"data row5 col8\" >100.00%</td>\n",
       "      <td id=\"T_7530d_row5_col9\" class=\"data row5 col9\" >100.00%</td>\n",
       "      <td id=\"T_7530d_row5_col10\" class=\"data row5 col10\" >100.00%</td>\n",
       "      <td id=\"T_7530d_row5_col11\" class=\"data row5 col11\" >100.00%</td>\n",
       "      <td id=\"T_7530d_row5_col12\" class=\"data row5 col12\" >100.00%</td>\n",
       "      <td id=\"T_7530d_row5_col13\" class=\"data row5 col13\" >100.00%</td>\n",
       "      <td id=\"T_7530d_row5_col14\" class=\"data row5 col14\" >100.00%</td>\n",
       "      <td id=\"T_7530d_row5_col15\" class=\"data row5 col15\" >100.00%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f1a0bc61ed0>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_performances.xs(\"train\", level=1).style.format(\"{:.2%}\").background_gradient(\"Blues\", axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_d9a25_row0_col0, #T_d9a25_row0_col6, #T_d9a25_row4_col6 {\n",
       "  background-color: #75c477;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d9a25_row0_col1, #T_d9a25_row0_col3, #T_d9a25_row0_col4, #T_d9a25_row0_col5, #T_d9a25_row0_col9, #T_d9a25_row0_col10, #T_d9a25_row0_col11, #T_d9a25_row0_col13, #T_d9a25_row0_col14, #T_d9a25_row0_col15, #T_d9a25_row1_col6, #T_d9a25_row1_col12, #T_d9a25_row1_col13, #T_d9a25_row2_col6, #T_d9a25_row2_col13, #T_d9a25_row3_col8, #T_d9a25_row4_col1, #T_d9a25_row4_col2, #T_d9a25_row4_col7, #T_d9a25_row4_col11, #T_d9a25_row4_col13, #T_d9a25_row5_col0, #T_d9a25_row5_col2, #T_d9a25_row5_col6, #T_d9a25_row5_col7, #T_d9a25_row5_col13 {\n",
       "  background-color: #f7fcf5;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d9a25_row0_col2, #T_d9a25_row1_col1, #T_d9a25_row1_col2, #T_d9a25_row2_col1, #T_d9a25_row2_col2, #T_d9a25_row5_col11 {\n",
       "  background-color: #73c476;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d9a25_row0_col7 {\n",
       "  background-color: #157f3b;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d9a25_row0_col8, #T_d9a25_row1_col9, #T_d9a25_row1_col11, #T_d9a25_row1_col14, #T_d9a25_row2_col0, #T_d9a25_row2_col3, #T_d9a25_row2_col4, #T_d9a25_row2_col7, #T_d9a25_row2_col11, #T_d9a25_row2_col14, #T_d9a25_row2_col15, #T_d9a25_row3_col2, #T_d9a25_row3_col5, #T_d9a25_row3_col6, #T_d9a25_row3_col13, #T_d9a25_row4_col5, #T_d9a25_row5_col1, #T_d9a25_row5_col10, #T_d9a25_row5_col12 {\n",
       "  background-color: #00441b;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d9a25_row0_col12, #T_d9a25_row3_col9, #T_d9a25_row3_col12, #T_d9a25_row4_col12 {\n",
       "  background-color: #8ed08b;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d9a25_row1_col0 {\n",
       "  background-color: #0b7734;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d9a25_row1_col3 {\n",
       "  background-color: #006227;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d9a25_row1_col4, #T_d9a25_row1_col5, #T_d9a25_row2_col5, #T_d9a25_row5_col4, #T_d9a25_row5_col5 {\n",
       "  background-color: #05712f;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d9a25_row1_col7 {\n",
       "  background-color: #4bb062;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d9a25_row1_col8, #T_d9a25_row2_col8 {\n",
       "  background-color: #ceecc8;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d9a25_row1_col10, #T_d9a25_row2_col10 {\n",
       "  background-color: #cbebc5;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d9a25_row1_col15 {\n",
       "  background-color: #006b2b;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d9a25_row2_col9, #T_d9a25_row4_col4, #T_d9a25_row4_col9, #T_d9a25_row5_col9 {\n",
       "  background-color: #2c944c;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d9a25_row2_col12 {\n",
       "  background-color: #bce4b5;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d9a25_row3_col0, #T_d9a25_row4_col0 {\n",
       "  background-color: #37a055;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d9a25_row3_col1, #T_d9a25_row5_col8 {\n",
       "  background-color: #aedea7;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d9a25_row3_col3 {\n",
       "  background-color: #84cc83;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d9a25_row3_col4 {\n",
       "  background-color: #56b567;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d9a25_row3_col7 {\n",
       "  background-color: #d3eecd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d9a25_row3_col10 {\n",
       "  background-color: #81ca81;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d9a25_row3_col11, #T_d9a25_row3_col14, #T_d9a25_row5_col14 {\n",
       "  background-color: #c7e9c0;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d9a25_row3_col15 {\n",
       "  background-color: #60ba6c;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d9a25_row4_col3 {\n",
       "  background-color: #62bb6d;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d9a25_row4_col8 {\n",
       "  background-color: #e7f6e3;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d9a25_row4_col10 {\n",
       "  background-color: #45ad5f;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d9a25_row4_col14 {\n",
       "  background-color: #e5f5e0;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d9a25_row4_col15 {\n",
       "  background-color: #7dc87e;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d9a25_row5_col3 {\n",
       "  background-color: #107a37;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d9a25_row5_col15 {\n",
       "  background-color: #006328;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_d9a25\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank\" >&nbsp;</th>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_d9a25_level0_col0\" class=\"col_heading level0 col0\" >CO</th>\n",
       "      <th id=\"T_d9a25_level0_col1\" class=\"col_heading level0 col1\" >LA</th>\n",
       "      <th id=\"T_d9a25_level0_col2\" class=\"col_heading level0 col2\" >LR</th>\n",
       "      <th id=\"T_d9a25_level0_col3\" class=\"col_heading level0 col3\" >LS</th>\n",
       "      <th id=\"T_d9a25_level0_col4\" class=\"col_heading level0 col4\" >EF</th>\n",
       "      <th id=\"T_d9a25_level0_col5\" class=\"col_heading level0 col5\" >CR</th>\n",
       "      <th id=\"T_d9a25_level0_col6\" class=\"col_heading level0 col6\" >EM</th>\n",
       "      <th id=\"T_d9a25_level0_col7\" class=\"col_heading level0 col7\" >CL</th>\n",
       "      <th id=\"T_d9a25_level0_col8\" class=\"col_heading level0 col8\" >AP</th>\n",
       "      <th id=\"T_d9a25_level0_col9\" class=\"col_heading level0 col9\" >AR</th>\n",
       "      <th id=\"T_d9a25_level0_col10\" class=\"col_heading level0 col10\" >RE</th>\n",
       "      <th id=\"T_d9a25_level0_col11\" class=\"col_heading level0 col11\" >GA</th>\n",
       "      <th id=\"T_d9a25_level0_col12\" class=\"col_heading level0 col12\" >GR</th>\n",
       "      <th id=\"T_d9a25_level0_col13\" class=\"col_heading level0 col13\" >GS</th>\n",
       "      <th id=\"T_d9a25_level0_col14\" class=\"col_heading level0 col14\" >OV</th>\n",
       "      <th id=\"T_d9a25_level0_col15\" class=\"col_heading level0 col15\" >AVG</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >method</th>\n",
       "      <th class=\"index_name level1\" >pos</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "      <th class=\"blank col1\" >&nbsp;</th>\n",
       "      <th class=\"blank col2\" >&nbsp;</th>\n",
       "      <th class=\"blank col3\" >&nbsp;</th>\n",
       "      <th class=\"blank col4\" >&nbsp;</th>\n",
       "      <th class=\"blank col5\" >&nbsp;</th>\n",
       "      <th class=\"blank col6\" >&nbsp;</th>\n",
       "      <th class=\"blank col7\" >&nbsp;</th>\n",
       "      <th class=\"blank col8\" >&nbsp;</th>\n",
       "      <th class=\"blank col9\" >&nbsp;</th>\n",
       "      <th class=\"blank col10\" >&nbsp;</th>\n",
       "      <th class=\"blank col11\" >&nbsp;</th>\n",
       "      <th class=\"blank col12\" >&nbsp;</th>\n",
       "      <th class=\"blank col13\" >&nbsp;</th>\n",
       "      <th class=\"blank col14\" >&nbsp;</th>\n",
       "      <th class=\"blank col15\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_d9a25_level0_row0\" class=\"row_heading level0 row0\" rowspan=\"6\">logistic</th>\n",
       "      <th id=\"T_d9a25_level1_row0\" class=\"row_heading level1 row0\" >ADJ</th>\n",
       "      <td id=\"T_d9a25_row0_col0\" class=\"data row0 col0\" >65.57%</td>\n",
       "      <td id=\"T_d9a25_row0_col1\" class=\"data row0 col1\" >49.18%</td>\n",
       "      <td id=\"T_d9a25_row0_col2\" class=\"data row0 col2\" >59.02%</td>\n",
       "      <td id=\"T_d9a25_row0_col3\" class=\"data row0 col3\" >62.30%</td>\n",
       "      <td id=\"T_d9a25_row0_col4\" class=\"data row0 col4\" >63.93%</td>\n",
       "      <td id=\"T_d9a25_row0_col5\" class=\"data row0 col5\" >47.54%</td>\n",
       "      <td id=\"T_d9a25_row0_col6\" class=\"data row0 col6\" >75.41%</td>\n",
       "      <td id=\"T_d9a25_row0_col7\" class=\"data row0 col7\" >72.13%</td>\n",
       "      <td id=\"T_d9a25_row0_col8\" class=\"data row0 col8\" >77.05%</td>\n",
       "      <td id=\"T_d9a25_row0_col9\" class=\"data row0 col9\" >55.74%</td>\n",
       "      <td id=\"T_d9a25_row0_col10\" class=\"data row0 col10\" >50.82%</td>\n",
       "      <td id=\"T_d9a25_row0_col11\" class=\"data row0 col11\" >50.82%</td>\n",
       "      <td id=\"T_d9a25_row0_col12\" class=\"data row0 col12\" >47.54%</td>\n",
       "      <td id=\"T_d9a25_row0_col13\" class=\"data row0 col13\" >81.97%</td>\n",
       "      <td id=\"T_d9a25_row0_col14\" class=\"data row0 col14\" >55.74%</td>\n",
       "      <td id=\"T_d9a25_row0_col15\" class=\"data row0 col15\" >60.98%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d9a25_level1_row1\" class=\"row_heading level1 row1\" >ADV</th>\n",
       "      <td id=\"T_d9a25_row1_col0\" class=\"data row1 col0\" >68.85%</td>\n",
       "      <td id=\"T_d9a25_row1_col1\" class=\"data row1 col1\" >54.10%</td>\n",
       "      <td id=\"T_d9a25_row1_col2\" class=\"data row1 col2\" >59.02%</td>\n",
       "      <td id=\"T_d9a25_row1_col3\" class=\"data row1 col3\" >78.69%</td>\n",
       "      <td id=\"T_d9a25_row1_col4\" class=\"data row1 col4\" >73.77%</td>\n",
       "      <td id=\"T_d9a25_row1_col5\" class=\"data row1 col5\" >57.38%</td>\n",
       "      <td id=\"T_d9a25_row1_col6\" class=\"data row1 col6\" >73.77%</td>\n",
       "      <td id=\"T_d9a25_row1_col7\" class=\"data row1 col7\" >70.49%</td>\n",
       "      <td id=\"T_d9a25_row1_col8\" class=\"data row1 col8\" >65.57%</td>\n",
       "      <td id=\"T_d9a25_row1_col9\" class=\"data row1 col9\" >67.21%</td>\n",
       "      <td id=\"T_d9a25_row1_col10\" class=\"data row1 col10\" >55.74%</td>\n",
       "      <td id=\"T_d9a25_row1_col11\" class=\"data row1 col11\" >57.38%</td>\n",
       "      <td id=\"T_d9a25_row1_col12\" class=\"data row1 col12\" >42.62%</td>\n",
       "      <td id=\"T_d9a25_row1_col13\" class=\"data row1 col13\" >81.97%</td>\n",
       "      <td id=\"T_d9a25_row1_col14\" class=\"data row1 col14\" >68.85%</td>\n",
       "      <td id=\"T_d9a25_row1_col15\" class=\"data row1 col15\" >65.03%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d9a25_level1_row2\" class=\"row_heading level1 row2\" >INTJ</th>\n",
       "      <td id=\"T_d9a25_row2_col0\" class=\"data row2 col0\" >70.49%</td>\n",
       "      <td id=\"T_d9a25_row2_col1\" class=\"data row2 col1\" >54.10%</td>\n",
       "      <td id=\"T_d9a25_row2_col2\" class=\"data row2 col2\" >59.02%</td>\n",
       "      <td id=\"T_d9a25_row2_col3\" class=\"data row2 col3\" >80.33%</td>\n",
       "      <td id=\"T_d9a25_row2_col4\" class=\"data row2 col4\" >75.41%</td>\n",
       "      <td id=\"T_d9a25_row2_col5\" class=\"data row2 col5\" >57.38%</td>\n",
       "      <td id=\"T_d9a25_row2_col6\" class=\"data row2 col6\" >73.77%</td>\n",
       "      <td id=\"T_d9a25_row2_col7\" class=\"data row2 col7\" >73.77%</td>\n",
       "      <td id=\"T_d9a25_row2_col8\" class=\"data row2 col8\" >65.57%</td>\n",
       "      <td id=\"T_d9a25_row2_col9\" class=\"data row2 col9\" >63.93%</td>\n",
       "      <td id=\"T_d9a25_row2_col10\" class=\"data row2 col10\" >55.74%</td>\n",
       "      <td id=\"T_d9a25_row2_col11\" class=\"data row2 col11\" >57.38%</td>\n",
       "      <td id=\"T_d9a25_row2_col12\" class=\"data row2 col12\" >45.90%</td>\n",
       "      <td id=\"T_d9a25_row2_col13\" class=\"data row2 col13\" >81.97%</td>\n",
       "      <td id=\"T_d9a25_row2_col14\" class=\"data row2 col14\" >68.85%</td>\n",
       "      <td id=\"T_d9a25_row2_col15\" class=\"data row2 col15\" >65.57%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d9a25_level1_row3\" class=\"row_heading level1 row3\" >NOUN</th>\n",
       "      <td id=\"T_d9a25_row3_col0\" class=\"data row3 col0\" >67.21%</td>\n",
       "      <td id=\"T_d9a25_row3_col1\" class=\"data row3 col1\" >52.46%</td>\n",
       "      <td id=\"T_d9a25_row3_col2\" class=\"data row3 col2\" >60.66%</td>\n",
       "      <td id=\"T_d9a25_row3_col3\" class=\"data row3 col3\" >70.49%</td>\n",
       "      <td id=\"T_d9a25_row3_col4\" class=\"data row3 col4\" >70.49%</td>\n",
       "      <td id=\"T_d9a25_row3_col5\" class=\"data row3 col5\" >59.02%</td>\n",
       "      <td id=\"T_d9a25_row3_col6\" class=\"data row3 col6\" >77.05%</td>\n",
       "      <td id=\"T_d9a25_row3_col7\" class=\"data row3 col7\" >67.21%</td>\n",
       "      <td id=\"T_d9a25_row3_col8\" class=\"data row3 col8\" >62.30%</td>\n",
       "      <td id=\"T_d9a25_row3_col9\" class=\"data row3 col9\" >60.66%</td>\n",
       "      <td id=\"T_d9a25_row3_col10\" class=\"data row3 col10\" >60.66%</td>\n",
       "      <td id=\"T_d9a25_row3_col11\" class=\"data row3 col11\" >52.46%</td>\n",
       "      <td id=\"T_d9a25_row3_col12\" class=\"data row3 col12\" >47.54%</td>\n",
       "      <td id=\"T_d9a25_row3_col13\" class=\"data row3 col13\" >85.25%</td>\n",
       "      <td id=\"T_d9a25_row3_col14\" class=\"data row3 col14\" >59.02%</td>\n",
       "      <td id=\"T_d9a25_row3_col15\" class=\"data row3 col15\" >63.50%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d9a25_level1_row4\" class=\"row_heading level1 row4\" >PROPN</th>\n",
       "      <td id=\"T_d9a25_row4_col0\" class=\"data row4 col0\" >67.21%</td>\n",
       "      <td id=\"T_d9a25_row4_col1\" class=\"data row4 col1\" >49.18%</td>\n",
       "      <td id=\"T_d9a25_row4_col2\" class=\"data row4 col2\" >57.38%</td>\n",
       "      <td id=\"T_d9a25_row4_col3\" class=\"data row4 col3\" >72.13%</td>\n",
       "      <td id=\"T_d9a25_row4_col4\" class=\"data row4 col4\" >72.13%</td>\n",
       "      <td id=\"T_d9a25_row4_col5\" class=\"data row4 col5\" >59.02%</td>\n",
       "      <td id=\"T_d9a25_row4_col6\" class=\"data row4 col6\" >75.41%</td>\n",
       "      <td id=\"T_d9a25_row4_col7\" class=\"data row4 col7\" >65.57%</td>\n",
       "      <td id=\"T_d9a25_row4_col8\" class=\"data row4 col8\" >63.93%</td>\n",
       "      <td id=\"T_d9a25_row4_col9\" class=\"data row4 col9\" >63.93%</td>\n",
       "      <td id=\"T_d9a25_row4_col10\" class=\"data row4 col10\" >63.93%</td>\n",
       "      <td id=\"T_d9a25_row4_col11\" class=\"data row4 col11\" >50.82%</td>\n",
       "      <td id=\"T_d9a25_row4_col12\" class=\"data row4 col12\" >47.54%</td>\n",
       "      <td id=\"T_d9a25_row4_col13\" class=\"data row4 col13\" >81.97%</td>\n",
       "      <td id=\"T_d9a25_row4_col14\" class=\"data row4 col14\" >57.38%</td>\n",
       "      <td id=\"T_d9a25_row4_col15\" class=\"data row4 col15\" >63.17%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d9a25_level1_row5\" class=\"row_heading level1 row5\" >VERB</th>\n",
       "      <td id=\"T_d9a25_row5_col0\" class=\"data row5 col0\" >60.66%</td>\n",
       "      <td id=\"T_d9a25_row5_col1\" class=\"data row5 col1\" >59.02%</td>\n",
       "      <td id=\"T_d9a25_row5_col2\" class=\"data row5 col2\" >57.38%</td>\n",
       "      <td id=\"T_d9a25_row5_col3\" class=\"data row5 col3\" >77.05%</td>\n",
       "      <td id=\"T_d9a25_row5_col4\" class=\"data row5 col4\" >73.77%</td>\n",
       "      <td id=\"T_d9a25_row5_col5\" class=\"data row5 col5\" >57.38%</td>\n",
       "      <td id=\"T_d9a25_row5_col6\" class=\"data row5 col6\" >73.77%</td>\n",
       "      <td id=\"T_d9a25_row5_col7\" class=\"data row5 col7\" >65.57%</td>\n",
       "      <td id=\"T_d9a25_row5_col8\" class=\"data row5 col8\" >67.21%</td>\n",
       "      <td id=\"T_d9a25_row5_col9\" class=\"data row5 col9\" >63.93%</td>\n",
       "      <td id=\"T_d9a25_row5_col10\" class=\"data row5 col10\" >72.13%</td>\n",
       "      <td id=\"T_d9a25_row5_col11\" class=\"data row5 col11\" >54.10%</td>\n",
       "      <td id=\"T_d9a25_row5_col12\" class=\"data row5 col12\" >54.10%</td>\n",
       "      <td id=\"T_d9a25_row5_col13\" class=\"data row5 col13\" >81.97%</td>\n",
       "      <td id=\"T_d9a25_row5_col14\" class=\"data row5 col14\" >59.02%</td>\n",
       "      <td id=\"T_d9a25_row5_col15\" class=\"data row5 col15\" >65.14%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f1a45fb57b0>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_performances.xs(\"test\", level=1).style.format(\"{:.2%}\").background_gradient(\"Greens\", axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate argument quality based on different pos tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rick/.anaconda/envs/rick/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/home/rick/.anaconda/envs/rick/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/rick/.anaconda/envs/rick/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/rick/.anaconda/envs/rick/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/rick/.anaconda/envs/rick/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/rick/.anaconda/envs/rick/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/rick/.anaconda/envs/rick/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/rick/.anaconda/envs/rick/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/rick/.anaconda/envs/rick/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/rick/.anaconda/envs/rick/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/rick/.anaconda/envs/rick/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/rick/.anaconda/envs/rick/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/rick/.anaconda/envs/rick/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/rick/.anaconda/envs/rick/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/rick/.anaconda/envs/rick/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/rick/.anaconda/envs/rick/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# Evaluate pos tags weights on argument quality dimension based on logistic regression\n",
    "\n",
    "train_pos = TRAIN_DATASET[\"Plain Words\"]\n",
    "test_pos = TEST_DATASET[\"Plain Words\"]\n",
    "\n",
    "pos_vectorizer = CountVectorizer(tokenizer=str.split, min_df=0.6)\n",
    "\n",
    "train_x = pos_vectorizer.fit_transform(train_pos.apply(poses_to_string))\n",
    "test_x = pos_vectorizer.transform(test_pos.apply(poses_to_string))\n",
    "\n",
    "pos_weight_dict = {}\n",
    "\n",
    "for dimensions in AGGREGATED.columns[4:4 + 15]:\n",
    "    model = LogisticRegression()\n",
    "    model.fit(train_x, TRAIN_DATASET[dimensions])\n",
    "\n",
    "    level_3 = model.coef_[2]\n",
    "    pos = [word for word, _ in sorted(pos_vectorizer.vocabulary_.items(), key=lambda x: x[1])]\n",
    "\n",
    "    pos_weight = dict(zip(pos, level_3))\n",
    "    pos_weight_dict[dimensions] = sorted(pos_weight.items(), key=lambda x: x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the weights for each dimension\n",
    "df_pos_weight_dict = pd.DataFrame.from_dict({k: dict(v) for k, v in pos_weight_dict.items()}, orient=\"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_ee25c_row0_col0, #T_ee25c_row0_col1, #T_ee25c_row0_col7, #T_ee25c_row0_col9, #T_ee25c_row0_col10, #T_ee25c_row0_col14, #T_ee25c_row2_col6, #T_ee25c_row2_col12, #T_ee25c_row3_col5, #T_ee25c_row3_col11, #T_ee25c_row4_col3, #T_ee25c_row5_col2, #T_ee25c_row8_col4, #T_ee25c_row8_col8, #T_ee25c_row9_col13 {\n",
       "  background-color: #f7fcf5;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ee25c_row0_col2, #T_ee25c_row7_col4 {\n",
       "  background-color: #a8dca2;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ee25c_row0_col3 {\n",
       "  background-color: #b0dfaa;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ee25c_row0_col4 {\n",
       "  background-color: #d4eece;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ee25c_row0_col5, #T_ee25c_row0_col11 {\n",
       "  background-color: #91d28e;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ee25c_row0_col6, #T_ee25c_row8_col13 {\n",
       "  background-color: #39a257;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ee25c_row0_col8, #T_ee25c_row1_col11 {\n",
       "  background-color: #bee5b8;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ee25c_row0_col12 {\n",
       "  background-color: #a9dca3;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ee25c_row0_col13, #T_ee25c_row1_col9, #T_ee25c_row4_col6, #T_ee25c_row6_col3, #T_ee25c_row6_col4, #T_ee25c_row6_col10, #T_ee25c_row9_col2, #T_ee25c_row9_col7, #T_ee25c_row9_col8, #T_ee25c_row9_col11, #T_ee25c_row9_col12, #T_ee25c_row9_col14, #T_ee25c_row10_col1, #T_ee25c_row10_col5, #T_ee25c_row10_col6, #T_ee25c_row11_col0 {\n",
       "  background-color: #00441b;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ee25c_row1_col0 {\n",
       "  background-color: #c4e8bd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ee25c_row1_col1 {\n",
       "  background-color: #d2edcc;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ee25c_row1_col2 {\n",
       "  background-color: #76c578;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ee25c_row1_col3 {\n",
       "  background-color: #f0f9ed;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ee25c_row1_col4, #T_ee25c_row7_col13 {\n",
       "  background-color: #147e3a;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ee25c_row1_col5, #T_ee25c_row2_col3 {\n",
       "  background-color: #8ed08b;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ee25c_row1_col6 {\n",
       "  background-color: #43ac5e;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ee25c_row1_col7 {\n",
       "  background-color: #005321;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ee25c_row1_col8, #T_ee25c_row4_col9 {\n",
       "  background-color: #c3e7bc;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ee25c_row1_col10 {\n",
       "  background-color: #b8e3b2;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ee25c_row1_col12, #T_ee25c_row11_col14 {\n",
       "  background-color: #1f8742;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ee25c_row1_col13 {\n",
       "  background-color: #127c39;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ee25c_row1_col14 {\n",
       "  background-color: #2a924a;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ee25c_row2_col0, #T_ee25c_row7_col8 {\n",
       "  background-color: #97d492;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ee25c_row2_col1 {\n",
       "  background-color: #99d595;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ee25c_row2_col2 {\n",
       "  background-color: #c9eac2;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ee25c_row2_col4, #T_ee25c_row7_col9 {\n",
       "  background-color: #6dc072;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ee25c_row2_col5 {\n",
       "  background-color: #00481d;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ee25c_row2_col7, #T_ee25c_row3_col1 {\n",
       "  background-color: #f2faf0;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ee25c_row2_col8 {\n",
       "  background-color: #eff9ec;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ee25c_row2_col9 {\n",
       "  background-color: #e0f3db;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ee25c_row2_col10, #T_ee25c_row3_col0 {\n",
       "  background-color: #73c476;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ee25c_row2_col11 {\n",
       "  background-color: #a3da9d;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ee25c_row2_col13, #T_ee25c_row9_col0 {\n",
       "  background-color: #006c2c;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ee25c_row2_col14 {\n",
       "  background-color: #3fa95c;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ee25c_row3_col2, #T_ee25c_row3_col4, #T_ee25c_row3_col8 {\n",
       "  background-color: #e6f5e1;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ee25c_row3_col3, #T_ee25c_row11_col8 {\n",
       "  background-color: #cfecc9;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ee25c_row3_col6, #T_ee25c_row6_col5 {\n",
       "  background-color: #0c7735;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ee25c_row3_col7 {\n",
       "  background-color: #87cd86;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ee25c_row3_col9, #T_ee25c_row11_col9 {\n",
       "  background-color: #3ba458;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ee25c_row3_col10 {\n",
       "  background-color: #c8e9c1;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ee25c_row3_col12 {\n",
       "  background-color: #90d18d;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ee25c_row3_col13 {\n",
       "  background-color: #4eb264;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ee25c_row3_col14 {\n",
       "  background-color: #7fc97f;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ee25c_row4_col0 {\n",
       "  background-color: #63bc6e;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ee25c_row4_col1 {\n",
       "  background-color: #19833e;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ee25c_row4_col2, #T_ee25c_row8_col3, #T_ee25c_row11_col2 {\n",
       "  background-color: #65bd6f;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ee25c_row4_col4, #T_ee25c_row4_col7 {\n",
       "  background-color: #f6fcf4;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ee25c_row4_col5 {\n",
       "  background-color: #e9f7e5;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ee25c_row4_col8 {\n",
       "  background-color: #ecf8e8;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ee25c_row4_col10 {\n",
       "  background-color: #a4da9e;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ee25c_row4_col11 {\n",
       "  background-color: #5eb96b;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ee25c_row4_col12, #T_ee25c_row6_col0 {\n",
       "  background-color: #289049;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ee25c_row4_col13 {\n",
       "  background-color: #50b264;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ee25c_row4_col14, #T_ee25c_row8_col5, #T_ee25c_row8_col10 {\n",
       "  background-color: #b1e0ab;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ee25c_row5_col0 {\n",
       "  background-color: #369f54;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ee25c_row5_col1 {\n",
       "  background-color: #b4e1ad;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ee25c_row5_col3 {\n",
       "  background-color: #6bc072;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ee25c_row5_col4 {\n",
       "  background-color: #acdea6;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ee25c_row5_col5 {\n",
       "  background-color: #0d7836;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ee25c_row5_col6 {\n",
       "  background-color: #00682a;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ee25c_row5_col7, #T_ee25c_row10_col8 {\n",
       "  background-color: #78c679;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ee25c_row5_col8 {\n",
       "  background-color: #c1e6ba;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ee25c_row5_col9, #T_ee25c_row10_col9 {\n",
       "  background-color: #45ad5f;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ee25c_row5_col10 {\n",
       "  background-color: #8bcf89;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ee25c_row5_col11 {\n",
       "  background-color: #a2d99c;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ee25c_row5_col12 {\n",
       "  background-color: #66bd6f;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ee25c_row5_col13 {\n",
       "  background-color: #1a843f;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ee25c_row5_col14, #T_ee25c_row11_col5, #T_ee25c_row11_col13 {\n",
       "  background-color: #2f974e;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ee25c_row6_col1, #T_ee25c_row8_col0 {\n",
       "  background-color: #05712f;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ee25c_row6_col2 {\n",
       "  background-color: #42ab5d;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ee25c_row6_col6 {\n",
       "  background-color: #53b466;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ee25c_row6_col7 {\n",
       "  background-color: #88ce87;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ee25c_row6_col8 {\n",
       "  background-color: #8ace88;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ee25c_row6_col9 {\n",
       "  background-color: #0b7734;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ee25c_row6_col11 {\n",
       "  background-color: #00491d;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ee25c_row6_col12, #T_ee25c_row6_col14 {\n",
       "  background-color: #006328;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ee25c_row6_col13 {\n",
       "  background-color: #016e2d;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ee25c_row7_col0 {\n",
       "  background-color: #218944;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ee25c_row7_col1, #T_ee25c_row8_col12 {\n",
       "  background-color: #48ae60;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ee25c_row7_col2 {\n",
       "  background-color: #9cd797;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ee25c_row7_col3 {\n",
       "  background-color: #c6e8bf;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ee25c_row7_col5 {\n",
       "  background-color: #ebf7e7;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ee25c_row7_col6 {\n",
       "  background-color: #359e53;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ee25c_row7_col7 {\n",
       "  background-color: #95d391;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ee25c_row7_col10 {\n",
       "  background-color: #79c67a;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ee25c_row7_col11 {\n",
       "  background-color: #6ec173;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ee25c_row7_col12, #T_ee25c_row10_col11 {\n",
       "  background-color: #56b567;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ee25c_row7_col14, #T_ee25c_row11_col11 {\n",
       "  background-color: #329b51;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ee25c_row8_col1, #T_ee25c_row10_col4, #T_ee25c_row10_col7 {\n",
       "  background-color: #72c375;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ee25c_row8_col2 {\n",
       "  background-color: #dbf1d5;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ee25c_row8_col6, #T_ee25c_row9_col10 {\n",
       "  background-color: #005522;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ee25c_row8_col7 {\n",
       "  background-color: #a0d99b;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ee25c_row8_col9 {\n",
       "  background-color: #2b934b;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ee25c_row8_col11 {\n",
       "  background-color: #d8f0d2;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ee25c_row8_col14 {\n",
       "  background-color: #3ca559;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ee25c_row9_col1 {\n",
       "  background-color: #208843;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ee25c_row9_col3 {\n",
       "  background-color: #067230;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ee25c_row9_col4 {\n",
       "  background-color: #aedea7;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ee25c_row9_col5 {\n",
       "  background-color: #9ed798;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ee25c_row9_col6, #T_ee25c_row9_col9 {\n",
       "  background-color: #5ab769;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ee25c_row10_col0 {\n",
       "  background-color: #005120;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ee25c_row10_col2 {\n",
       "  background-color: #1c8540;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ee25c_row10_col3, #T_ee25c_row11_col3 {\n",
       "  background-color: #5db96b;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ee25c_row10_col10 {\n",
       "  background-color: #258d47;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ee25c_row10_col12 {\n",
       "  background-color: #55b567;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ee25c_row10_col13 {\n",
       "  background-color: #248c46;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ee25c_row10_col14 {\n",
       "  background-color: #29914a;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ee25c_row11_col1 {\n",
       "  background-color: #46ae60;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ee25c_row11_col4 {\n",
       "  background-color: #0e7936;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ee25c_row11_col6 {\n",
       "  background-color: #006b2b;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ee25c_row11_col7 {\n",
       "  background-color: #b7e2b1;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ee25c_row11_col10 {\n",
       "  background-color: #17813d;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ee25c_row11_col12 {\n",
       "  background-color: #3ea75a;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_ee25c\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_ee25c_level0_col0\" class=\"col_heading level0 col0\" >CO</th>\n",
       "      <th id=\"T_ee25c_level0_col1\" class=\"col_heading level0 col1\" >LA</th>\n",
       "      <th id=\"T_ee25c_level0_col2\" class=\"col_heading level0 col2\" >LR</th>\n",
       "      <th id=\"T_ee25c_level0_col3\" class=\"col_heading level0 col3\" >LS</th>\n",
       "      <th id=\"T_ee25c_level0_col4\" class=\"col_heading level0 col4\" >EF</th>\n",
       "      <th id=\"T_ee25c_level0_col5\" class=\"col_heading level0 col5\" >CR</th>\n",
       "      <th id=\"T_ee25c_level0_col6\" class=\"col_heading level0 col6\" >EM</th>\n",
       "      <th id=\"T_ee25c_level0_col7\" class=\"col_heading level0 col7\" >CL</th>\n",
       "      <th id=\"T_ee25c_level0_col8\" class=\"col_heading level0 col8\" >AP</th>\n",
       "      <th id=\"T_ee25c_level0_col9\" class=\"col_heading level0 col9\" >AR</th>\n",
       "      <th id=\"T_ee25c_level0_col10\" class=\"col_heading level0 col10\" >RE</th>\n",
       "      <th id=\"T_ee25c_level0_col11\" class=\"col_heading level0 col11\" >GA</th>\n",
       "      <th id=\"T_ee25c_level0_col12\" class=\"col_heading level0 col12\" >GR</th>\n",
       "      <th id=\"T_ee25c_level0_col13\" class=\"col_heading level0 col13\" >GS</th>\n",
       "      <th id=\"T_ee25c_level0_col14\" class=\"col_heading level0 col14\" >OV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_ee25c_level0_row0\" class=\"row_heading level0 row0\" >adv</th>\n",
       "      <td id=\"T_ee25c_row0_col0\" class=\"data row0 col0\" >-9.54%</td>\n",
       "      <td id=\"T_ee25c_row0_col1\" class=\"data row0 col1\" >-6.82%</td>\n",
       "      <td id=\"T_ee25c_row0_col2\" class=\"data row0 col2\" >2.81%</td>\n",
       "      <td id=\"T_ee25c_row0_col3\" class=\"data row0 col3\" >1.64%</td>\n",
       "      <td id=\"T_ee25c_row0_col4\" class=\"data row0 col4\" >-1.45%</td>\n",
       "      <td id=\"T_ee25c_row0_col5\" class=\"data row0 col5\" >5.42%</td>\n",
       "      <td id=\"T_ee25c_row0_col6\" class=\"data row0 col6\" >-1.86%</td>\n",
       "      <td id=\"T_ee25c_row0_col7\" class=\"data row0 col7\" >-12.03%</td>\n",
       "      <td id=\"T_ee25c_row0_col8\" class=\"data row0 col8\" >2.98%</td>\n",
       "      <td id=\"T_ee25c_row0_col9\" class=\"data row0 col9\" >-22.76%</td>\n",
       "      <td id=\"T_ee25c_row0_col10\" class=\"data row0 col10\" >-19.68%</td>\n",
       "      <td id=\"T_ee25c_row0_col11\" class=\"data row0 col11\" >1.94%</td>\n",
       "      <td id=\"T_ee25c_row0_col12\" class=\"data row0 col12\" >-8.56%</td>\n",
       "      <td id=\"T_ee25c_row0_col13\" class=\"data row0 col13\" >43.94%</td>\n",
       "      <td id=\"T_ee25c_row0_col14\" class=\"data row0 col14\" >-16.86%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ee25c_level0_row1\" class=\"row_heading level0 row1\" >det</th>\n",
       "      <td id=\"T_ee25c_row1_col0\" class=\"data row1 col0\" >-4.71%</td>\n",
       "      <td id=\"T_ee25c_row1_col1\" class=\"data row1 col1\" >-3.17%</td>\n",
       "      <td id=\"T_ee25c_row1_col2\" class=\"data row1 col2\" >7.20%</td>\n",
       "      <td id=\"T_ee25c_row1_col3\" class=\"data row1 col3\" >-5.99%</td>\n",
       "      <td id=\"T_ee25c_row1_col4\" class=\"data row1 col4\" >12.79%</td>\n",
       "      <td id=\"T_ee25c_row1_col5\" class=\"data row1 col5\" >5.69%</td>\n",
       "      <td id=\"T_ee25c_row1_col6\" class=\"data row1 col6\" >-3.16%</td>\n",
       "      <td id=\"T_ee25c_row1_col7\" class=\"data row1 col7\" >19.72%</td>\n",
       "      <td id=\"T_ee25c_row1_col8\" class=\"data row1 col8\" >2.35%</td>\n",
       "      <td id=\"T_ee25c_row1_col9\" class=\"data row1 col9\" >22.74%</td>\n",
       "      <td id=\"T_ee25c_row1_col10\" class=\"data row1 col10\" >-5.11%</td>\n",
       "      <td id=\"T_ee25c_row1_col11\" class=\"data row1 col11\" >-2.19%</td>\n",
       "      <td id=\"T_ee25c_row1_col12\" class=\"data row1 col12\" >11.11%</td>\n",
       "      <td id=\"T_ee25c_row1_col13\" class=\"data row1 col13\" >11.03%</td>\n",
       "      <td id=\"T_ee25c_row1_col14\" class=\"data row1 col14\" >7.34%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ee25c_level0_row2\" class=\"row_heading level0 row2\" >part</th>\n",
       "      <td id=\"T_ee25c_row2_col0\" class=\"data row2 col0\" >-2.08%</td>\n",
       "      <td id=\"T_ee25c_row2_col1\" class=\"data row2 col1\" >0.21%</td>\n",
       "      <td id=\"T_ee25c_row2_col2\" class=\"data row2 col2\" >-0.66%</td>\n",
       "      <td id=\"T_ee25c_row2_col3\" class=\"data row2 col3\" >4.50%</td>\n",
       "      <td id=\"T_ee25c_row2_col4\" class=\"data row2 col4\" >6.10%</td>\n",
       "      <td id=\"T_ee25c_row2_col5\" class=\"data row2 col5\" >28.81%</td>\n",
       "      <td id=\"T_ee25c_row2_col6\" class=\"data row2 col6\" >-22.08%</td>\n",
       "      <td id=\"T_ee25c_row2_col7\" class=\"data row2 col7\" >-10.88%</td>\n",
       "      <td id=\"T_ee25c_row2_col8\" class=\"data row2 col8\" >-5.57%</td>\n",
       "      <td id=\"T_ee25c_row2_col9\" class=\"data row2 col9\" >-16.13%</td>\n",
       "      <td id=\"T_ee25c_row2_col10\" class=\"data row2 col10\" >4.87%</td>\n",
       "      <td id=\"T_ee25c_row2_col11\" class=\"data row2 col11\" >0.41%</td>\n",
       "      <td id=\"T_ee25c_row2_col12\" class=\"data row2 col12\" >-25.03%</td>\n",
       "      <td id=\"T_ee25c_row2_col13\" class=\"data row2 col13\" >22.70%</td>\n",
       "      <td id=\"T_ee25c_row2_col14\" class=\"data row2 col14\" >4.30%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ee25c_level0_row3\" class=\"row_heading level0 row3\" >pron</th>\n",
       "      <td id=\"T_ee25c_row3_col0\" class=\"data row3 col0\" >-0.23%</td>\n",
       "      <td id=\"T_ee25c_row3_col1\" class=\"data row3 col1\" >-6.26%</td>\n",
       "      <td id=\"T_ee25c_row3_col2\" class=\"data row3 col2\" >-4.67%</td>\n",
       "      <td id=\"T_ee25c_row3_col3\" class=\"data row3 col3\" >-1.29%</td>\n",
       "      <td id=\"T_ee25c_row3_col4\" class=\"data row3 col4\" >-3.31%</td>\n",
       "      <td id=\"T_ee25c_row3_col5\" class=\"data row3 col5\" >-11.88%</td>\n",
       "      <td id=\"T_ee25c_row3_col6\" class=\"data row3 col6\" >3.39%</td>\n",
       "      <td id=\"T_ee25c_row3_col7\" class=\"data row3 col7\" >2.84%</td>\n",
       "      <td id=\"T_ee25c_row3_col8\" class=\"data row3 col8\" >-3.21%</td>\n",
       "      <td id=\"T_ee25c_row3_col9\" class=\"data row3 col9\" >6.86%</td>\n",
       "      <td id=\"T_ee25c_row3_col10\" class=\"data row3 col10\" >-7.64%</td>\n",
       "      <td id=\"T_ee25c_row3_col11\" class=\"data row3 col11\" >-10.25%</td>\n",
       "      <td id=\"T_ee25c_row3_col12\" class=\"data row3 col12\" >-5.10%</td>\n",
       "      <td id=\"T_ee25c_row3_col13\" class=\"data row3 col13\" >-27.85%</td>\n",
       "      <td id=\"T_ee25c_row3_col14\" class=\"data row3 col14\" >-1.14%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ee25c_level0_row4\" class=\"row_heading level0 row4\" >verb</th>\n",
       "      <td id=\"T_ee25c_row4_col0\" class=\"data row4 col0\" >0.48%</td>\n",
       "      <td id=\"T_ee25c_row4_col1\" class=\"data row4 col1\" >7.06%</td>\n",
       "      <td id=\"T_ee25c_row4_col2\" class=\"data row4 col2\" >8.52%</td>\n",
       "      <td id=\"T_ee25c_row4_col3\" class=\"data row4 col3\" >-7.28%</td>\n",
       "      <td id=\"T_ee25c_row4_col4\" class=\"data row4 col4\" >-5.92%</td>\n",
       "      <td id=\"T_ee25c_row4_col5\" class=\"data row4 col5\" >-7.85%</td>\n",
       "      <td id=\"T_ee25c_row4_col6\" class=\"data row4 col6\" >8.46%</td>\n",
       "      <td id=\"T_ee25c_row4_col7\" class=\"data row4 col7\" >-11.78%</td>\n",
       "      <td id=\"T_ee25c_row4_col8\" class=\"data row4 col8\" >-4.93%</td>\n",
       "      <td id=\"T_ee25c_row4_col9\" class=\"data row4 col9\" >-10.73%</td>\n",
       "      <td id=\"T_ee25c_row4_col10\" class=\"data row4 col10\" >-1.81%</td>\n",
       "      <td id=\"T_ee25c_row4_col11\" class=\"data row4 col11\" >5.71%</td>\n",
       "      <td id=\"T_ee25c_row4_col12\" class=\"data row4 col12\" >9.35%</td>\n",
       "      <td id=\"T_ee25c_row4_col13\" class=\"data row4 col13\" >-28.38%</td>\n",
       "      <td id=\"T_ee25c_row4_col14\" class=\"data row4 col14\" >-6.08%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ee25c_level0_row5\" class=\"row_heading level0 row5\" >punct</th>\n",
       "      <td id=\"T_ee25c_row5_col0\" class=\"data row5 col0\" >2.87%</td>\n",
       "      <td id=\"T_ee25c_row5_col1\" class=\"data row5 col1\" >-1.22%</td>\n",
       "      <td id=\"T_ee25c_row5_col2\" class=\"data row5 col2\" >-8.39%</td>\n",
       "      <td id=\"T_ee25c_row5_col3\" class=\"data row5 col3\" >7.00%</td>\n",
       "      <td id=\"T_ee25c_row5_col4\" class=\"data row5 col4\" >1.86%</td>\n",
       "      <td id=\"T_ee25c_row5_col5\" class=\"data row5 col5\" >22.15%</td>\n",
       "      <td id=\"T_ee25c_row5_col6\" class=\"data row5 col6\" >5.21%</td>\n",
       "      <td id=\"T_ee25c_row5_col7\" class=\"data row5 col7\" >4.32%</td>\n",
       "      <td id=\"T_ee25c_row5_col8\" class=\"data row5 col8\" >2.69%</td>\n",
       "      <td id=\"T_ee25c_row5_col9\" class=\"data row5 col9\" >5.28%</td>\n",
       "      <td id=\"T_ee25c_row5_col10\" class=\"data row5 col10\" >1.54%</td>\n",
       "      <td id=\"T_ee25c_row5_col11\" class=\"data row5 col11\" >0.56%</td>\n",
       "      <td id=\"T_ee25c_row5_col12\" class=\"data row5 col12\" >0.08%</td>\n",
       "      <td id=\"T_ee25c_row5_col13\" class=\"data row5 col13\" >5.25%</td>\n",
       "      <td id=\"T_ee25c_row5_col14\" class=\"data row5 col14\" >6.60%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ee25c_level0_row6\" class=\"row_heading level0 row6\" >cconj</th>\n",
       "      <td id=\"T_ee25c_row6_col0\" class=\"data row6 col0\" >3.99%</td>\n",
       "      <td id=\"T_ee25c_row6_col1\" class=\"data row6 col1\" >8.34%</td>\n",
       "      <td id=\"T_ee25c_row6_col2\" class=\"data row6 col2\" >11.26%</td>\n",
       "      <td id=\"T_ee25c_row6_col3\" class=\"data row6 col3\" >20.17%</td>\n",
       "      <td id=\"T_ee25c_row6_col4\" class=\"data row6 col4\" >17.47%</td>\n",
       "      <td id=\"T_ee25c_row6_col5\" class=\"data row6 col5\" >22.38%</td>\n",
       "      <td id=\"T_ee25c_row6_col6\" class=\"data row6 col6\" >-4.32%</td>\n",
       "      <td id=\"T_ee25c_row6_col7\" class=\"data row6 col7\" >2.79%</td>\n",
       "      <td id=\"T_ee25c_row6_col8\" class=\"data row6 col8\" >9.11%</td>\n",
       "      <td id=\"T_ee25c_row6_col9\" class=\"data row6 col9\" >15.19%</td>\n",
       "      <td id=\"T_ee25c_row6_col10\" class=\"data row6 col10\" >29.05%</td>\n",
       "      <td id=\"T_ee25c_row6_col11\" class=\"data row6 col11\" >18.20%</td>\n",
       "      <td id=\"T_ee25c_row6_col12\" class=\"data row6 col12\" >17.74%</td>\n",
       "      <td id=\"T_ee25c_row6_col13\" class=\"data row6 col13\" >20.75%</td>\n",
       "      <td id=\"T_ee25c_row6_col14\" class=\"data row6 col14\" >13.46%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ee25c_level0_row7\" class=\"row_heading level0 row7\" >noun</th>\n",
       "      <td id=\"T_ee25c_row7_col0\" class=\"data row7 col0\" >4.43%</td>\n",
       "      <td id=\"T_ee25c_row7_col1\" class=\"data row7 col1\" >3.97%</td>\n",
       "      <td id=\"T_ee25c_row7_col2\" class=\"data row7 col2\" >3.87%</td>\n",
       "      <td id=\"T_ee25c_row7_col3\" class=\"data row7 col3\" >-0.29%</td>\n",
       "      <td id=\"T_ee25c_row7_col4\" class=\"data row7 col4\" >2.20%</td>\n",
       "      <td id=\"T_ee25c_row7_col5\" class=\"data row7 col5\" >-8.40%</td>\n",
       "      <td id=\"T_ee25c_row7_col6\" class=\"data row7 col6\" >-1.41%</td>\n",
       "      <td id=\"T_ee25c_row7_col7\" class=\"data row7 col7\" >1.55%</td>\n",
       "      <td id=\"T_ee25c_row7_col8\" class=\"data row7 col8\" >7.81%</td>\n",
       "      <td id=\"T_ee25c_row7_col9\" class=\"data row7 col9\" >0.80%</td>\n",
       "      <td id=\"T_ee25c_row7_col10\" class=\"data row7 col10\" >3.97%</td>\n",
       "      <td id=\"T_ee25c_row7_col11\" class=\"data row7 col11\" >4.68%</td>\n",
       "      <td id=\"T_ee25c_row7_col12\" class=\"data row7 col12\" >1.91%</td>\n",
       "      <td id=\"T_ee25c_row7_col13\" class=\"data row7 col13\" >9.44%</td>\n",
       "      <td id=\"T_ee25c_row7_col14\" class=\"data row7 col14\" >6.13%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ee25c_level0_row8\" class=\"row_heading level0 row8\" >adj</th>\n",
       "      <td id=\"T_ee25c_row8_col0\" class=\"data row8 col0\" >6.36%</td>\n",
       "      <td id=\"T_ee25c_row8_col1\" class=\"data row8 col1\" >2.17%</td>\n",
       "      <td id=\"T_ee25c_row8_col2\" class=\"data row8 col2\" >-3.04%</td>\n",
       "      <td id=\"T_ee25c_row8_col3\" class=\"data row8 col3\" >7.47%</td>\n",
       "      <td id=\"T_ee25c_row8_col4\" class=\"data row8 col4\" >-6.14%</td>\n",
       "      <td id=\"T_ee25c_row8_col5\" class=\"data row8 col5\" >1.34%</td>\n",
       "      <td id=\"T_ee25c_row8_col6\" class=\"data row8 col6\" >6.92%</td>\n",
       "      <td id=\"T_ee25c_row8_col7\" class=\"data row8 col7\" >0.54%</td>\n",
       "      <td id=\"T_ee25c_row8_col8\" class=\"data row8 col8\" >-7.82%</td>\n",
       "      <td id=\"T_ee25c_row8_col9\" class=\"data row8 col9\" >9.92%</td>\n",
       "      <td id=\"T_ee25c_row8_col10\" class=\"data row8 col10\" >-3.97%</td>\n",
       "      <td id=\"T_ee25c_row8_col11\" class=\"data row8 col11\" >-4.97%</td>\n",
       "      <td id=\"T_ee25c_row8_col12\" class=\"data row8 col12\" >3.64%</td>\n",
       "      <td id=\"T_ee25c_row8_col13\" class=\"data row8 col13\" >-15.91%</td>\n",
       "      <td id=\"T_ee25c_row8_col14\" class=\"data row8 col14\" >4.77%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ee25c_level0_row9\" class=\"row_heading level0 row9\" >sconj</th>\n",
       "      <td id=\"T_ee25c_row9_col0\" class=\"data row9 col0\" >6.71%</td>\n",
       "      <td id=\"T_ee25c_row9_col1\" class=\"data row9 col1\" >6.62%</td>\n",
       "      <td id=\"T_ee25c_row9_col2\" class=\"data row9 col2\" >23.20%</td>\n",
       "      <td id=\"T_ee25c_row9_col3\" class=\"data row9 col3\" >16.20%</td>\n",
       "      <td id=\"T_ee25c_row9_col4\" class=\"data row9 col4\" >1.75%</td>\n",
       "      <td id=\"T_ee25c_row9_col5\" class=\"data row9 col5\" >3.98%</td>\n",
       "      <td id=\"T_ee25c_row9_col6\" class=\"data row9 col6\" >-4.80%</td>\n",
       "      <td id=\"T_ee25c_row9_col7\" class=\"data row9 col7\" >21.29%</td>\n",
       "      <td id=\"T_ee25c_row9_col8\" class=\"data row9 col8\" >30.75%</td>\n",
       "      <td id=\"T_ee25c_row9_col9\" class=\"data row9 col9\" >2.85%</td>\n",
       "      <td id=\"T_ee25c_row9_col10\" class=\"data row9 col10\" >26.41%</td>\n",
       "      <td id=\"T_ee25c_row9_col11\" class=\"data row9 col11\" >18.73%</td>\n",
       "      <td id=\"T_ee25c_row9_col12\" class=\"data row9 col12\" >22.18%</td>\n",
       "      <td id=\"T_ee25c_row9_col13\" class=\"data row9 col13\" >-131.16%</td>\n",
       "      <td id=\"T_ee25c_row9_col14\" class=\"data row9 col14\" >16.63%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ee25c_level0_row10\" class=\"row_heading level0 row10\" >adp</th>\n",
       "      <td id=\"T_ee25c_row10_col0\" class=\"data row10 col0\" >8.24%</td>\n",
       "      <td id=\"T_ee25c_row10_col1\" class=\"data row10 col1\" >10.89%</td>\n",
       "      <td id=\"T_ee25c_row10_col2\" class=\"data row10 col2\" >16.14%</td>\n",
       "      <td id=\"T_ee25c_row10_col3\" class=\"data row10 col3\" >7.95%</td>\n",
       "      <td id=\"T_ee25c_row10_col4\" class=\"data row10 col4\" >5.84%</td>\n",
       "      <td id=\"T_ee25c_row10_col5\" class=\"data row10 col5\" >29.36%</td>\n",
       "      <td id=\"T_ee25c_row10_col6\" class=\"data row10 col6\" >8.56%</td>\n",
       "      <td id=\"T_ee25c_row10_col7\" class=\"data row10 col7\" >4.79%</td>\n",
       "      <td id=\"T_ee25c_row10_col8\" class=\"data row10 col8\" >11.01%</td>\n",
       "      <td id=\"T_ee25c_row10_col9\" class=\"data row10 col9\" >5.25%</td>\n",
       "      <td id=\"T_ee25c_row10_col10\" class=\"data row10 col10\" >16.38%</td>\n",
       "      <td id=\"T_ee25c_row10_col11\" class=\"data row10 col11\" >6.31%</td>\n",
       "      <td id=\"T_ee25c_row10_col12\" class=\"data row10 col12\" >2.20%</td>\n",
       "      <td id=\"T_ee25c_row10_col13\" class=\"data row10 col13\" >-0.85%</td>\n",
       "      <td id=\"T_ee25c_row10_col14\" class=\"data row10 col14\" >7.42%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ee25c_level0_row11\" class=\"row_heading level0 row11\" >aux</th>\n",
       "      <td id=\"T_ee25c_row11_col0\" class=\"data row11 col0\" >8.98%</td>\n",
       "      <td id=\"T_ee25c_row11_col1\" class=\"data row11 col1\" >3.98%</td>\n",
       "      <td id=\"T_ee25c_row11_col2\" class=\"data row11 col2\" >8.59%</td>\n",
       "      <td id=\"T_ee25c_row11_col3\" class=\"data row11 col3\" >8.03%</td>\n",
       "      <td id=\"T_ee25c_row11_col4\" class=\"data row11 col4\" >13.29%</td>\n",
       "      <td id=\"T_ee25c_row11_col5\" class=\"data row11 col5\" >17.11%</td>\n",
       "      <td id=\"T_ee25c_row11_col6\" class=\"data row11 col6\" >4.94%</td>\n",
       "      <td id=\"T_ee25c_row11_col7\" class=\"data row11 col7\" >-1.94%</td>\n",
       "      <td id=\"T_ee25c_row11_col8\" class=\"data row11 col8\" >0.60%</td>\n",
       "      <td id=\"T_ee25c_row11_col9\" class=\"data row11 col9\" >6.92%</td>\n",
       "      <td id=\"T_ee25c_row11_col10\" class=\"data row11 col10\" >18.89%</td>\n",
       "      <td id=\"T_ee25c_row11_col11\" class=\"data row11 col11\" >9.62%</td>\n",
       "      <td id=\"T_ee25c_row11_col12\" class=\"data row11 col12\" >5.16%</td>\n",
       "      <td id=\"T_ee25c_row11_col13\" class=\"data row11 col13\" >-8.39%</td>\n",
       "      <td id=\"T_ee25c_row11_col14\" class=\"data row11 col14\" >8.72%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f1a0b833e20>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pos_weight_dict.T.style.format(\"{:.2%}\").background_gradient(\"Greens\", axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "922a666d644bf7f1fa4ade08540063ff21c0eb45f3d762dc9889697841ef722e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
